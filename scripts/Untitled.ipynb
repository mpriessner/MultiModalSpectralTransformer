{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394ddcc3-546a-40dd-9af1-ed8ecec4a922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of 4000\n",
      "Created folder for chunk 0: /projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350_4000/chunk_000_20241018_063126\n",
      "prepare_data\n",
      "generate_simulated_data\n",
      "\u001b[1m\u001b[31mThis is: data_generation\u001b[0m\n",
      "outside ran_num\n",
      "442124\n",
      "442124\n",
      "0\n",
      "\u001b[1m\u001b[33m run_sgnn: DONE\u001b[0m\n",
      "\u001b[1m\u001b[33m run_1H_generation: DONE\u001b[0m\n",
      "\u001b[1m\u001b[33m run_13C_generation: DONE\u001b[0m\n",
      "\u001b[1m\u001b[33m run_COSY_generation: DONE\u001b[0m\n",
      "\u001b[1m\u001b[33m run_HSQC_generation: DONE\u001b[0m\n",
      "\u001b[1m\u001b[33m IR Generation: DONE\u001b[0m\n",
      "load_model_and_data\n",
      "Warning: File for dataset IR not found. Skipping...\n",
      "Proecessing data to save as pkl file\n",
      "/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2/data_1H_442124_583466.pkl\n",
      "Pickle saved.\n",
      "Pickle Loaded.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/tmp_user_data/knlr326/ipykernel_2115469/3100877496.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;31m#config.MF_generations = 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m     \u001b[0mrun_base_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIR_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi_MF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitos_MF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/tmp_user_data/knlr326/ipykernel_2115469/3100877496.py\u001b[0m in \u001b[0;36mrun_base_model\u001b[0;34m(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblank_percentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pretrained_model_on_sim_data_before\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIR_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi_MF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitos_MF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{chunk_idx}_{0}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_1H_path_SGNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tmp_user_data/knlr326/ipykernel_2115469/3100877496.py\u001b[0m in \u001b[0;36mtest_pretrained_model_on_sim_data_before\u001b[0;34m(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, idx)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"load_model_and_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0mmodel_MMT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi_MF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_model_analysis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tmp_user_data/knlr326/ipykernel_2115469/3100877496.py\u001b[0m in \u001b[0;36mload_model_and_data\u001b[0;34m(config, stoi, stoi_MF)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi_MF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0mval_dataloader_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi_MF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m     \u001b[0mmodel_MMT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_MMT_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_MMT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader_multi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/utils_MMT/mmt_result_test_functions_15_4.py\u001b[0m in \u001b[0;36mload_MMT_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0mmulti_gpu_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerMultiGPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m     \u001b[0mmulti_gpu_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/cc/se_users/knlr326/miniconda_SE/envs/NMR_Structure_Elucidator/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, tags_csv, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags_csv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/cc/se_users/knlr326/miniconda_SE/envs/NMR_Structure_Elucidator/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/cc/se_users/knlr326/miniconda_SE/envs/NMR_Structure_Elucidator/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/cc/se_users/knlr326/miniconda_SE/envs/NMR_Structure_Elucidator/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/cc/se_users/knlr326/miniconda_SE/envs/NMR_Structure_Elucidator/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Core libraries\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import copy\n",
    "\n",
    "\n",
    "# Data processing and scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine learning and data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# RDKit for cheminformatics\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Draw, MolFromSmiles, MolToSmiles\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# tqdm for progress bars\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "\n",
    "# Miscellaneous\n",
    "from argparse import Namespace\n",
    "from IPython.display import HTML, SVG\n",
    "\n",
    "# Setting up environment\n",
    "torch.cuda.device_count()\n",
    "#wandb.login()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "from rdkit.Chem.Descriptors import MolWt\n",
    "from rdkit import DataStructs\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "#import seaborn as sns\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.profiler import SimpleProfiler, AdvancedProfiler\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import sys\n",
    "sys.path.append(\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer\")\n",
    "\n",
    "import utils_MMT.clip_functions_v15_4 as cf #\n",
    "import utils_MMT.MT_functions_v15_4 as mtf # is different compared to V14_1\n",
    "import utils_MMT.validate_generate_MMT_v15_4 as vgmmt #\n",
    "import utils_MMT.run_batch_gen_val_MMT_v15_4 as rbgvm #\n",
    "import utils_MMT.clustering_visualization_v15_4 as cv #\n",
    "import utils_MMT.plotting_v15_4 as pt #\n",
    "import utils_MMT.execution_function_v15_4 as ex #\n",
    "import utils_MMT.train_test_functions_pl_v15_4 as ttf\n",
    "import utils_MMT.ir_simulation_v15_4 as irs\n",
    "import utils_MMT.helper_functions_pl_v15_4 as hf\n",
    "import utils_MMT.mmt_result_test_functions_15_4 as mrtf\n",
    "\n",
    "\n",
    "def load_json_dics():\n",
    "    with open('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/itos.json', 'r') as f:\n",
    "        itos = json.load(f)\n",
    "    with open('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/stoi.json', 'r') as f:\n",
    "        stoi = json.load(f)\n",
    "\n",
    "    with open('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/stoi_MF.json', 'r') as f:\n",
    "        stoi_MF = json.load(f)\n",
    "    with open('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/itos_MF.json', 'r') as f:\n",
    "        itos_MF = json.load(f)    \n",
    "    return itos, stoi, stoi_MF, itos_MF\n",
    "    \n",
    "itos, stoi, stoi_MF, itos_MF = load_json_dics()\n",
    "rand_num = str(random.randint(1, 10000000))\n",
    "\n",
    "IR_config_dict = {\n",
    "    \"gpu\": list(range(torch.cuda.device_count())),  # Default value is None, should be one of the available GPU indices\n",
    "    \"test_path\": [\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/chemprop-IR/ir_models_data/solvation_example/solvation_spectra.csv\"],  # Default value is None\n",
    "    \"use_compound_names\": [False],  # Default is False\n",
    "    \"preds_path\": [\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/chemprop-IR/ir_models_data/ir_preds_test_2.csv\"],  # Default value is None\n",
    "    #\"checkpoint_dir\": [\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/chemprop-IR/ir_models_data/computed_model/model_files\"],  # Default value is None\n",
    "    \"checkpoint_dir\": [\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/chemprop-IR/ir_models_data/experiment_model/model_files\"],  # Default value is None\n",
    "    \"spectra_type\": [\"experimental\"],  # [\"experimental\", \"simulated\"] Default value is None\n",
    "    \"spectra_type_nr\": [0],  # 0-4 Default value is None\n",
    "    \n",
    "    \"checkpoint_path\": [None],  # Default value is None\n",
    "    \"batch_size\": [64],  # Default is 50\n",
    "    \"no_cuda\": [False],  # Default is False\n",
    "    \"features_generator\":[None],  # Default value is None, should be one of the available features generators\n",
    "    \"features_path\": [None],  # Default value is None\n",
    "    #\"features_path\": [[\"/projects/cc/se_users/knlr326/2_git_repos/chemprop-IR/ir_models_data/solvation_example/solvation_phases.csv\" ]],  # Default value is None\n",
    "    \"max_data_size\": [100],  # Default value is None\n",
    "    \"ensemble_variance\": [False],  # Default is False\n",
    "    \"ensemble_variance_conv\": [0.0],  # Default is 0.0\n",
    "    #\"dataset_type\":[\"spectra\"]\n",
    "    }\n",
    "\n",
    "hyperparameters = {\n",
    "    # General project information\n",
    "    \"project\": [\"Improv_Cycle_v1\"],  # Name of the project for wandb monitoring\n",
    "    \"ran_num\":[rand_num],\n",
    "    #\"random_seed\":[42], # random_seed\n",
    "    \"device\": [\"cuda\"], # device on which training takes place\n",
    "    \"gpu_num\":[1], # number of GPUs for training with pytorch lightning\n",
    "    \"num_workers\":[4], # Needs to stay 1 otherwise code crashes - ToDO\n",
    "    \"data_type\":[\"sgnn\"], #[\"sgnn\", \"exp\", \"acd\", \"real\", \"inference\"], Different data types to select\n",
    "    \"execution_type\":[\"validate_MMT\"], #[ \"plot_similarities\", \"simulate_real\", \"test_performance\", \"SMI_generation_MMT\", \"SMI_generation_MF\", \"data_generation\", \"transformer_training\",\"transformer_improvement\", \"clip_training\", \"clip_improvement\", \"validate_MMT\"] # different networks to select for training\n",
    "    \"syn_data_simulated\": [False],  # For the improvment cycle a ticker that shows whether data has been simulated or not.\n",
    "    \"training_type\":[\"clip\"], #[\"clip\",\"transformer\"] # different networks to select for training\n",
    "\n",
    "    # Encoding dicts\n",
    "    \"itos_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/itos.json\"],\n",
    "    \"stoi_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/stoi.json\"],\n",
    "    \"itos_MF_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/itos_MF.json\"],\n",
    "    \"stoi_MF_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/stoi_MF.json\"],\n",
    "    \n",
    "    ### Data settings\n",
    "    \"input_dim_1H\":[2], # Imput dimensions of the 1H data\n",
    "    \"input_dim_13C\": [1], # Imput dimensions of the 13C data\n",
    "    \"input_dim_HSQC\": [2], # Imput dimensions of the HSQC data\n",
    "    \"input_dim_COSY\": [2],  # Imput dimensions of the COSY data\n",
    "    \"input_dim_IR\": [1000],  # Imput dimensions of the IR data\n",
    "    \"MF_vocab_size\": [len(stoi_MF)],  # New, size of the vocabulary for molecular formulas\n",
    "    \"MS_vocab_size\": [len(stoi)],  # New, size of the vocabulary for molecular formulas\n",
    "    \"tr_te_split\":[0.9], # Train-Test split\n",
    "    \"padding_points_number\":[64], # Padding number for the embedding layer into the network\n",
    "    \"data_size\": [4000], # number of datapoints for the training 3975764/1797828\n",
    "    \"test_size\": [10], # number of datapoints for the training 3975764\n",
    "    \"model_save_dir\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/test\"], # Folder where networks are saved\n",
    "    \"ML_dump_folder\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/dump\"], # a folder where intermediate files for the SGNN network are generated\n",
    "    \"model_save_interval\": [10000], # seconds passed until next model is saved\n",
    "    \n",
    "    # Option 1 SGNN\n",
    "    \"use_real_data\":[False], #[True, False]\n",
    "    \"ref_data_type\":[\"1H\"], #[\"1H\",\"13C\",\"HSQC\",\"COSY\",\"IR\"]\n",
    "    \"csv_train_path\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_train_V8.csv'], # To keep a reference of the compounds that it was trained on\n",
    "    \"csv_1H_path_SGNN\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_train_V8.csv'],\n",
    "    \"csv_13C_path_SGNN\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_13C.csv'],    \n",
    "    \"csv_HSQC_path_SGNN\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_HSQC.csv'],    \n",
    "    \"csv_COSY_path_SGNN\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_COSY.csv'],      \n",
    "    \"csv_IR_MF_path\": [''],     #571124\n",
    "    \"csv_path_val\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8.csv'], #63459   \n",
    "    #\"IR_data_folder\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"],\n",
    "    \"IR_data_folder\": [\"\"],\n",
    "\n",
    "   # \"pickle_file_path\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_V8_938756.pkl\"],\n",
    "    \"pickle_file_path\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8_355655.pkl\"],\n",
    "    \n",
    "    \"dl_mode\": ['val'], #[\"val\",\"train\"]   \n",
    "    \"isomericSmiles\": [False], # whether stereochemistry is considered or not\n",
    "    \n",
    "    # Option 2 exp\n",
    "    #\"exp_path\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/missing_ZINC_files.csv'], #63459   \n",
    "\n",
    "     # Option 2 ACD\n",
    "    #\"csv_path_1H_ACD\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/1H_ZINC_XL_v3.csv'],\n",
    "    #\"data_folder_HSQC_ACD\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/zinc250k\"],\n",
    "    # Option 3 real\n",
    "    \"comparision_number\": [1000],  # With how many of the training examples should it be compared with in a t-SNE plot\n",
    "    \"vector_db\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/smiles_fingerprints_train_4M_v1.csv'],    \n",
    "    \"secret_csv_SMI_vectors\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/25_Test_Improvement_cycle/1_Test_ZINC_250/test_32_zinc250_vec_db.csv'],    \n",
    "    \"secret_csv_SMI_targets\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/25_Test_Improvement_cycle/1_Test_ZINC_250/test_32_zinc250.csv'],    \n",
    "    \"secret_csv_SMI_sim_searched\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/25_Test_Improvement_cycle/1_Test_ZINC_250/test_32_zinc250.csv'],    \n",
    "    \"csv_SMI_targets\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/25_Test_Improvement_cycle/1_Test_ZINC_250/test_32_zinc250_single_target_919.csv'],\n",
    "    \"csv_1H_path_REAL\": [''],\n",
    "    \"csv_13C_path_REAL\": [''],    \n",
    "    \"csv_HSQC_path_REAL\": [''],    \n",
    "    \"csv_COSY_path_REAL\": [''],    \n",
    "    #\"pkl_path_HSQC_real\": [\"\"],\n",
    "    # noising HSQC data\n",
    "    #\"noising_HSQC\":[False],\n",
    "    #\"noising_peaks_file\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v1/noise_peaks_norm_4.pkl\"],\n",
    "    #\"noising_dist_file\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v1/noise_num_list_norm_4.pkl\"],\n",
    "\n",
    "    #### Transformer Settings ####\n",
    "    # Training and model settings\n",
    "    \"training_mode\":[\"1H_13C_HSQC_COSY_IR_MF_MW\"], #[\"edding_src_1H = torch.zeros((feature_dim, current_ba\"], Modalities selected for training\n",
    "    \"blank_percentage\":[0.0], # percentage of spectra that are blanked out during training for better generalizability of the network to various datatypes\n",
    "    \"batch_size\":[64], # number needs to be the same as number of GPUs \n",
    "    \"num_epochs\": [10], # number of epochs for training\n",
    "    \"lr_pretraining\": [1e-4], # Pretraining learning rate\n",
    "    \"lr_finetuning\": [5e-5], # Finetuning learning rate\n",
    "    \"load_model\": [True], # if model should be loaded from path\n",
    "    \"checkpoint_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW_Drop/MultimodalTransformer_time_1704760608.6927748_Loss_0.137.ckpt\"], #V8\n",
    "\n",
    "\n",
    "    \"save_model\": [True], # if model should be saved\n",
    "    # Model architecture\n",
    "    \"in_size\": [len(stoi)],\n",
    "    \"hidden_size\": [128],\n",
    "    \"out_size\": [len(stoi)],\n",
    "    \"num_encoder_layers\": [6], #8\n",
    "    \"num_decoder_layers\": [6], #8\n",
    "    \"num_heads\": [16], #8  ### number of attention heads\n",
    "    \"forward_expansion\": [4], #4\n",
    "    \"max_len\": [128], # maximum length of the generated sequence\n",
    "    \"drop_out\": [0.1],\n",
    "    \"fingerprint_size\": [512], # Dimensions of encoder output for CLIP contrastive training    \n",
    "    #\"track_metrics\":[True],\n",
    "    \"gen_SMI_sequence\":[True], # If the model generates a sequence with the SMILES current model for evaluation\n",
    "    \"sampling_method\":[\"mix\"], # weight_mol_weight [\"multinomial\", \"greedy\". \"mix\"]  \n",
    "    \"training_setup\":[\"pretraining\"], # [\"pretraining\",\"finetuning\"]\n",
    "    \"smi_randomizer\":[False], # if smiles are randomized or canonical during training\n",
    "    ### SGNN Feedback\n",
    "    \"sgnn_feedback\":[False], # if SGNN generates 1H and 13C spectrum on the fly on the generated smiles -> \"gen_SMI_sequence\":[True]\n",
    "    \"matching\":[\"HungDist\"], #[\"MinSum\",\"EucDist\",\"HungDist\"], # HSQC point matching technique used\n",
    "    \"padding\":[\"NN\"], # [\"Zero\",\"Trunc\",\"NN\"], # HSQC padding technique used -> see publication: XXX\n",
    "    # Weight feedback\n",
    "    \"train_weight_min\":[None], # Calculate on the fly - Used for the weight loss calculation for scaling\n",
    "    \"train_weight_max\":[None], # Calculate on the fly - Used for the weight loss calculation for scaling\n",
    "    # Training Loss Weighting options\n",
    "    #\"symbol_reward_weight\": [0.1], # loss weight if considered to contribute to loss function\n",
    "    \"weight_validity\": [0.0], # up to 1\n",
    "    \"weight_SMI\": [1.0], # up to 1\n",
    "    #\"weight_MF\": [1.0], # up to 1\n",
    "    \"weight_FP\": [0.0], # up to 1\n",
    "    \"weight_MW\": [0], # up to 100\n",
    "    \"weight_sgnn\": [0.0], # up to 10\n",
    "    \"weight_tanimoto\": [0.0], # up to 1\n",
    "    \"change_loss_weights\":[False], # if selected the weights get ajusted along the training\n",
    "    \"increment\":[0.01], # increment on how much it gets ajusted during training -> TODO\n",
    "    \"batch_frequency\":[10000], # Frequency how often it gets ajusted -> TODO\n",
    "    \n",
    "    ### For Validation\n",
    "    \"beam_size\": [1],  \n",
    "    \"multinom_runs\": [1], \n",
    "    \"temperature\":[1],\n",
    "    \"gen_len\":[64],\n",
    "    \"pkl_save_folder\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/pkl_save_folder\"],\n",
    "    \n",
    "    ### Molformer options \n",
    "    \"MF_max_trails\":[500],\n",
    "    \"MF_tanimoto_filter\":[0.1],\n",
    "    \"MF_filter_higher\":[1], # False = 0 True = 1\n",
    "    \"MF_delta_weight\":[5],\n",
    "    \"MF_generations\":[30],\n",
    "    \"MF_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/deep-molecular-optimization/experiments/trained/Alessandro_big/weights_pubchem_with_counts_and_rank_sanitized.ckpt\"],\n",
    "    \"MF_vocab\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/deep-molecular-optimization/experiments/trained/Alessandro_big/vocab_new.pkl\"],\n",
    "    \"MF_csv_source_folder_location\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/deep-molecular-optimization/data/MMP\"],\n",
    "    \"MF_csv_source_file_name\":[\"test_selection_2\"],\n",
    "    \"MF_methods\":[\"MMP\"], #[\"MMP\", \"scaffold\", \"MMP_scaffold\"],    \n",
    "    \"max_scaffold_generations\":[10], #\n",
    "    ### MMT batch generation\n",
    "    \"MMT_batch\":[32], # how big is the batch of copies of the same inputs that is processed by MMT \n",
    "    \"MMT_generations\":[4], # need to be multiple of MMT_batch -> number of valid generated molecules\n",
    "    #------------------------\n",
    "    \"n_samples\":[10], # number of molecules that should be processed for data generation - needs to be smaller than dataloader size\n",
    "    \"gen_mol_csv_folder_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2\"], # number of molecules that should be processed for data generation - needs to be smaller than dataloader size\n",
    "    \n",
    "    ### Fine-tuning improvement options\n",
    "    \"train_data_blend\":[0], # how many additional molecules should be added to the new dataset from the original training dataset\n",
    "    \"train_data_blend_CLIP\":[1000], # how many additional molecules should be added to the new dataset from the original training dataset\n",
    "    \n",
    "    ### Data generation SGNN -> 1H, 13C, HSQC, COSY\n",
    "    \"SGNN_gen_folder_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2/dump_2\"],\n",
    "    \"SGNN_csv_gen_smi\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/deep-molecular-optimization/data/MMP/test_selection_1.csv\"],\n",
    "    \"SGNN_size_filter\":[550],\n",
    "    \"SGNN_csv_save_folder\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2\"],\n",
    "    \"IR_save_folder\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2/IR_data\"],\n",
    "    \n",
    "    #################################################\n",
    "    #### LEGACY parameters for other expeirments ####\n",
    "    #################################################\n",
    "    #### CLIP Settings ####\n",
    "    ### ChemBerta\n",
    "    \"model_version\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v1/Chemberta_source\"],   # Source of pretrained chemberta from paper\n",
    "    \"CB_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v1/Large_300_15.pth\"], # path to pretrained Chemberta model\n",
    "    \"num_class\":[1024], #\n",
    "    \"num_linear_layers\":[0], # number of linear layers in architecture before num_class output\n",
    "    \"use_dropout\":[True],\n",
    "    \"use_relu\":[False],\n",
    "    \"loss_fn\":[\"BCEWithLogitsLoss\"], #\"MSELoss\", \"BCELoss\", \n",
    "    \"CB_embedding\": [1024], #1024\n",
    "    # PCA\n",
    "    \"fp_dim_reduction\":[False], #True\n",
    "    \"pca_components\":[300],  \n",
    "    #\"CB_model_name\": [\"Large_300_15\"],\n",
    "\n",
    "    ### Multimodal Transformer\n",
    "    \"MT_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW2_Drop/MultimodalTransformer_time_1706856620.3718672_Loss_0.202.pth\"],  # path to pretrained Multimodal Transformer model  \n",
    "    #\"MT_model_name\": [\"SpectrumBERT_PCA_large_3.6\"],\n",
    "    \"MT_embedding\": [512], #512\n",
    "    ### Projection Head\n",
    "    \"projection_dim\": [512],\n",
    "    \"dropout\": [0.1],\n",
    "    \n",
    "    #CLIP\n",
    "    # Dataloader settings\n",
    "    \"similarity_threshold\":[0.6], # Filtere that selects just molecules with a tanimotosimilarity higher than that number\n",
    "    \"max_search_size\":[10000], # Size of the data that will be searched to find the similar molecules  # 100000\n",
    "    \"weight_delta\":[50], # Filter to molecules with a +/- delta weight of that numbeTraceback (most recent call last):\n",
    "    \"CLIP_batch_size\":[128],  #,64,128,256 ### batch size for the CLIP training\n",
    "    \"CLIP_NUM_EPOCHS\": [10],    # Number of training epochs\n",
    "    \n",
    "    ### Train parameters\n",
    "    ### CLIP Model   \n",
    "    \"CLIP_temperature\": [1],\n",
    "    #\"CB_projection_lr\": [1e-3], # projection head learning rate for Chemberta\n",
    "    \"MT_projection_lr\": [1e-3], # projection head learning rate for Multimodal Transfomer\n",
    "    \"CB_lr\": [1e-4], # Chemberta Learning Rate\n",
    "    \"MT_lr\": [1e-5], # Multimodal Transfomer Learning Rate\n",
    "    \"weight_decay\": [1e-3], # Weight decay for projection heads -> TODO why just on those\n",
    "    \"patience\": [1],   # not integrated yet\n",
    "    \"factor\": [0.8],   # not integrated yet\n",
    "    \"CLIP_continue_training\":[True],\n",
    "    \"CLIP_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_modalities_CLIP_1_dot_product/MultimodalCLIP_Epoch_9_Loss0.096.ckpt\"],   \n",
    "    \"CLIP_model_save_dir\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/test_CLIP\"],\n",
    "    \n",
    "    ### BLIP Model\n",
    "    \"BLIP_temperature\": [1],\n",
    "    \"Qformer_lr\":[1e-4],\n",
    "    \"Qformer_CB_lr\":[1e-4],\n",
    "    \"Qformer_MT_lr\":[1e-4],\n",
    "    \"BLIP_continue_training\":[True],\n",
    "    # \"BLIP_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/test_BLIP_1M/model_BLIP-epoch=03-loss=2.54_v0.ckpt\"],   \n",
    "    # \"BLIP_model_save_dir\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/test_BLIP_1M\"],\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_config(config, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(config, f)\n",
    "\n",
    "def load_config(path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return None    \n",
    "\n",
    "def parse_arguments(hyperparameters):\n",
    "    # Using dictionary comprehension to simplify your code\n",
    "    parsed_args = {key: val[0] for key, val in hyperparameters.items()}\n",
    "    return Namespace(**parsed_args)\n",
    "\n",
    "\n",
    "config = parse_arguments(hyperparameters)\n",
    "ir_config_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/utils_MMT/ir_config_V8.json'\n",
    "save_config(IR_config_dict, ir_config_path)\n",
    "IR_config_dict = load_config(ir_config_path)\n",
    "IR_config = parse_arguments(IR_config_dict)\n",
    "irs.modify_predict_args(IR_config)\n",
    "\n",
    "\n",
    "config_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/utils_MMT/config_V8.json'\n",
    "save_config(hyperparameters, config_path)\n",
    "config_dict = load_config(config_path)\n",
    "config = parse_arguments(config_dict)\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Union, Tuple\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "\n",
    "\n",
    "def process_pkl_files(folder_path, file_type, ranking_method):\n",
    "    pkl_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) \n",
    "                 if f.endswith('.pkl') and file_type in f]\n",
    "    \n",
    "    all_rankings = defaultdict(list)\n",
    "    \n",
    "    for file_path in pkl_files:\n",
    "        file_data = load_data(file_path)\n",
    "        ranked_molecules = rank_molecules_in_file(file_data, ranking_method)\n",
    "        \n",
    "        for molecule in ranked_molecules:\n",
    "            trg_smi = molecule[0]\n",
    "            all_rankings[trg_smi].append(molecule)\n",
    "    \n",
    "    return all_rankings\n",
    "\n",
    "\n",
    "def split_dataset(config, chunk_size: int) -> List[pd.DataFrame]:\n",
    "    df = pd.read_csv(config.SGNN_csv_gen_smi)\n",
    "    return [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "def create_chunk_folder(config, idx: int) -> str:\n",
    "    base_dir = config.model_save_dir\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    chunk_folder_name = f\"chunk_{idx:03d}_{current_datetime}\"\n",
    "    chunk_folder_path = os.path.join(base_dir, chunk_folder_name)\n",
    "    \n",
    "    os.makedirs(chunk_folder_path, exist_ok=True)\n",
    "    print(f\"Created folder for chunk {idx}: {chunk_folder_path}\")\n",
    "    \n",
    "    return chunk_folder_path\n",
    "\n",
    "def test_pretrained_model_on_sim_data_before(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, idx):\n",
    "    MW_filter, greedy_full = True, False\n",
    "    \n",
    "    print(\"prepare_data\")\n",
    "    config = prepare_data(config, chunk)\n",
    "    print(\"generate_simulated_data\")\n",
    "    config = generate_simulated_data(config, IR_config)\n",
    "\n",
    "    print(\"load_model_and_data\")\n",
    "    model_MMT, val_dataloader, val_dataloader_multi = load_model_and_data(config, stoi, stoi_MF)\n",
    "\n",
    "    print(\"run_model_analysis\")\n",
    "    prob_dict_results_1c_, results_dict_1c_ = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "    results = test_model_performance(config, model_MMT, val_dataloader, val_dataloader_multi, stoi, itos, stoi_MF, itos_MF)\n",
    "\n",
    "    save_results_before(results, config, idx)\n",
    "\n",
    "    return config\n",
    "\n",
    "def prepare_data(config: Any, chunk: pd.DataFrame) -> Any:\n",
    "    chunk_csv_path = os.path.join(config.pkl_save_folder, \"SGNN_csv_gen_smi.csv\")\n",
    "    chunk.to_csv(chunk_csv_path)\n",
    "    config.SGNN_csv_gen_smi = chunk_csv_path \n",
    "    config.data_size = len(chunk)\n",
    "    return config\n",
    "\n",
    "def generate_simulated_data(config: Any, IR_config: Any) -> Any:\n",
    "    config.execution_type = \"data_generation\"\n",
    "    if config.execution_type == \"data_generation\":\n",
    "        print(\"\\033[1m\\033[31mThis is: data_generation\\033[0m\")\n",
    "        #import IPython; IPython.embed();\n",
    "\n",
    "        config = ex.gen_sim_aug_data(config, IR_config)\n",
    "        backup_config_paths(config)\n",
    "    return config\n",
    "\n",
    "def backup_config_paths(config: Any) -> None:\n",
    "    config.csv_1H_path_SGNN_backup = copy.deepcopy(config.csv_1H_path_SGNN)\n",
    "    config.csv_13C_path_SGNN_backup = copy.deepcopy(config.csv_13C_path_SGNN)\n",
    "    config.csv_HSQC_path_SGNN_backup = copy.deepcopy(config.csv_HSQC_path_SGNN)\n",
    "    config.csv_COSY_path_SGNN_backup = copy.deepcopy(config.csv_COSY_path_SGNN)\n",
    "    config.IR_data_folder_backup = copy.deepcopy(config.IR_data_folder)\n",
    "\n",
    "def save_results_before(results: Dict[str, Any], config: Any, idx: int) -> None:\n",
    "    variables_to_save = {\n",
    "        'avg_tani_bl_ZINC': results['avg_tani_bl_ZINC_'],\n",
    "        'results_dict_greedy_bl_ZINC': results.get('results_dict_greedy_bl_ZINC_'),\n",
    "        'failed_bl_ZINC': results.get('failed_bl_ZINC_'),\n",
    "        'avg_tani_greedy_bl_ZINC': results['avg_tani_greedy_bl_ZINC_'],\n",
    "        'results_dict_ZINC_greedy_bl': results.get('results_dict_ZINC_greedy_bl_'),\n",
    "        'total_results_bl_ZINC': results['total_results_bl_ZINC_'],\n",
    "        'corr_sampleing_prob_bl_ZINC': results['corr_sampleing_prob_bl_ZINC_'],\n",
    "        'results_dict_bl_ZINC': results['results_dict_bl_ZINC_'],\n",
    "    }\n",
    "    save_data_with_datetime_index(variables_to_save, config.pkl_save_folder, \"before_sim_data\", idx)\n",
    "\n",
    "def create_run_folder(chunk_folder, idx):\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_folder_name = f\"run_{idx}_{current_datetime}\"\n",
    "    run_folder_path = os.path.join(chunk_folder, run_folder_name)\n",
    "    \n",
    "    os.makedirs(run_folder_path, exist_ok=True)\n",
    "    print(f\"Created folder for run {idx}: {run_folder_path}\")\n",
    "    \n",
    "    return run_folder_path\n",
    "\n",
    "def fine_tune_model_aug_mol(config, stoi, stoi_MF, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "    config, all_gen_smis, aug_mol_df = generate_augmented_molecules_from_aug_mol(config, chunk, idx)\n",
    "    \n",
    "    config.parent_model_save_dir = config.model_save_dir\n",
    "    config.model_save_dir = config.current_run_folder \n",
    "    \n",
    "    if config.execution_type == \"transformer_improvement\":\n",
    "        print(\"\\033[1m\\033[31mThis is: transformer_improvement, sim_data_gen == TRUE\\033[0m\")\n",
    "        config.training_setup = \"pretraining\"\n",
    "        mtf.run_MMT(config, stoi, stoi_MF)\n",
    "    \n",
    "    config.model_save_dir = config.parent_model_save_dir\n",
    "    #config = ex.update_model_path(config)\n",
    "\n",
    "    return config, aug_mol_df, all_gen_smis\n",
    "\n",
    "\n",
    "def generate_augmented_molecules_from_aug_mol(config, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    ############# THis is just relevant for the augmented molecules #############\n",
    "    chunk.rename(columns={'SMILES': 'SMILES_orig', 'SMILES_regio_isomers': 'SMILES'}, inplace=True)\n",
    "    #############################################################################\n",
    "    \n",
    "    script_dir = os.getcwd()\n",
    "    \n",
    "    base_path = os.path.abspath(os.path.join(script_dir, 'deep-molecular-optimization'))\n",
    "\n",
    "    csv_file_path = f'{base_path}/data/MMP/test_selection_2.csv'\n",
    "    chunk.to_csv(csv_file_path, index=False)\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "    config.data_size = len(chunk)\n",
    "    config.n_samples = config.data_size\n",
    "\n",
    "    config, results_dict_MF = generate_smiles_mf(config)\n",
    "\n",
    "    combined_list_MF = process_generated_smiles(results_dict_MF, config)\n",
    "\n",
    "    all_gen_smis = filter_and_combine_smiles(combined_list_MF)\n",
    "\n",
    "    aug_mol_df = create_augmented_dataframe(all_gen_smis)\n",
    "\n",
    "    config, final_df = ex.blend_aug_with_train_data(config, aug_mol_df)\n",
    "\n",
    "    config = ex.gen_sim_aug_data(config, IR_config)\n",
    "    config.execution_type = \"transformer_improvement\"\n",
    "\n",
    "    return config, all_gen_smis, aug_mol_df\n",
    "\n",
    "\n",
    "def fine_tune_model(config, stoi, stoi_MF, chunk, idx):\n",
    "    \"\"\"\n",
    "    Fine-tune the model on a chunk of data.\n",
    "    \"\"\"\n",
    "    config, aug_mol_df, all_gen_smis = generate_augmented_molecules(config, chunk, idx)\n",
    "    \n",
    "    config.parent_model_save_dir = config.model_save_dir\n",
    "    new_model_save_dir = create_model_save_dir(config.parent_model_save_dir, idx)\n",
    "    config.model_save_dir = new_model_save_dir\n",
    "    \n",
    "    # Fine-tune the model\n",
    "    if config.execution_type == \"transformer_improvement\":\n",
    "        print(\"\\033[1m\\033[31mThis is: transformer_improvement, sim_data_gen == TRUE\\033[0m\")\n",
    "        config.training_setup = \"pretraining\"\n",
    "        mtf.run_MMT(config, stoi, stoi_MF)\n",
    "        \n",
    "    #config = ex.update_model_path(config)\n",
    "    config.model_save_dir = config.parent_model_save_dir\n",
    "    \n",
    "    return config, aug_mol_df, all_gen_smis\n",
    "\n",
    "def generate_augmented_molecules(config, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "    script_dir = os.getcwd()\n",
    "    \n",
    "    base_path = os.path.abspath(os.path.join(script_dir, 'deep-molecular-optimization'))\n",
    "\n",
    "    csv_file_path = f'{base_path}/data/MMP/test_selection_2.csv'\n",
    "    chunk.to_csv(csv_file_path, index=False)\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "    config.data_size = len(chunk)\n",
    "    config.n_samples = config.data_size\n",
    "\n",
    "    config, results_dict_MF = generate_smiles_mf(config)\n",
    "\n",
    "    combined_list_MF = process_generated_smiles(results_dict_MF, config)\n",
    "\n",
    "    all_gen_smis = filter_and_combine_smiles(combined_list_MF)\n",
    "\n",
    "    aug_mol_df = create_augmented_dataframe(all_gen_smis)\n",
    "\n",
    "    config, final_df = ex.blend_aug_with_train_data(config, aug_mol_df)\n",
    "\n",
    "    config = ex.gen_sim_aug_data(config, IR_config)\n",
    "    config.execution_type = \"transformer_improvement\"\n",
    "\n",
    "    return config, all_gen_smis, aug_mol_df\n",
    "\n",
    "\n",
    "def generate_smiles_mf(config):\n",
    "    print(\"\\033[1m\\033[31mThis is: SMI_generation_MF\\033[0m\")\n",
    "    return ex.SMI_generation_MF(config, stoi, stoi_MF, itos, itos_MF)\n",
    "\n",
    "def process_generated_smiles(results_dict_MF, config):\n",
    "    results_dict_MF = {key: value for key, value in results_dict_MF.items() if not hf.contains_only_nan(value)}\n",
    "    for key, value in results_dict_MF.items():\n",
    "        results_dict_MF[key] = hf.remove_nan_from_list(value)\n",
    "\n",
    "    combined_list_MF, _, _, _ = cv.plot_cluster_MF(results_dict_MF, config)\n",
    "    return combined_list_MF\n",
    "\n",
    "def filter_and_combine_smiles(combined_list_MF):\n",
    "    print(\"\\033[1m\\033[31mThis is: combine_MMT_MF\\033[0m\")\n",
    "    all_gen_smis = combined_list_MF\n",
    "    all_gen_smis = [smiles for smiles in all_gen_smis if smiles != 'NAN']\n",
    "\n",
    "    val_data = pd.read_csv(config.csv_path_val)\n",
    "    all_gen_smis = mrtf.filter_smiles(val_data, all_gen_smis)\n",
    "    return all_gen_smis\n",
    "\n",
    "def create_augmented_dataframe(all_gen_smis):\n",
    "    length_of_list = len(all_gen_smis)\n",
    "    random_number_strings = [f\"GT_{str(i).zfill(7)}\" for i in range(1, length_of_list + 1)]\n",
    "    return pd.DataFrame({'SMILES': all_gen_smis, 'sample-id': random_number_strings})\n",
    "\n",
    "def setup_data_paths(config):\n",
    "    base_path_acd = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/\"\n",
    "    config.csv_1H_path_ACD = f\"{base_path_acd}ACD_1H_with_SN_filtered_v3.csv\"\n",
    "    config.csv_13C_path_ACD = f\"{base_path_acd}ACD_13C_with_SN_filtered_v3.csv\"\n",
    "    config.csv_HSQC_path_ACD = f\"{base_path_acd}ACD_HSQC_with_SN_filtered_v3.csv\"\n",
    "    config.csv_COSY_path_ACD = f\"{base_path_acd}ACD_COSY_with_SN_filtered_v3.csv\"\n",
    "    config.IR_data_folder_ACD = f\"{base_path_acd}IR_spectra\"\n",
    "    \n",
    "    base_path_exp = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/36_Richard_43_dataset/experimenal_data/\"\n",
    "    config.csv_1H_path_exp = f\"{base_path_exp}real_1H_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_13C_path_exp = f\"{base_path_exp}real_13C_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_HSQC_path_exp = f\"{base_path_exp}real_HSQC_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_COSY_path_exp = f\"{base_path_exp}real_COSY_with_AZ_SMILES_v3.csv\"\n",
    "    config.IR_data_folder_exp = f\"{base_path_exp}IR_data\"\n",
    "    return config\n",
    "\n",
    "def test_model_on_datasets(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, aug_mol_df, all_gen_smis):\n",
    "    checkpoint_path_backup = config.checkpoint_path    \n",
    "    for data_type in ['exp', 'sim', 'ACD', ]:\n",
    "        print(f\"Testing on {data_type} data\")\n",
    "        config.pickle_file_path = \"\"\n",
    "        config.training_mode = \"1H_13C_HSQC_COSY_IR_MF_MW\"\n",
    "        config = test_on_data(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, data_type, aug_mol_df, all_gen_smis)\n",
    "    config.checkpoint_path = checkpoint_path_backup\n",
    "    return config\n",
    "\n",
    "def test_on_data(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, data_type, aug_mol_df, all_gen_smis):\n",
    "    if data_type == 'sim':\n",
    "        restore_backup_configs(config)\n",
    "    else:\n",
    "        sample_ids = chunk['sample-id'].tolist()\n",
    "        process_spectrum_data(config, sample_ids, data_type)\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    update_config_settings(config)\n",
    "    last_checkpoint = get_last_checkpoint(config.current_run_folder)\n",
    "    config.checkpoint_path = last_checkpoint\n",
    "    \n",
    "    model_MMT, val_dataloader, val_dataloader_multi = load_model_and_data(config, stoi, stoi_MF)\n",
    "    \n",
    "    prob_dict_results_1c_, results_dict_1c_ = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "    results = test_model_performance(config, model_MMT, val_dataloader, val_dataloader_multi,\n",
    "                                     stoi, itos, stoi_MF, itos_MF)\n",
    "    \n",
    "    if data_type == 'sim':\n",
    "        results['aug_mol_df'] = aug_mol_df\n",
    "        results['all_gen_smis'] = all_gen_smis\n",
    "    \n",
    "    save_results_acd_exp(results, config, data_type, composite_idx)\n",
    "    return config\n",
    "\n",
    "def restore_backup_configs(config):\n",
    "    config.csv_1H_path_SGNN = config.csv_1H_path_SGNN_backup\n",
    "    config.csv_13C_path_SGNN = config.csv_13C_path_SGNN_backup\n",
    "    config.csv_HSQC_path_SGNN = config.csv_HSQC_path_SGNN_backup\n",
    "    config.csv_COSY_path_SGNN = config.csv_COSY_path_SGNN_backup\n",
    "    config.IR_data_folder = config.IR_data_folder_backup \n",
    "    config.csv_path_val = config.csv_1H_path_SGNN_backup\n",
    "    config.pickle_file_path = \"\"\n",
    "\n",
    "def process_spectrum_data(config: Any, sample_ids: List[str], data_type: str) -> None:\n",
    "    spectrum_types = ['1H', '13C', 'HSQC', 'COSY']\n",
    "    for spectrum in spectrum_types:\n",
    "        csv_path = getattr(config, f'csv_{spectrum}_path_{data_type}')\n",
    "        df_data = pd.read_csv(csv_path)\n",
    "        df_data['sample-id'] = df_data['AZ_Number']\n",
    "        data = select_relevant_samples(df_data, sample_ids)\n",
    "        dummy_path, config = save_and_update_config(config, data_type, spectrum, data)\n",
    "        print(f\"Saved {spectrum} data to: {dummy_path}\")\n",
    "    if data_type == \"ACD\" or data_type == \"sim\":\n",
    "        config.IR_data_folder = config.IR_data_folder_backup \n",
    "    elif  data_type == \"exp\":\n",
    "        config.IR_data_folder = config.IR_data_folder_exp \n",
    "\n",
    "    \n",
    "    \n",
    "def select_relevant_samples(df: pd.DataFrame, sample_ids: List[str]) -> pd.DataFrame:\n",
    "    return df[df['sample-id'].isin(sample_ids)]\n",
    "\n",
    "def save_and_update_config(config, data_type: str, spectrum_type: str, data: pd.DataFrame) -> Tuple[str, Any]:\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    dummy_path = os.path.join(temp_dir, f\"{data_type}_{spectrum_type}_selected_samples.csv\")\n",
    "    \n",
    "    data.to_csv(dummy_path, index=False)\n",
    "    \n",
    "    config_key = f'csv_{spectrum_type}_path_SGNN'\n",
    "    setattr(config, config_key, dummy_path)\n",
    "    \n",
    "    return dummy_path, config\n",
    "\n",
    "def update_config_settings(config: Any) -> None:\n",
    "    config.csv_path_val = config.csv_1H_path_SGNN\n",
    "    config.pickle_file_path = \"\"\n",
    "\n",
    "def get_last_checkpoint(model_folder: str) -> str:\n",
    "    checkpoints = [f for f in os.listdir(model_folder) if f.endswith('.ckpt')]\n",
    "    if not checkpoints:\n",
    "        raise ValueError(f\"No checkpoints found in {model_folder}\")\n",
    "    \n",
    "    last_checkpoint = max(checkpoints, key=lambda x: os.path.getmtime(os.path.join(model_folder, x)))\n",
    "    return os.path.join(model_folder, last_checkpoint)\n",
    "\n",
    "def load_model_and_data(config: Any, stoi: Dict, stoi_MF: Dict) -> Tuple[Any, Any, Any]:\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    return model_MMT, val_dataloader, val_dataloader_multi\n",
    "\n",
    "def test_model_performance(config: Any, model_MMT: Any, val_dataloader: Any, val_dataloader_multi: Any, \n",
    "                           stoi: Dict, itos: Dict, stoi_MF: Dict, itos_MF: Dict) -> Dict[str, Any]:\n",
    "    print(\"\\033[1m\\033[31mThis is: test_performance\\033[0m\")\n",
    "    \n",
    "    MW_filter = True\n",
    "    greedy_full = False\n",
    "    \n",
    "    model_CLIP = mrtf.load_CLIP_model(config)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['results_dict_bl_ZINC_'] = mrtf.run_test_mns_performance_CLIP_3(\n",
    "        config, model_MMT, model_CLIP, val_dataloader, stoi, itos, MW_filter)\n",
    "    results['results_dict_bl_ZINC_'], counter = mrtf.filter_invalid_inputs(results['results_dict_bl_ZINC_'])\n",
    "\n",
    "    results['avg_tani_bl_ZINC_'], html_plot = rbgvm.plot_hist_of_results(results['results_dict_bl_ZINC_'])\n",
    "\n",
    "    if greedy_full:\n",
    "        results['results_dict_greedy_bl_ZINC_'], results['failed_bl_ZINC_'] = mrtf.run_test_performance_CLIP_greedy_3(\n",
    "            config, stoi, stoi_MF, itos, itos_MF)\n",
    "        results['avg_tani_greedy_bl_ZINC_'], html_plot_greedy = rbgvm.plot_hist_of_results_greedy(\n",
    "            results['results_dict_greedy_bl_ZINC_'])\n",
    "    else:\n",
    "        config, results['results_dict_ZINC_greedy_bl_'] = mrtf.run_greedy_sampling(\n",
    "            config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "        results['avg_tani_greedy_bl_ZINC_'] = results['results_dict_ZINC_greedy_bl_'][\"tanimoto_mean\"]\n",
    "\n",
    "    results['total_results_bl_ZINC_'] = mrtf.run_test_performance_CLIP_3(\n",
    "        config, model_MMT, val_dataloader, stoi)\n",
    "    results['corr_sampleing_prob_bl_ZINC_'] = results['total_results_bl_ZINC_'][\"statistics_multiplication_avg\"][0]\n",
    "\n",
    "    print(\"avg_tani, avg_tani_greedy, corr_sampleing_prob'\")\n",
    "    print(results['avg_tani_bl_ZINC_'], results['avg_tani_greedy_bl_ZINC_'], results['corr_sampleing_prob_bl_ZINC_'])\n",
    "    print(\"Greedy tanimoto results\")\n",
    "    rbgvm.plot_hist_of_results_greedy_new(results['results_dict_ZINC_greedy_bl_'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_results_acd_exp(results: Dict[str, Any], config: Any, data_type: str, composite_idx: str) -> None:\n",
    "    variables_to_save = {\n",
    "        'avg_tani_bl_ZINC': results['avg_tani_bl_ZINC_'],\n",
    "        'results_dict_greedy_bl_ZINC': results.get('results_dict_greedy_bl_ZINC_'),\n",
    "        'failed_bl_ZINC': results.get('failed_bl_ZINC_'),\n",
    "        'avg_tani_greedy_bl_ZINC': results['avg_tani_greedy_bl_ZINC_'],\n",
    "        'results_dict_ZINC_greedy_bl': results.get('results_dict_ZINC_greedy_bl_'),\n",
    "        'total_results_bl_ZINC': results['total_results_bl_ZINC_'],\n",
    "        'corr_sampleing_prob_bl_ZINC': results['corr_sampleing_prob_bl_ZINC_'],\n",
    "        'results_dict_bl_ZINC': results['results_dict_bl_ZINC_'],\n",
    "        'checkpoint_path': config.checkpoint_path,\n",
    "    }\n",
    "    \n",
    "    if data_type == 'sim':\n",
    "        variables_to_save['aug_mol_df'] = results.get('aug_mol_df')\n",
    "        variables_to_save['all_gen_smis'] = results.get('all_gen_smis')\n",
    "    \n",
    "    save_data_with_datetime_index(\n",
    "        variables_to_save, \n",
    "        config.pkl_save_folder, \n",
    "        f\"{data_type}_sim_data\", \n",
    "        composite_idx\n",
    "    )\n",
    "\n",
    "def save_data_with_datetime_index(data: Any, base_folder: str, name: str, idx: Union[int, str]) -> None:\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{current_datetime}_{name}_{idx}.pkl\"\n",
    "    os.makedirs(base_folder, exist_ok=True)\n",
    "    file_path = os.path.join(base_folder, filename)\n",
    "    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    \n",
    "    print(f\"Data saved to: {file_path}\")\n",
    "\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Union, Tuple\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "def load_model_and_data(config: Any, stoi: Dict, stoi_MF: Dict) -> Tuple[Any, Any, Any]:\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    return model_MMT, val_dataloader, val_dataloader_multi\n",
    "\n",
    "def run_base_model(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF):\n",
    "    chunks = split_dataset(config, chunk_size)\n",
    "    config.model_save_dir = config.pkl_save_folder\n",
    "    model_save_dir_backup = config.model_save_dir\n",
    "    original_checkpoint_path = config.checkpoint_path  # Store the original checkpoint path\n",
    "\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {chunk_idx+1} of {len(chunks)}\")\n",
    "        \n",
    "        chunk_folder = create_chunk_folder(config, chunk_idx)\n",
    "        config.current_chunk_folder = chunk_folder\n",
    "            \n",
    "        config.blank_percentage = 0\n",
    "        config = test_pretrained_model_on_sim_data_before(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, f\"{chunk_idx}_{0}\")\n",
    "        print(config.csv_1H_path_SGNN)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        \n",
    "    config.SGNN_csv_gen_smi = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8_4000.csv'\n",
    "    config.pkl_save_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350_4000\"\n",
    "    config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "\n",
    "    config.data_size = 4000 # config.test_size # why would I do that? \n",
    "    #config.data_size = 4 # config.test_size # why would I do that? \n",
    "    config.execution_type = \"test_performance\"\n",
    "    config.multinom_runs = 10\n",
    "    #config.multinom_runs = 3\n",
    "    config.temperature = 1\n",
    "    greedy_full = False\n",
    "    MW_filter = True\n",
    "    #config.MF_generations = 10\n",
    "    chunk_size = 1\n",
    "    run_base_model(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a433a-7fa6-46a4-8ebf-835f2a99eb05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NMR_Structure_Elucidator] *",
   "language": "python",
   "name": "conda-env-NMR_Structure_Elucidator-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
