{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783e8f12-1f7a-4740-aac5-894149d9206c",
   "metadata": {},
   "source": [
    "# MultiModalSpectralTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779aadf-b0c6-4bf6-b32a-abc49525adf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e66ba-6380-495d-85ee-77c059e16955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Pastel color palette hex codes\n",
    "pastel_colors = [\n",
    "    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "]\n",
    "\n",
    "# Create sample data\n",
    "categories = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "values = np.random.randint(10, 50, size=10)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(categories, values)\n",
    "\n",
    "# Set each bar's color according to the pastel palette\n",
    "for bar, color in zip(bars, pastel_colors):\n",
    "    bar.set_color(color)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Sample Bar Plot with Pastel Colors', pad=20, size=14)\n",
    "plt.xlabel('Categories', labelpad=10)\n",
    "plt.ylabel('Values', labelpad=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21655d8d-f368-4840-b1a9-1a6edf142712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83b4aa1a-82fc-4f5c-b758-1a6506e111e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53559a93-de37-4548-b701-32b47773af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Core libraries\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import copy\n",
    "import statistics\n",
    "\n",
    "# Data processing and scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine learning and data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# RDKit for cheminformatics\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Draw, MolFromSmiles, MolToSmiles\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# tqdm for progress bars\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "\n",
    "# Miscellaneous\n",
    "from argparse import Namespace\n",
    "from IPython.display import HTML, SVG\n",
    "\n",
    "# Setting up environment\n",
    "torch.cuda.device_count()\n",
    "wandb.login()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "from rdkit.Chem.Descriptors import MolWt\n",
    "from rdkit import DataStructs\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f060d7-45cf-4fbc-8566-6b345218914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.profiler import SimpleProfiler, AdvancedProfiler\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f872931-34bf-4b5b-916d-31c75e8feeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_MMT.clip_functions_v15_4 as cf #\n",
    "import utils_MMT.MT_functions_v15_4 as mtf # is different compared to V14_1\n",
    "import utils_MMT.validate_generate_MMT_v15_4 as vgmmt #\n",
    "import utils_MMT.run_batch_gen_val_MMT_v15_4 as rbgvm #\n",
    "import utils_MMT.clustering_visualization_v15_4 as cv #\n",
    "import utils_MMT.plotting_v15_4 as pt #\n",
    "import utils_MMT.execution_function_v15_4 as ex #\n",
    "import utils_MMT.train_test_functions_pl_v15_4 as ttf\n",
    "import utils_MMT.ir_simulation_v15_4 as irs\n",
    "import utils_MMT.helper_functions_pl_v15_4 as hf\n",
    "import utils_MMT.mmt_result_test_functions_15_4 as mrtf\n",
    "###\n",
    "import utils_MMT.experiment_function_v15_4 as exp_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4926683-d6e8-4a21-997e-e79d3de41c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_json_dics():\n",
    "    with open('./itos.json', 'r') as f:\n",
    "        itos = json.load(f)\n",
    "    with open('./stoi.json', 'r') as f:\n",
    "        stoi = json.load(f)\n",
    "    with open('./stoi_MF.json', 'r') as f:\n",
    "        stoi_MF = json.load(f)\n",
    "    with open('./itos_MF.json', 'r') as f:\n",
    "        itos_MF = json.load(f)    \n",
    "    return itos, stoi, stoi_MF, itos_MF\n",
    "    \n",
    "itos, stoi, stoi_MF, itos_MF = load_json_dics()\n",
    "rand_num = str(random.randint(1, 10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542a9e5-88cb-4f17-9c08-3cc1936a99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_config_dict = {\n",
    "    \"gpu\": list(range(torch.cuda.device_count())),  # Default value is None, should be one of the available GPU indices\n",
    "    \"test_path\": [\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/chemprop-IR/ir_models_data/solvation_example/solvation_spectra.csv\"],  # Default value is None\n",
    "    \"use_compound_names\": [False],  # Default is False\n",
    "    \"preds_path\": [\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/chemprop-IR/ir_models_data/ir_preds_test_2.csv\"],  # Default value is None\n",
    "    \"checkpoint_dir\": [\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/chemprop-IR/ir_models_data/experiment_model/model_files\"],  # Default value is None\n",
    "    \"spectra_type\": [\"experimental\"],  # [\"experimental\", \"simulated\"] Default value is None\n",
    "    \"spectra_type_nr\": [0],  # 0-4 Default value is None\n",
    "    \"checkpoint_path\": [None],  # Default value is None\n",
    "    \"batch_size\": [64],  # Default is 50\n",
    "    \"no_cuda\": [False],  # Default is False\n",
    "    \"features_generator\":[None],  # Default value is None, should be one of the available features generators\n",
    "    \"features_path\": [None],  # Default value is None\n",
    "    \"max_data_size\": [100],  # Default value is None\n",
    "    \"ensemble_variance\": [False],  # Default is False\n",
    "    \"ensemble_variance_conv\": [0.0],  # Default is 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d55c1b-c8c7-4d35-90e9-4123b9a8a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    # General project information\n",
    "    \"project\": [\"Improv_Cycle_v1\"],  # Name of the project for wandb monitoring\n",
    "    \"ran_num\":[rand_num],\n",
    "    \"device\": [\"cuda\"], # device on which training takes place\n",
    "    \"gpu_num\":[1], # number of GPUs for training with pytorch lightning\n",
    "    \"num_workers\":[4], # Needs to stay 1 otherwise code crashes - ToDO\n",
    "    \"data_type\":[\"sgnn\"], #[\"sgnn\", \"exp\", \"acd\", \"real\", \"inference\"], Different data types to select\n",
    "    \"execution_type\":[\"validate_MMT\"], #[ \"plot_similarities\", \"simulate_real\", \"test_performance\", \"SMI_generation_MMT\", \"SMI_generation_MF\", \"data_generation\", \"transformer_training\",\"transformer_improvement\", \"clip_training\", \"clip_improvement\", \"validate_MMT\"] # different networks to select for training\n",
    "    \"syn_data_simulated\": [False],  # For the improvment cycle a ticker that shows whether data has been simulated or not.\n",
    "    \"training_type\":[\"clip\"], #[\"clip\",\"transformer\"] # different networks to select for training\n",
    "\n",
    "    # Encoding dicts\n",
    "    \"itos_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/itos.json\"],\n",
    "    \"stoi_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/stoi.json\"],\n",
    "    \"itos_MF_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/itos_MF.json\"],\n",
    "    \"stoi_MF_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/stoi_MF.json\"],\n",
    "    \n",
    "    ### Data settings\n",
    "    \"input_dim_1H\":[2], # Imput dimensions of the 1H data\n",
    "    \"input_dim_13C\": [1], # Imput dimensions of the 13C data\n",
    "    \"input_dim_HSQC\": [2], # Imput dimensions of the HSQC data\n",
    "    \"input_dim_COSY\": [2],  # Imput dimensions of the COSY data\n",
    "    \"input_dim_IR\": [1000],  # Imput dimensions of the IR data\n",
    "    \"MF_vocab_size\": [len(stoi_MF)],  # New, size of the vocabulary for molecular formulas\n",
    "    \"MS_vocab_size\": [len(stoi)],  # New, size of the vocabulary for molecular formulas\n",
    "    \"tr_te_split\":[0.9], # Train-Test split\n",
    "    \"padding_points_number\":[64], # Padding number for the embedding layer into the network\n",
    "    \"data_size\": [1000], # number of datapoints for the training 3975764/1797828\n",
    "    \"test_size\": [10], # number of datapoints for the training 3975764\n",
    "    \"model_save_dir\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/test\"], # Folder where networks are saved\n",
    "    \"ML_dump_folder\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/dump\"], # a folder where intermediate files for the SGNN network are generated\n",
    "    \"model_save_interval\": [10000], # seconds passed until next model is saved\n",
    "    \n",
    "    # Option 1 SGNN\n",
    "    \"use_real_data\":[False], #[True, False]\n",
    "    \"ref_data_type\":[\"1H\"], #[\"1H\",\"13C\",\"HSQC\",\"COSY\",\"IR\"]\n",
    "    \"csv_train_path\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_train_V8.csv'], # To keep a reference of the compounds that it was trained on\n",
    "    \"csv_1H_path_SGNN\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_train_V8.csv'],\n",
    "    \"csv_13C_path_SGNN\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_13C.csv'],    \n",
    "    \"csv_HSQC_path_SGNN\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_HSQC.csv'],    \n",
    "    \"csv_COSY_path_SGNN\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_COSY.csv'],      \n",
    "    \"csv_IR_MF_path\": [''],     #571124\n",
    "    \"csv_path_val\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8.csv'], #63459   \n",
    "    #\"IR_data_folder\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"],\n",
    "    \"IR_data_folder\": [\"\"],\n",
    "\n",
    "   # \"pickle_file_path\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_V8_938756.pkl\"],\n",
    "    \"pickle_file_path\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8_355655.pkl\"],\n",
    "    \n",
    "    \"dl_mode\": ['val'], #[\"val\",\"train\"]   \n",
    "    \"isomericSmiles\": [False], # whether stereochemistry is considered or not\n",
    "    \n",
    "    # Option 2 exp\n",
    "    #\"exp_path\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/missing_ZINC_files.csv'], #63459   \n",
    "\n",
    "     # Option 2 ACD\n",
    "    #\"csv_path_1H_ACD\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/1H_ZINC_XL_v3.csv'],\n",
    "    #\"data_folder_HSQC_ACD\": [\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/zinc250k\"],\n",
    "    # Option 3 real\n",
    "    \"comparision_number\": [1000],  # With how many of the training examples should it be compared with in a t-SNE plot\n",
    "    \"vector_db\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/smiles_fingerprints_train_4M_v1.csv'],    \n",
    "    \"secret_csv_SMI_vectors\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/25_Test_Improvement_cycle/1_Test_ZINC_250/test_32_zinc250_vec_db.csv'],    \n",
    "    \"secret_csv_SMI_targets\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/25_Test_Improvement_cycle/1_Test_ZINC_250/test_32_zinc250.csv'],    \n",
    "    \"secret_csv_SMI_sim_searched\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/25_Test_Improvement_cycle/1_Test_ZINC_250/test_32_zinc250.csv'],    \n",
    "    \"csv_SMI_targets\": ['/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/25_Test_Improvement_cycle/1_Test_ZINC_250/test_32_zinc250_single_target_919.csv'],\n",
    "    \"csv_1H_path_REAL\": [''],\n",
    "    \"csv_13C_path_REAL\": [''],    \n",
    "    \"csv_HSQC_path_REAL\": [''],    \n",
    "    \"csv_COSY_path_REAL\": [''],    \n",
    "    #\"pkl_path_HSQC_real\": [\"\"],\n",
    "\n",
    "    #### Transformer Settings ####\n",
    "    # Training and model settings\n",
    "    \"training_mode\":[\"1H_13C_HSQC_COSY_IR_MF_MW\"], #[\"edding_src_1H = torch.zeros((feature_dim, current_ba\"], Modalities selected for training\n",
    "    \"blank_percentage\":[0.0], # percentage of spectra that are blanked out during training for better generalizability of the network to various datatypes\n",
    "    \"batch_size\":[64], # number needs to be the same as number of GPUs \n",
    "    \"num_epochs\": [10], # number of epochs for training\n",
    "    \"lr_pretraining\": [1e-4], # Pretraining learning rate\n",
    "    \"lr_finetuning\": [5e-5], # Finetuning learning rate\n",
    "    \"load_model\": [True], # if model should be loaded from path\n",
    "    \"checkpoint_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW_Drop/MultimodalTransformer_time_1704760608.6927748_Loss_0.137.ckpt\"], #V8\n",
    "    \"save_model\": [True], # if model should be saved\n",
    "    \n",
    "    # Model architecture\n",
    "    \"in_size\": [len(stoi)],\n",
    "    \"hidden_size\": [128],\n",
    "    \"out_size\": [len(stoi)],\n",
    "    \"num_encoder_layers\": [6], #8\n",
    "    \"num_decoder_layers\": [6], #8\n",
    "    \"num_heads\": [16], #8  ### number of attention heads\n",
    "    \"forward_expansion\": [4], #4\n",
    "    \"max_len\": [128], # maximum length of the generated sequence\n",
    "    \"drop_out\": [0.1],\n",
    "    \"fingerprint_size\": [512], # Dimensions of encoder output for CLIP contrastive training    \n",
    "    \"gen_SMI_sequence\":[True], # If the model generates a sequence with the SMILES current model for evaluation\n",
    "    \"sampling_method\":[\"mix\"], # weight_mol_weight [\"multinomial\", \"greedy\". \"mix\"]  \n",
    "    \"training_setup\":[\"pretraining\"], # [\"pretraining\",\"finetuning\"]\n",
    "    \"smi_randomizer\":[False], # if smiles are randomized or canonical during training\n",
    "    \n",
    "    ### SGNN Feedback\n",
    "    \"sgnn_feedback\":[False], # if SGNN generates 1H and 13C spectrum on the fly on the generated smiles -> \"gen_SMI_sequence\":[True]\n",
    "    \"matching\":[\"HungDist\"], #[\"MinSum\",\"EucDist\",\"HungDist\"], # HSQC point matching technique used\n",
    "    \"padding\":[\"NN\"], # [\"Zero\",\"Trunc\",\"NN\"], # HSQC padding technique used -> see publication: XXX\n",
    "    # Weight feedback\n",
    "    \"train_weight_min\":[None], # Calculate on the fly - Used for the weight loss calculation for scaling\n",
    "    \"train_weight_max\":[None], # Calculate on the fly - Used for the weight loss calculation for scaling\n",
    "    # Training Loss Weighting options\n",
    "    \"weight_validity\": [0.0], # up to 1\n",
    "    \"weight_SMI\": [1.0], # up to 1\n",
    "    \"weight_FP\": [0.0], # up to 1\n",
    "    \"weight_MW\": [0], # up to 100\n",
    "    \"weight_sgnn\": [0.0], # up to 10\n",
    "    \"weight_tanimoto\": [0.0], # up to 1\n",
    "    \"change_loss_weights\":[False], # if selected the weights get ajusted along the training\n",
    "    \"increment\":[0.01], # increment on how much it gets ajusted during training -> TODO\n",
    "    \"batch_frequency\":[10000], # Frequency how often it gets ajusted -> TODO\n",
    "    \n",
    "    ### For Validation\n",
    "    \"beam_size\": [1],  \n",
    "    \"multinom_runs\": [1], \n",
    "    \"temperature\":[1],\n",
    "    \"gen_len\":[64],\n",
    "    \"pkl_save_folder\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/pkl_save_folder\"],\n",
    "    \n",
    "    ### Molformer options \n",
    "    \"MF_max_trails\":[500],\n",
    "    \"MF_tanimoto_filter\":[0.1],\n",
    "    \"MF_filter_higher\":[1], # False = 0 True = 1\n",
    "    \"MF_delta_weight\":[5],\n",
    "    \"MF_generations\":[30],\n",
    "    \"MF_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/deep-molecular-optimization/experiments/trained/Alessandro_big/weights_pubchem_with_counts_and_rank_sanitized.ckpt\"],\n",
    "    \"MF_vocab\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/deep-molecular-optimization/experiments/trained/Alessandro_big/vocab_new.pkl\"],\n",
    "    \"MF_csv_source_folder_location\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/deep-molecular-optimization/data/MMP\"],\n",
    "    \"MF_csv_source_file_name\":[\"test_selection_2\"],\n",
    "    \"MF_methods\":[\"MMP\"], #[\"MMP\", \"scaffold\", \"MMP_scaffold\"],    \n",
    "    \"max_scaffold_generations\":[10], #\n",
    "    \n",
    "    ### MMT batch generation\n",
    "    \"MMT_batch\":[32], # how big is the batch of copies of the same inputs that is processed by MMT \n",
    "    \"MMT_generations\":[4], # need to be multiple of MMT_batch -> number of valid generated molecules\n",
    "    #------------------------\n",
    "    \"n_samples\":[10], # number of molecules that should be processed for data generation - needs to be smaller than dataloader size\n",
    "    \"gen_mol_csv_folder_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2\"], # number of molecules that should be processed for data generation - needs to be smaller than dataloader size\n",
    "    \n",
    "    ### Fine-tuning improvement options\n",
    "    \"train_data_blend\":[0], # how many additional molecules should be added to the new dataset from the original training dataset\n",
    "    \"train_data_blend_CLIP\":[1000], # how many additional molecules should be added to the new dataset from the original training dataset\n",
    "    \n",
    "    ### Data generation SGNN -> 1H, 13C, HSQC, COSY\n",
    "    \"SGNN_gen_folder_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2/dump_2\"],\n",
    "    \"SGNN_csv_gen_smi\":[\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalSpectralTransformer/deep-molecular-optimization/data/MMP/test_selection_1.csv\"],\n",
    "    \"SGNN_size_filter\":[550],\n",
    "    \"SGNN_csv_save_folder\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2\"],\n",
    "    \"IR_save_folder\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2/IR_data\"],\n",
    "    \n",
    "    #################################################\n",
    "    #### LEGACY parameters for other expeirments ####\n",
    "    #################################################\n",
    "    #### CLIP Settings ####\n",
    "    ### ChemBerta\n",
    "    \"model_version\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v1/Chemberta_source\"],   # Source of pretrained chemberta from paper\n",
    "    \"CB_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v1/Large_300_15.pth\"], # path to pretrained Chemberta model\n",
    "    \"num_class\":[1024], #\n",
    "    \"num_linear_layers\":[0], # number of linear layers in architecture before num_class output\n",
    "    \"use_dropout\":[True],\n",
    "    \"use_relu\":[False],\n",
    "    \"loss_fn\":[\"BCEWithLogitsLoss\"], #\"MSELoss\", \"BCELoss\", \n",
    "    \"CB_embedding\": [1024], #1024\n",
    "    # PCA\n",
    "    \"fp_dim_reduction\":[False], #True\n",
    "    \"pca_components\":[300],  \n",
    "    #\"CB_model_name\": [\"Large_300_15\"],\n",
    "\n",
    "    ### Multimodal Transformer\n",
    "    \"MT_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW2_Drop/MultimodalTransformer_time_1706856620.3718672_Loss_0.202.pth\"],  # path to pretrained Multimodal Transformer model  \n",
    "    #\"MT_model_name\": [\"SpectrumBERT_PCA_large_3.6\"],\n",
    "    \"MT_embedding\": [512], #512\n",
    "    ### Projection Head\n",
    "    \"projection_dim\": [512],\n",
    "    \"dropout\": [0.1],\n",
    "    \n",
    "    #CLIP\n",
    "    # Dataloader settings\n",
    "    \"similarity_threshold\":[0.6], # Filtere that selects just molecules with a tanimotosimilarity higher than that number\n",
    "    \"max_search_size\":[10000], # Size of the data that will be searched to find the similar molecules  # 100000\n",
    "    \"weight_delta\":[50], # Filter to molecules with a +/- delta weight of that numbeTraceback (most recent call last):\n",
    "    \"CLIP_batch_size\":[128],  #,64,128,256 ### batch size for the CLIP training\n",
    "    \"CLIP_NUM_EPOCHS\": [10],    # Number of training epochs\n",
    "    \n",
    "    ### Train parameters\n",
    "    ### CLIP Model   \n",
    "    \"CLIP_temperature\": [1],\n",
    "    #\"CB_projection_lr\": [1e-3], # projection head learning rate for Chemberta\n",
    "    \"MT_projection_lr\": [1e-3], # projection head learning rate for Multimodal Transfomer\n",
    "    \"CB_lr\": [1e-4], # Chemberta Learning Rate\n",
    "    \"MT_lr\": [1e-5], # Multimodal Transfomer Learning Rate\n",
    "    \"weight_decay\": [1e-3], # Weight decay for projection heads -> TODO why just on those\n",
    "    \"patience\": [1],   # not integrated yet\n",
    "    \"factor\": [0.8],   # not integrated yet\n",
    "    \"CLIP_continue_training\":[True],\n",
    "    \"CLIP_model_path\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_modalities_CLIP_1_dot_product/MultimodalCLIP_Epoch_9_Loss0.096.ckpt\"],   \n",
    "    \"CLIP_model_save_dir\":[\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/test_CLIP\"],\n",
    "    \n",
    "    ### BLIP Model\n",
    "    \"BLIP_temperature\": [1],\n",
    "    \"Qformer_lr\":[1e-4],\n",
    "    \"Qformer_CB_lr\":[1e-4],\n",
    "    \"Qformer_MT_lr\":[1e-4],\n",
    "    \"BLIP_continue_training\":[True],\n",
    "    # \"BLIP_model_path\":[\"/projects/cc/se_users/knlr326//knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/test_BLIP_1M/model_BLIP-epoch=03-loss=2.54_v0.ckpt\"],   \n",
    "    # \"BLIP_model_save_dir\":[\"/projects/cc/se_users/knlr326//knlr326//knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/test_BLIP_1M\"],\n",
    "    \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c4877-1bd0-478d-8565-b2571b139e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_config(config, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(config, f)\n",
    "\n",
    "def load_config(path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return None    \n",
    "\n",
    "def parse_arguments(hyperparameters):\n",
    "    # Using dictionary comprehension to simplify your code\n",
    "    parsed_args = {key: val[0] for key, val in hyperparameters.items()}\n",
    "    return Namespace(**parsed_args)\n",
    "\n",
    "\n",
    "config = parse_arguments(hyperparameters)\n",
    "ir_config_path = './utils_MMT/ir_config_V8.json'\n",
    "save_config(IR_config_dict, ir_config_path)\n",
    "IR_config_dict = load_config(ir_config_path)\n",
    "IR_config = parse_arguments(IR_config_dict)\n",
    "irs.modify_predict_args(IR_config)\n",
    "\n",
    "\n",
    "config_path = './utils_MMT/config_V8.json'\n",
    "save_config(hyperparameters, config_path)\n",
    "config_dict = load_config(config_path)\n",
    "config = parse_arguments(config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd59e1-d552-4ae7-ad03-4319b9578452",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### 0.0 Test Sized Models and Different Training Data (Model with IR as data input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dcca10-cdf1-42ef-a1ca-84eb97a84632",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Data size effect - Training times effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37bc21-3b7d-4a24-bf22-00bcdf98feba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# V8 Raw 1M\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_1Mio/model-epoch=07-loss=0.10.ckpt\"\n",
    "#same batches as 20M mol seen\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_1Mio/model-epoch=19-loss=0.04.ckpt\"\n",
    "\n",
    "\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_0a, results_dict_0a = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "print(np.mean(results_dict_0a[\"tanimoto_sim\"]))\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "#file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_1M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_1M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_0a, file)\n",
    "    \n",
    "\n",
    "# Save the data to a file\n",
    "#file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_1M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_1M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_0a, file)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb768f9-5cbe-44ad-8c03-4af77b62807b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# V8 Raw 2M\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_2Mio/model-epoch=07-loss=0.06.ckpt\"\n",
    "#same batches as 20M mol seen\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326//knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_2Mio/model-epoch=09-loss=0.04.ckpt\"\n",
    "\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_0b, results_dict_0b = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "print(np.mean(results_dict_0b[\"tanimoto_sim\"]))\n",
    "\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "#file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_2M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_2M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_0b, file)\n",
    "    \n",
    "\n",
    "# Save the data to a file\n",
    "#file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_2M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_2M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_0b, file)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea2fae-6623-432a-bc5d-bd205d51a422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# V8 Raw 4M\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_4Mio/model-epoch=07-loss=0.02.ckpt\"\n",
    "#same batches as 20M mol seen\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_4Mio/model-epoch=04-loss=0.04.ckpt\"\n",
    "\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_0b, results_dict_0b = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "#file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_4M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_4M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_0b, file)\n",
    "    \n",
    "\n",
    "# Save the data to a file\n",
    "#file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_4M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_4M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_0b, file)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a93fdc-2469-41fe-b54b-139dcc0c3950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e3171d-c1ed-407c-97de-6cebf9c69426",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Load saved data - EPOCH 7\n",
    "- Different data sizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a454ad-a287-4553-afe1-664e6f9b387b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Epoch 7 for all molecules seen\n",
    "\n",
    "import pickle\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240430_Epoch_7/0.0_prob_dict_results_4M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0a = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240430_Epoch_7/0.1_results_dict_4M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0a = pickle.load(file)\n",
    "\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240430_Epoch_7/0.0_prob_dict_results_2M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0b = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240430_Epoch_7/0.1_results_dict_2M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0b = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240430_Epoch_7/0.0_prob_dict_results_1M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0c = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240430_Epoch_7/0.1_results_dict_1M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0c = pickle.load(file)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02307452-a72f-430f-8a40-3e8456d18bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### add 0.1M to this one \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240430_Epoch_7/0.0_prob_dict_results_0.1M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0d = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240430_Epoch_7/0.1_results_dict_0.1M_L_epoch_7.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0d = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084f729-a343-4f58-9ce2-3c5edd4ddbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prob_dict_results_2 = [ prob_dict_results_0c, prob_dict_results_0b, prob_dict_results_0a]\n",
    "results_dict_2 = [results_dict_0c, results_dict_0b, results_dict_0a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de76ab-da30-413e-a0ae-88fdff73f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prob_dict_results_2 = [ prob_dict_results_0d, prob_dict_results_0c, prob_dict_results_0b, prob_dict_results_0a]\n",
    "results_dict_2 = [results_dict_0d, results_dict_0c, results_dict_0b, results_dict_0a]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff15fe-21e6-4fc1-8e37-15855bc62b0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Violin Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf15905-ac21-4554-9414-0f2cb7f5c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['0.1M Epoch 7', '1M Epoch 7', '2M Epoch 7', '4M Epoch 7']\n",
    "prob_dict_results_2 = [ prob_dict_results_0d, prob_dict_results_0c, prob_dict_results_0b, prob_dict_results_0a]\n",
    "\n",
    "# Calculate mean and standard deviation for each dictionary\n",
    "mean_results = []\n",
    "std_results = []\n",
    "data_for_violin = []\n",
    "for prob_dict in prob_dict_results_2:\n",
    "    mean_prob = np.mean(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "    mean_results.append(mean_prob)\n",
    "    std_value = statistics.stdev(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "    std_results.append(std_value)\n",
    "    data_for_violin.append(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors\n",
    "color = '#A1C8F3'  # Use a single color for all the violin plots\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title('Correct SMILES Sample Probability', fontsize=22)\n",
    "#ax.set_xlabel('Trained Model', fontsize=16)\n",
    "ax.set_ylabel('Probability of Correct SMILES', fontsize=22)\n",
    "ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "\n",
    "mean_values = [np.mean(data) if data is not None else 0 for data in data_for_violin]\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in zip(np.arange(1, len(mean_values) + 1), mean_values):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Adding a legend\n",
    "lightseagreen_patch = plt.Line2D([0], [0], color='lightseagreen', lw=4, label='MMST')\n",
    "#ax.legend(handles=[lightseagreen_patch], loc='upper left', fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)  # Adjust based on your data's range\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.0_Violin_Epoch_7_v3.png'  # Replace with your desired path\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b8491-3db5-4899-9676-3348006bc520",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Tanimoto Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e152d-68f4-408b-9f43-36785b69660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_2 = [results_dict_0c, results_dict_0b, results_dict_0a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ee850-581d-472f-92e4-96bd89893a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample input data\n",
    "#labels = ['MMTi \\n0.1 Mol - 20M', 'MMTi \\n1 Mol - 20M', 'MMTi \\n2 Mol - 20M', 'MMTi \\n4 Mol - 20M']\n",
    "#results_dict_2 = [results_dict_0e, results_dict_0c, results_dict_0b, results_dict_0a]\n",
    "\n",
    "labels = ['0.1M Epoch 7', '1M Epoch 7', '2M Epoch 7', '4M Epoch 7']\n",
    "results_dict_2 = [results_dict_0d,results_dict_0c, results_dict_0b, results_dict_0a]\n",
    "\n",
    "\n",
    "#labels = ['MMTi \\n0.1 Mol - 20M', 'MMTi \\n0.5 Mol - 20M', 'MMTi \\n1 Mol - 20M', 'MMTi \\n2 Mol - 20M', 'MMTi \\n4 Mol - 20M']\n",
    "#results_dict_2 = [results_dict_0e, results_dict_0d, results_dict_0c, results_dict_0b, results_dict_0a]\n",
    "\n",
    "# Prepare data\n",
    "data_for_violin = [d[\"tanimoto_sim\"] for d in results_dict_2]\n",
    "\n",
    "# Calculate means for each dataset\n",
    "mean_values = [np.mean(data) for data in data_for_violin]\n",
    "\n",
    "# Labels for each subplot\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors to all lightseagreen\n",
    "color = '#A1C8F3'\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title('Greedy Sampled Average Tanimoto Similarity', fontsize=22)\n",
    "ax.set_ylabel('Average Tanimoto Similarity', fontsize=22)\n",
    "\n",
    "ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "\n",
    "# Adding a legend\n",
    "lightseagreen_patch = plt.Line2D([0], [0], color='lightseagreen', lw=4, label='MMST')\n",
    "#ax.legend(handles=[lightseagreen_patch], loc='lower left', fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in zip(np.arange(1, len(mean_values) + 1), mean_values):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.0_Tanimoto_Violin_plot_Epoch_7_v3.png'\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea2579d-0394-4fe0-a3ab-9915ffd5f869",
   "metadata": {},
   "source": [
    "##### Number of Invalid molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda4b48-28cf-4685-99a0-d925cb208289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample input data\n",
    "labels = ['0.1M Epoch 7', '1M Epoch 7', '2M Epoch 7', '4M Epoch 7']\n",
    "results_dict_2 = [results_dict_0d, results_dict_0c, results_dict_0b, results_dict_0a]\n",
    "\n",
    "# Prepare data\n",
    "mean_results_2 = [len(d[\"failed\"]) for d in results_dict_2]  # Assuming \"failed\" is a key in each dictionary\n",
    "total_entries = len(results_dict_2[0][\"gen_conv_SMI_list\"]) # Total for percentage calculation\n",
    "\n",
    "# Define colors for the bars\n",
    "color2 = '#A1C8F3'\n",
    "\n",
    "# Set bar width\n",
    "bar_width = 0.35\n",
    "positions = np.arange(len(labels))\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "# Plotting the bars\n",
    "bar1 = ax.bar(positions, mean_results_2, bar_width, color=color2, edgecolor='black', label='MMST')\n",
    "\n",
    "# Adding value labels inside and percentage on top of each bar\n",
    "for bar in bar1:\n",
    "    yval = bar.get_height()\n",
    "    percentage = (yval / total_entries) * 100 if total_entries > 0 else 0  # Calculate percentage\n",
    "    \n",
    "    # Inside the bar\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval / 2, f'{yval:,.0f}', \n",
    "            rotation=90, ha='center', va='center', fontsize=22, color='black')\n",
    "    \n",
    "    # Top of the bar (moved higher)\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval + 2000, f'{percentage:.1f}%', \n",
    "            rotation=90, ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title(f'Greedy Sampled Number of Invalid SMILES           ', fontsize=22)\n",
    "plt.ylabel('Invalid Molecules', fontsize=22)\n",
    "plt.xticks(positions, labels, ha='center', fontsize=22)\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set y-limit slightly higher than max for label visibility\n",
    "ax.set_ylim(0, max(mean_results_2) * 1.25)  \n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "\n",
    "# Set aspect ratio\n",
    "ax.set_aspect(aspect='auto')\n",
    "\n",
    "# Adding a legend\n",
    "#ax.legend(fontsize=22)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.0_Invalid_molecules_Epoch_7_v3.png'\n",
    "plt.savefig(save_path, format='png')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e1a93-f132-4136-b5aa-1e17314b44e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Load saved data - 20M trained network\n",
    "- There is something wrong with the 0.5M - leave it out for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83210d71-1161-4b2d-a9a7-6e05fe4045d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exactly 20M molecules seen\n",
    "### Currently plotted the old - wrong results (without IR but trained with IR)\n",
    "\n",
    "import pickle\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.0_prob_dict_results_4M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0a = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.1_results_dict_4M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0a = pickle.load(file)\n",
    "\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.0_prob_dict_results_2M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0b = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240330_20M_Molecules_experiment_FALSE/0.1_results_dict_2M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0b = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240330_20M_Molecules_experiment_FALSE/0.0_prob_dict_results_1M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0c = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240330_20M_Molecules_experiment_FALSE/0.1_results_dict_1M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0c = pickle.load(file)\n",
    "    \n",
    "    \n",
    "\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.0_prob_dict_results_0.5M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0d = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.1_results_dict_0.5M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0d = pickle.load(file)\n",
    "\n",
    "\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.0_prob_dict_results_0.1M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0e = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.1_results_dict_0.1M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0e = pickle.load(file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aeeb28-ba31-4806-8c11-59dd78532a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict_results_2 = [prob_dict_results_0e, prob_dict_results_0d, prob_dict_results_0c, prob_dict_results_0b, prob_dict_results_0a]\n",
    "results_dict_2 = [results_dict_0e, results_dict_0d, results_dict_0c, results_dict_0b, results_dict_0a]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414c587-b8fb-4b64-8ecb-b879ae01f482",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Violine Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27b51c-e69d-495d-bd7a-3446836d92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['MMTi \\n0.1 Mol - 20M', 'MMTi \\n0.5 Mol - 20M', 'MMTi \\n1 Mol - 20M', 'MMTi \\n2Mol - 20M', 'MMTi \\n4Mol - 20M']\n",
    "prob_dict_results_2 = [ prob_dict_results_0e, prob_dict_results_0d, prob_dict_results_0c, prob_dict_results_0b, prob_dict_results_0a]\n",
    "\n",
    "labels = ['0.1M | 20M', '1M | 20M', '2M | 20M', '4M | 20M']\n",
    "prob_dict_results_2 = [ prob_dict_results_0e, prob_dict_results_0c, prob_dict_results_0b, prob_dict_results_0a]\n",
    "\n",
    "\n",
    "# Calculate mean and standard deviation for each dictionary\n",
    "mean_results = []\n",
    "std_results = []\n",
    "data_for_violin = []\n",
    "for prob_dict in prob_dict_results_2:\n",
    "    mean_prob = np.mean(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "    mean_results.append(mean_prob)\n",
    "    std_value = statistics.stdev(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "    std_results.append(std_value)\n",
    "    data_for_violin.append(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors\n",
    "color = '#A1C8F3'  # Use a single color for all the violin plots\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title('Correct SMILES Sample Probability', fontsize=22)\n",
    "ax.set_ylabel('Probability of Correct SMILES', fontsize=22)\n",
    "ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "\n",
    "mean_values = [np.mean(data) if data is not None else 0 for data in data_for_violin]\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in zip(np.arange(1, len(mean_values) + 1), mean_values):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Adding a legend\n",
    "lightseagreen_patch = plt.Line2D([0], [0], color='lightseagreen', lw=4, label='MMST')\n",
    "#ax.legend(handles=[lightseagreen_patch], loc='upper left', fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)  # Adjust based on your data's range\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.1_Violin_20M_v3.png'  # Replace with your desired path\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5eb5e-8a06-49f2-a940-c787af202256",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Tanimoto PLot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87b99a-ce22-45f4-87bc-49262d06cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['MMTi \\n0.1 Mol - 20M', 'MMTi \\n0.5 Mol - 20M', 'MMTi \\n1 Mol - 20M', 'MMTi \\n2 Mol - 20M', 'MMTi \\n4 Mol - 20M']\n",
    "results_dict_2 = [results_dict_0e, results_dict_0d, results_dict_0c, results_dict_0b, results_dict_0a]\n",
    "\n",
    "labels = ['0.1M | 20M', '1M | 20M', '2M | 20M', '4M | 20M']\n",
    "results_dict_2 = [results_dict_0e, results_dict_0c, results_dict_0b, results_dict_0a]\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "data_for_violin = [d[\"tanimoto_sim\"] for d in results_dict_2]\n",
    "\n",
    "# Calculate means for each dataset\n",
    "mean_values = [np.mean(data) for data in data_for_violin]\n",
    "\n",
    "# Labels for each subplot\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors to all lightseagreen\n",
    "color = '#A1C8F3'\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title('Greedy Sampled Average Tanimoto Similarity', fontsize=22)\n",
    "#ax.set_xlabel('Trained Model', fontsize=16)\n",
    "ax.set_ylabel('Average Tanimoto Similarity', fontsize=22)\n",
    "ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "\n",
    "# Adding a legend\n",
    "lightseagreen_patch = plt.Line2D([0], [0], color='lightseagreen', lw=4, label='MMST')\n",
    "#ax.legend(handles=[lightseagreen_patch], loc='lower left', fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in zip(np.arange(1, len(mean_values) + 1), mean_values):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.1_Tanimoto_Violin_plot_20_M_v3.png'\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e2784-9182-4a73-8535-32d7902b1dd3",
   "metadata": {},
   "source": [
    "##### Invalid Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7e82a-10bb-4e1b-b273-974f0143eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample input data\n",
    "# Labels, split into two lines for x-tick display\n",
    "labels = ['MMTi \\n0.1 Mol - 20M', 'MMTi \\n0.5 Mol - 20M', 'MMTi \\n1 Mol - 20M', 'MMTi \\n2 Mol - 20M', 'MMTi \\n4 Mol - 20M']\n",
    "results_dict_2 = [results_dict_0e, results_dict_0d, results_dict_0c, results_dict_0b, results_dict_0a]\n",
    "\n",
    "# Labels, split into two lines for x-tick display\n",
    "labels = ['0.1M | 20M', '1M | 20M', '2M | 20M', '4M | 20M']\n",
    "results_dict_2 = [results_dict_0e, results_dict_0c, results_dict_0b, results_dict_0a]\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "mean_results_2 = [len(d[\"failed\"]) for d in results_dict_2]  # Assuming \"failed\" is a key in each dictionary\n",
    "total_entries = len(results_dict_2[0][\"gen_conv_SMI_list\"]) # Total for percentage calculation\n",
    "\n",
    "# Define colors for the bars\n",
    "color2 = '#A1C8F3'\n",
    "\n",
    "# Set bar width\n",
    "bar_width = 0.35\n",
    "positions = np.arange(len(labels))\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "# Plotting the bars\n",
    "bar1 = ax.bar(positions, mean_results_2, bar_width, color=color2, edgecolor='black', label='MMST')\n",
    "\n",
    "# Adding value labels inside and percentage on top of each bar\n",
    "for bar in bar1:\n",
    "    yval = bar.get_height()\n",
    "    percentage = (yval / total_entries) * 100 if total_entries > 0 else 0  # Calculate percentage\n",
    "    # Inside the bar\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval / 2, f'{yval:,.0f}', \n",
    "            rotation=90, ha='center', va='center', fontsize=22, color='black')\n",
    "    \n",
    "    # Top of the bar (moved higher)\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval + 2000, f'{percentage:.1f}%', \n",
    "            rotation=90, ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title(f'Greedy Sampled Number of Invalid SMILES         ', fontsize=22)\n",
    "#plt.xlabel('Trained Model', fontsize=16)\n",
    "plt.ylabel('Number of Invalid Molecules', fontsize=22)\n",
    "plt.xticks(positions, labels, ha='center', fontsize=22)\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, max(mean_results_2) * 1.2)  # Set y-limit slightly higher than max for label visibility\n",
    "\n",
    "# Set aspect ratio\n",
    "ax.set_aspect(aspect='auto')\n",
    "\n",
    "# Adding a legend\n",
    "#ax.legend(fontsize=22)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.1_Invalid_molecules_20M_v3.png'\n",
    "plt.savefig(save_path, format='png')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae852a-f721-4c9f-a205-191c2b88c85f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Model Size  & Training Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5846e30-4ab8-4f84-9bb5-4067fef495ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# V8 Raw 1M Large\n",
    "config.num_encoder_layers = 6\n",
    "config.num_decoder_layers = 6\n",
    "config.num_heads = 16\n",
    "\n",
    "# V8 Raw 1M\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_1Mio/model-epoch=19-loss=0.04.ckpt\"\n",
    "\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_0a, results_dict_0a = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_1M_L_epoch_20.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_0a, file)\n",
    "    \n",
    "\n",
    "# Save the data to a file\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_1M_Lepoch_20.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_0a, file)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589c45e-a194-4ca8-9726-9016b97da93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# V8 Raw 1M Medium\n",
    "config.num_encoder_layers = 3\n",
    "config.num_decoder_layers = 3\n",
    "config.num_heads = 8\n",
    "\n",
    "\n",
    "### 20 M molecules seen\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_1Mio_medium/model-epoch=19-loss=0.09.ckpt\"\n",
    "\n",
    "\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_0b, results_dict_0b = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "#file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_1M_M_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_0b, file)\n",
    "    \n",
    "\n",
    "# Save the data to a file\n",
    "#file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_1M_M_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_0b, file)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca15e6-e0b6-4363-9098-b1840cb753d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# V8 Raw 1M Small\n",
    "config.num_encoder_layers = 2\n",
    "config.num_decoder_layers = 2\n",
    "config.num_heads = 4\n",
    "\n",
    "### 20 M molecules seen\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_1Mio_small/model-epoch=19-loss=0.11.ckpt\"\n",
    "\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_0c, results_dict_0c = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "#file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.0_prob_dict_results_1M_S_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_0c, file)\n",
    "    \n",
    "\n",
    "# Save the data to a file\n",
    "#file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_1M_S_20M_mol.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_0c, file)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63b556-4c09-47be-8d3c-5a0af7675461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0840e4c2-5e96-4e02-91cc-62a00940b826",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Load saved data - Model Size 20M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab788d14-119d-4c20-9852-5a4a25568595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.0_prob_dict_results_1M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0d = pickle.load(file)\n",
    "\n",
    "    \n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules/0.1_results_dict_1M_L_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0d = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules_backup/0.0_prob_dict_results_1M_M_20M_mol.pkl'  # Replace with your desired path\n",
    "#file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240330_20M_Molecules_experiment_FALSE/0.0_prob_dict_results_1M_M_last.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0e = pickle.load(file)\n",
    "\n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules_backup/0.1_results_dict_1M_M_20M_mol.pkl'  # Replace with your desired path\n",
    "#file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/0.1_results_dict_1M_M_last.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0e = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules_backup/0.0_prob_dict_results_1M_S_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_0f = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_20M_Molecules_backup/0.1_results_dict_1M_S_20M_mol.pkl'  # Replace with your desired path\n",
    "# Loading results_list_b\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_0f = pickle.load(file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c61887-2cd2-4212-8a04-c001cf6fbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict_results_2 = [prob_dict_results_0f, prob_dict_results_0e, prob_dict_results_0d]\n",
    "results_dict_2 = [results_dict_0f, results_dict_0e, results_dict_0d]\n",
    "test_data_size = len(pd.read_csv(config.csv_path_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825450c-8d58-4691-975f-c7dc2443d942",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Violin Chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a9aa1-f7b0-4d96-a899-4198991646ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels, split into two lines for x-tick display\n",
    "labels = ['MMTi \\n1 Mol 20M S', 'MMTi \\n1 Mol 20M M','MMTi \\n1 Mol 20M L']\n",
    "labels = ['1M | 20M | S', '1M | 20M | M','1M | 20M | L']\n",
    "\n",
    "results_dict_2 = [results_dict_0f, results_dict_0e, results_dict_0d]\n",
    "\n",
    "# Calculate mean and standard deviation for each dictionary\n",
    "mean_results = []\n",
    "std_results = []\n",
    "data_for_violin = []\n",
    "for prob_dict in prob_dict_results_2:\n",
    "    mean_prob = np.mean(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "    mean_results.append(mean_prob)\n",
    "    std_value = statistics.stdev(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "    std_results.append(std_value)\n",
    "    data_for_violin.append(prob_dict[\"aggregated_corr_prob_multi\"])\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors\n",
    "color = '#A1C8F3'  # Use a single color for all the violin plots\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title('Correct SMILES Sample Probability', fontsize=22)\n",
    "#ax.set_xlabel('Trained Model', fontsize=22)\n",
    "ax.set_ylabel('Probability of Correct SMILES', fontsize=22)\n",
    "ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "\n",
    "mean_values = [np.mean(data) if data is not None else 0 for data in data_for_violin]\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in zip(np.arange(1, len(mean_values) + 1), mean_values):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Adding a legend\n",
    "lightseagreen_patch = plt.Line2D([0], [0], color='#A1C8F3', lw=4, label='MMST')\n",
    "#ax.legend(handles=[lightseagreen_patch], loc='upper left', fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)  # Adjust based on your data's range\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.3_Violin_Size_20_M_mol_v3.png'  # Replace with your desired path\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24029185-eab4-4649-840d-89519f167128",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Tanimoto Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc04816-9024-465e-8202-24e9056b6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Labels, split into two lines for x-tick display\n",
    "labels = ['MMTi \\n1 Mol 20M S', 'MMTi \\n1 Mol 20M M','MMTi \\n1 Mol 20M L']\n",
    "labels = ['1M | 20M | S', '1M | 20M | M','1M | 20M | L']\n",
    "\n",
    "results_dict_2 = [results_dict_0f, results_dict_0e, results_dict_0d]\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "data_for_violin = [d[\"tanimoto_sim\"] for d in results_dict_2]\n",
    "\n",
    "# Calculate means for each dataset\n",
    "mean_values = [np.mean(data) for data in data_for_violin]\n",
    "\n",
    "# Labels for each subplot\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors to all lightseagreen\n",
    "color = '#A1C8F3'\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title('Greedy Sampled Average Tanimoto Similarity', fontsize=22)\n",
    "#ax.set_xlabel('Trained Model', fontsize=16)\n",
    "ax.set_ylabel('Average Tanimoto Similarity', fontsize=22)\n",
    "ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "\n",
    "# Adding a legend\n",
    "lightseagreen_patch = plt.Line2D([0], [0], color='#A1C8F3', lw=4, label='MMST')\n",
    "#ax.legend(handles=[lightseagreen_patch], loc='lower left', fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in zip(np.arange(1, len(mean_values) + 1), mean_values):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.3_Tanimoto_Violin_plot_Size_20_M_mol_v3.png'\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dfbd42-fe6d-4dd6-b4df-4c8f1c65be0d",
   "metadata": {},
   "source": [
    "##### Number of Invalid Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcabb9b-34aa-467d-8a2a-3d06a7a29fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Labels, split into two lines for x-tick display\n",
    "labels = ['MMTi \\n1 Mol 20M S', 'MMTi \\n1 Mol 20M M','MMTi \\n1 Mol 20M L']\n",
    "labels = ['1M | 20M | S', '1M | 20M | M','1M | 20M | L']\n",
    "\n",
    "results_dict_2 = [results_dict_0f, results_dict_0e, results_dict_0d]\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "mean_results_2 = [len(d[\"failed\"]) for d in results_dict_2]  # Assuming \"failed\" is a key in each dictionary\n",
    "total_entries = len(results_dict_2[0][\"gen_conv_SMI_list\"]) # Total for percentage calculation\n",
    "\n",
    "# Define colors for the bars\n",
    "color2 = '#A1C8F3'\n",
    "\n",
    "# Set bar width\n",
    "bar_width = 0.35\n",
    "positions = np.arange(len(labels))\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "# Plotting the bars\n",
    "bar1 = ax.bar(positions, mean_results_2, bar_width, color=color2, edgecolor='black', label='MMST')\n",
    "\n",
    "# Adding value labels inside and percentage on top of each bar\n",
    "for bar in bar1:\n",
    "    yval = bar.get_height()\n",
    "    percentage = (yval / total_entries) * 100 if total_entries > 0 else 0  # Calculate percentage\n",
    "    # Inside the bar\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval / 2, f'{yval:,.0f}', \n",
    "            rotation=90, ha='center', va='center', fontsize=22, color='black')\n",
    "    \n",
    "    # Top of the bar (moved higher)\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval + 2000, f'{percentage:.1f}%', \n",
    "            rotation=90, ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title(f'Greedy Sampled Number of Invalid SMILES       ', fontsize=22)\n",
    "#plt.xlabel('Trained Model', fontsize=16)\n",
    "plt.ylabel('Number of Invalid Molecules', fontsize=22)\n",
    "plt.xticks(positions, labels, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, max(mean_results_2) * 1.2)  # Set y-limit slightly higher than max for label visibility\n",
    "\n",
    "# Set aspect ratio\n",
    "ax.set_aspect(aspect='auto')\n",
    "\n",
    "# Adding a legend\n",
    "#ax.legend(fontsize=22)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/0.3_Invalid_molecules_Size_20_M_mol_v3.png'\n",
    "plt.savefig(save_path, format='png')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7cb8a-6768-4f72-921d-1f613d95ac1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d8e7c71-e6ee-425e-89d6-0a6eb3882c63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### 1.0 Test different models for paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fea220-f881-4789-97f2-e9ee5805184d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce20c0-51dc-42ed-8e49-40b14c809c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "config.IR_data_folder=\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"\n",
    "config.data_size = 500000 #int(1000*data_fraction)\n",
    "config.IR_data_folder = \"\"\n",
    "config.training_mode = \"1H_13C_HSQC_COSY_IR_MF_MW\" # it ignors IR because no folder provided and puts zeros in for IR\n",
    "config.multinom_runs = 1\n",
    "config.batch_size = 1024 #int(1000*data_fraction)\n",
    "\n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8_355655.pkl\"\n",
    "\n",
    "val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663d7b19-ebdd-4d9e-875b-a1f59c47e22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# V8i Raw \n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT/MultimodalTransformer_time_1702212447.1475492_Loss_0.056.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_1ai, results_dict_1ai = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "print(np.mean(results_dict_1ai[\"tanimoto_sim\"]))\n",
    "\n",
    "# V8i Raw + MW\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_MW/MultimodalTransformer_time_1702852525.1205726_Loss_0.088.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_1bi, results_dict_1bi = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "print(np.mean(results_dict_1bi[\"tanimoto_sim\"]))\n",
    "\n",
    "\n",
    "# V8i Raw + MW + Drop\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_1ci, results_dict_1ci = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "print(np.mean(results_dict_1ci[\"tanimoto_sim\"]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b92738a-ea32-412d-ae66-366226ce3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# V8i Raw \n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT/MultimodalTransformer_time_1702212447.1475492_Loss_0.056.ckpt\"\n",
    "\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_1ai, results_dict_1ai = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "print(np.mean(results_dict_1ai[\"tanimoto_sim\"]))\n",
    "\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/1.0_prob_dict_results_1ai.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_1ai, file)\n",
    "    \n",
    "\n",
    "# Save the data to a file\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/1.1_results_dict_1ai.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_1ai, file)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbf336-b49f-4f2e-a581-4a4b226f4980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# V8i Raw + MW\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_MW/MultimodalTransformer_time_1702852525.1205726_Loss_0.088.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_1bi, results_dict_1bi = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "print(np.mean(results_dict_1bi[\"tanimoto_sim\"]))\n",
    "\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/1.0_prob_dict_results_1bi.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_1bi, file)\n",
    "    \n",
    "\n",
    "# Save the data to a file\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/1.1_results_dict_1bi.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_1bi, file)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66328ed2-a21f-4f97-8f0f-5b7998c42227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# V8i Raw + MW + Drop\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "prob_dict_results_1ci, results_dict_1ci = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "print(np.mean(results_dict_1ci[\"tanimoto_sim\"]))\n",
    "\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/1.0_prob_dict_results_1ci.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_1ci, file)\n",
    "        \n",
    "\n",
    "# Save the data to a file\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/1.1_results_dict_1ci.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_1ci, file)\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd46b1-c738-42ab-8708-dabd98436e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load calculated results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1ee92-7151-4aac-b335-9e584aebf292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "    \n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_1_Trainings_Experiments/1.0_prob_dict_results_1ai__base.pkl\"\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    prob_dict_results_1ai = pickle.load(file)\n",
    "    \n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_1_Trainings_Experiments/1.0_prob_dict_results_1bi.pkl\"\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    prob_dict_results_1bi = pickle.load(file)\n",
    "    \n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_1_Trainings_Experiments/1.0_prob_dict_results_1ci.pkl\"\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    prob_dict_results_1ci = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae1afc-0dcb-4ba8-b278-19d79abb2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_1_Trainings_Experiments/1.1_results_dict_1ai__base.pkl\"\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    results_dict_1ai = pickle.load(file)\n",
    "    \n",
    "\n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_1_Trainings_Experiments/1.1_results_dict_1bi_.pkl\"\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    results_dict_1bi = pickle.load(file)\n",
    "    \n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240508_1_Trainings_Experiments/1.1_results_dict_1ci_.pkl\"\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    results_dict_1ci = pickle.load(file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1833a17-bf4f-41d6-b09c-a49668eb4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict_results_1 = [prob_dict_results_1ai, prob_dict_results_1bi, prob_dict_results_1ci]\n",
    "results_dict_1 = [results_dict_1ai, results_dict_1bi, results_dict_1ci]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf210ce3-db43-41aa-94a3-cbc04772c71a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Correct Sample Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565d02e-2e1b-4fe6-bdea-a0d7a109b799",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07983e2-3520-4193-9319-4ae42052b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict_results_1 = [prob_dict_results_1ai, prob_dict_results_1bi,  prob_dict_results_1ci]\n",
    "results_dict_1 = [results_dict_1ai, results_dict_1bi, results_dict_1ci]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88f2e9-67ee-4abd-9470-59e8a2fbd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_dict_1 = [results_dict_1a, results_dict_1ai, results_dict_1b, results_dict_1bi, results_dict_1c, results_dict_1ci]\n",
    "#results_dict_1 = [results_dict_1a, results_dict_1b, results_dict_1c]\n",
    "results_dict_2 = [results_dict_1ai, results_dict_1bi, results_dict_1ci]\n",
    "test_data_size = len(list(results_dict_1ai[\"trg_conv_SMI_list\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc873ac1-8411-426e-8caf-4b1ec42892e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f864880-082b-4283-8675-1d3060a67e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample input data\n",
    "prob_dict_results_2 = [prob_dict_results_1ai, prob_dict_results_1bi, prob_dict_results_1ci]\n",
    "\n",
    "# Prepare data\n",
    "data_for_violin = [d[\"aggregated_corr_prob_multi\"] for d in prob_dict_results_2]\n",
    "\n",
    "# Calculate means for each data set\n",
    "mean_values = [np.mean(d) for d in data_for_violin]\n",
    "\n",
    "# Labels\n",
    "labels = ['Raw', 'Raw \\nMW', 'Raw \\nMW \\nDropout']\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor(\"#A1C8F3\")\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title('Correct SMILES Sample Probability', fontsize=22)\n",
    "ax.set_ylabel('Probability of Correct SMILES', fontsize=22)\n",
    "ax.set_xticks([1, 2, 3])\n",
    "ax.set_xticklabels(labels, ha='center', fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in enumerate(mean_values, 1):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "    \n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/1.0_violin_plot_v3.png'  # Replace with your desired path\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()\n",
    "\n",
    "# Uncomment the following lines if you want to save the figure\n",
    "# save_path = '/path/to/your/figure/1.0_violin_plot_prob_dict_results_2.png'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d138790-0e50-46ac-8702-120dcf6e872a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Greedy Sampled Tanimoto Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e0afb-dc04-46eb-a36d-98a406d4dd17",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Violing Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e6fbf-da9a-4e56-98f3-1484933f6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample input data\n",
    "results_dict_2 = [results_dict_1ai, results_dict_1bi, results_dict_1ci]\n",
    "\n",
    "# Prepare data\n",
    "data_for_violin = [d[\"tanimoto_sim\"] for d in results_dict_2]\n",
    "\n",
    "# Calculate means for each data set\n",
    "mean_values = [np.mean(d) for d in data_for_violin]\n",
    "\n",
    "# Labels\n",
    "labels = ['Raw', 'Raw \\nMW', 'Raw \\nMW \\nDropout']\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor('#A1C8F3')\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title('Greedy Sampled Average Tanimoto Similarity', fontsize=22)\n",
    "ax.set_ylabel('Average Tanimoto Similarity', fontsize=22)\n",
    "ax.set_xticks([1, 2, 3])\n",
    "ax.set_xticklabels(labels, ha='center', fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in enumerate(mean_values, 1):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/1.0_Tanimoto_Similarity_v3.png'\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6af815-77cc-4c13-85d8-305abb5b8173",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Number of Invalid Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c91aaa-46a4-4f25-a45f-6df11635e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample input data\n",
    "results_dict_2 = [results_dict_1ai, results_dict_1bi, results_dict_1ci]\n",
    "\n",
    "# Prepare data\n",
    "mean_results_2 = [len(d[\"failed\"]) for d in results_dict_2]\n",
    "\n",
    "# Labels\n",
    "labels = ['Raw', 'Raw \\nMW', 'Raw \\nMW \\nDropout']\n",
    "\n",
    "# Define color for the bars\n",
    "color = '#A1C8F3'\n",
    "\n",
    "# Set bar width\n",
    "bar_width = 0.5\n",
    "positions = np.arange(len(labels))\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "# Plotting the bars\n",
    "bars = ax.bar(positions, mean_results_2, bar_width, capsize=10, \n",
    "              color=color, edgecolor='black', label='MMST')\n",
    "\n",
    "# Adding percentage labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    percentage = (yval / test_data_size) * 100\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval + 500, f'{percentage:.2f}%', \n",
    "            rotation=90, ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Adding value labels in the middle of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval / 2, f'{yval:,.0f}', \n",
    "            rotation=90, ha='center', va='center', fontsize=22, color='black')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Greedy Sampled Number of Invalid SMILES', fontsize=22)\n",
    "plt.ylabel('Number of Invalid Molecules', fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "# Set x-ticks\n",
    "plt.xticks(positions, labels,  ha='center', fontsize=22)\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, max(mean_results_2) * 1.2)\n",
    "\n",
    "# Set aspect ratio\n",
    "ax.set_aspect(aspect='auto')\n",
    "\n",
    "# Adding a legend\n",
    "#ax.legend(fontsize=22)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/1.0_Invalid_Molecules_v3.png'\n",
    "plt.savefig(save_path, format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cda591-79f4-4ce2-a994-7ce2f74c2ace",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### 2.0 Ablation Study fine-tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c97e6-c0f1-4167-abe3-c426069855ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f194757-48a6-4641-8d66-3d16773d27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''config.multinom_runs = 1\n",
    "config.training_mode = \"13C_HSQC_COSY_IR_MF_MW\"\n",
    "config.data_size = 489993\n",
    "# No 1H\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_4Mio_no_H_3/model-epoch=00-loss=0.03.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "prob_dict_results_2_1a, results_dict_2_1a = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "#print(np.mean(results_dict_2_1a[\"tanimoto_sim\"]))\n",
    "\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1a.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_2_1a, file)\n",
    "\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1a.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_2_1a, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd3d20-1c95-424f-a696-216923c464ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''config.multinom_runs = 1\n",
    "config.training_mode = \"1H_HSQC_COSY_IR_MF_MW\"\n",
    "config.data_size = 489993\n",
    "# No 13C\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_4Mio_no_C/model-epoch=00-loss=0.03.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "prob_dict_results_2_1b, results_dict_2_1b = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "#print(np.mean(results_dict_2_1b[\"tanimoto_sim\"]))\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1b.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_2_1b, file)\n",
    "\n",
    "# Save the data to a file\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1b.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_2_1b, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb7579-abe7-4eb9-a1ca-b791da243e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''config.multinom_runs = 1\n",
    "config.training_mode = \"1H_13C_COSY_IR_MF_MW\"\n",
    "config.data_size = 489993\n",
    "# No HSQC\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_4Mio_no_HSQC/model-epoch=00-loss=0.03.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "prob_dict_results_2_1c, results_dict_2_1c = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "#print(np.mean(results_dict_2_1c[\"tanimoto_sim\"]))\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1c.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_2_1c, file)\n",
    "\n",
    "# Save the data to a file\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1c.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_2_1c, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41588b4-dfa8-4468-8023-964e0430c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''config.multinom_runs = 1\n",
    "config.training_mode = \"1H_13C_HSQC_IR_MF_MW\"\n",
    "config.data_size = 489993\n",
    "# No COSY\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_4Mio_no_COSY/model-epoch=00-loss=0.03.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "prob_dict_results_2_1d, results_dict_2_1d = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "#print(np.mean(results_dict_2_1e[\"tanimoto_sim\"]))\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1d.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_2_1d, file)\n",
    "\n",
    "# Save the data to a file\n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1d.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_2_1d, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed292300-1ab6-4978-b2be-7d4b178c17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''config.multinom_runs = 1\n",
    "config.training_mode = \"1H_13C_HSQC_COSY_MF_MW\"\n",
    "config.data_size = 489993\n",
    "# No IR\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_4Mio_no_IR/model-epoch=00-loss=0.02.ckpt\"\n",
    "model_MMT = mrtf.load_MMT_model(config)\n",
    "val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "prob_dict_results_2_1e, results_dict_2_1e = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "#print(np.mean(results_dict_2_1e[\"tanimoto_sim\"]))\n",
    "\n",
    "import pickle\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1e.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'wb') as file:\n",
    "    pickle.dump(prob_dict_results_2_1e, file)\n",
    "\n",
    "# Save the data to a file\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1e.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'wb') as file:\n",
    "    pickle.dump(results_dict_2_1e, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64db36b-ea53-4855-be94-b9a235882ff1",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281c162-acb4-49b4-bf07-d9f994672dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1a.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    results_dict_2_1a = pickle.load(file)\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1b.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    results_dict_2_1b = pickle.load(file)\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1c.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    results_dict_2_1c = pickle.load(file)\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1d.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    results_dict_2_1d = pickle.load(file)\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_results_dict_2_1e.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    results_dict_2_1e = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d54b4-53b1-4337-9ab2-5cc8fe45a416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd9df6-4202-4a7d-9cbc-9316cb1a527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1a.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_2_1a = pickle.load(file)\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1b.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_2_1b = pickle.load(file)\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1c.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_2_1c = pickle.load(file)\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1d.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_2_1d = pickle.load(file)\n",
    "    \n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240624_FT_Ablation_Study/2.1_prob_dict_results_2_1e.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_2_1e = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f6028-5fc2-4b5c-9f00-13c4a8f7a068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b758d6-2d4d-4311-826c-a56b9b4f61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all\n",
    "file_prob_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/2.0_prob_dict_results_2ai.pkl'  # Replace with your desired path\n",
    "with open(file_prob_dict_path, 'rb') as file:\n",
    "    prob_dict_results_2_1all = pickle.load(file)\n",
    "    \n",
    "file_results_dict_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/2.1_results_dict_2ai.pkl'  # Replace with your desired path\n",
    "with open(file_results_dict_path, 'rb') as file:\n",
    "    results_dict_2_1all = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86f93e-99a1-45b9-9f9c-b672a98f9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_2 = [results_dict_2_1all, \n",
    "                  results_dict_2_1a, \n",
    "                    results_dict_2_1b, \n",
    "                    results_dict_2_1c, \n",
    "                    results_dict_2_1d, \n",
    "                    results_dict_2_1e,\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1941e3a-ed49-497d-bf74-dc38e871b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict_results_2 = [prob_dict_results_2_1all,\n",
    "                       prob_dict_results_2_1a, \n",
    "                    prob_dict_results_2_1b, \n",
    "                    prob_dict_results_2_1c, \n",
    "                    prob_dict_results_2_1d, \n",
    "                    prob_dict_results_2_1e,\n",
    "                      ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fd64b-1576-4ee7-a694-df9d28a30f62",
   "metadata": {},
   "source": [
    "#### Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b923bc-4d3e-4a66-8026-7797d212c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data for the violin plot\n",
    "data_for_violin = [d[\"aggregated_corr_prob_multi\"] for d in prob_dict_results_2]\n",
    "\n",
    "# Labels\n",
    "labels = ['All', 'W/O 1H', 'W/O 13C', \n",
    "          'W/O HSQC', 'W/O COSY', 'W/O IR']\n",
    "\n",
    "# Create the violin plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "parts = ax.violinplot(data_for_violin, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "# Customizing colors\n",
    "colors = ['#A1C8F3', '#A1C8F3', '#A1C8F3', '#A1C8F3', '#A1C8F3', '#A1C8F3', '#A1C8F3']\n",
    "for i, pc in enumerate(parts['bodies']):\n",
    "    pc.set_facecolor(colors[i])\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.7)\n",
    "    \n",
    "\n",
    "mean_values = [np.mean(data) if data is not None else 0 for data in data_for_violin]\n",
    "\n",
    "# Add mean values as text\n",
    "for pos, mean_value in zip(np.arange(1, len(mean_values) + 1), mean_values):\n",
    "    ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Customizing the axes and labels\n",
    "ax.set_title(f'Averaged Correct SMILES Sample Probability', fontsize=22)\n",
    "#ax.set_xlabel('Trained Model', fontsize=22)\n",
    "ax.set_ylabel('Probability of Correct SMILES', fontsize=22)\n",
    "ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)  # Adjust tick label size here\n",
    "#ax.legend(handles=[mmti_patch], loc='upper left', fontsize=22)\n",
    "\n",
    "# Add grid and set the limits\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 1)  # Adjust based on your data's range\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/2.1_Ablation_Violin_chart_v3.png'  # Replace with your desired path\n",
    "plt.savefig(save_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c847d4-45de-4efe-8847-453a1c9ed25b",
   "metadata": {},
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbc508-2105-4277-a1bc-b6cc81ac64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"list_list = []\n",
    "for prob_dict_results in prob_dict_results_2:\n",
    "    list_list.append((prob_dict_results[\"aggregated_corr_prob_multi\"]))\n",
    "    print(len(prob_dict_results[\"aggregated_corr_prob_multi\"]))\n",
    "\n",
    "# Labels for each subplot\n",
    "labels = ['All', 'W/O 1H', 'W/O 13C', \n",
    "          'W/O HSQC', 'W/O COSY', 'W/O IR']\n",
    "\n",
    "# Creating a 2x3 grid of subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i != 12:\n",
    "        # Plot histogram for each sublist\n",
    "        ax.hist(list_list[i], bins=20, color='#A1C8F3', edgecolor='black')\n",
    "        ax.set_title(f'Histogram of {labels[i]}', fontsize=16)\n",
    "        ax.set_xlabel('Value', fontsize=16)\n",
    "        ax.set_ylabel('Frequency', fontsize=16)\n",
    "        \n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "# Adjust layout\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/2.1_Histogram_Ablation_v3.png'  # Replace with your desired path\n",
    "plt.savefig(save_path, format='png')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443adfc6-6390-4ccf-be8c-02c72f883b80",
   "metadata": {},
   "source": [
    "#### Failed Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607fd8a-307f-4502-a227-91f6155a56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "# Calculate the mean number of failed results for each configuration\n",
    "mean_results_2 = []\n",
    "for results_dict in results_dict_2:\n",
    "    mean_prob = len(results_dict[\"failed\"])\n",
    "    mean_results_2.append(mean_prob)\n",
    "\n",
    "# Labels for each subplot\n",
    "labels = ['All', 'W/O 1H', 'W/O 13C', \n",
    "          'W/O HSQC', 'W/O COSY', 'W/O IR']\n",
    "\n",
    "# Define colors for the bars\n",
    "color = '#A1C8F3'\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "bars = ax.bar(range(len(mean_results_2)), mean_results_2, align='center', alpha=0.7, ecolor='black', capsize=10, edgecolor='black', color=color)\n",
    "\n",
    "# Adding value labels in the center of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval / 2, f'{yval:,.0f}',\n",
    "            rotation=90, ha='center', va='center', fontsize=22, color='black')\n",
    "\n",
    "# Set the title and labels\n",
    "ax.set_title('Greedy Sampled Number of Invalid Molecules   ', fontsize=22)\n",
    "ax.set_ylabel('Number of Invalid Molecules', fontsize=22)\n",
    "\n",
    "# Set x-ticks\n",
    "ax.set_xticks(range(len(mean_results_2)))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='center', fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "#ax.legend(handles=[mmti_patch], loc='upper left', fontsize=22)\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot with a black box around the bars\n",
    "for bar in bars:\n",
    "    bar.set_edgecolor('black')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot (uncomment if needed)\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/2.1_Ablation_Invalid_molecules_v3.png'  # Replace with your desired path\n",
    "plt.savefig(save_path, format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf566fc8-40e0-4984-a4bc-684d377d9696",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tanimoto comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53646a-da31-4877-8930-a6ce7010c809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict_2_1all.get(\"tanimoto_sim\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e9cec-ea3b-4c0a-9ea0-2690c0e19cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample input data (replace these with your actual data)\n",
    "results_dict_2 = [results_dict_2_1all, \n",
    "                  results_dict_2_1a, \n",
    "                  results_dict_2_1b, \n",
    "                  results_dict_2_1c, \n",
    "                  results_dict_2_1d, \n",
    "                  results_dict_2_1e]\n",
    "#                  results_dict_2_1f]\n",
    "\n",
    "# Prepare data and filter out empty datasets\n",
    "data_for_violin = []\n",
    "filtered_labels = []\n",
    "labels = ['All', 'W/O 1H', 'W/O 13C', \n",
    "          'W/O HSQC', 'W/O COSY', 'W/O IR']\n",
    "\n",
    "for d, label in zip(results_dict_2, labels):\n",
    "    if label == 'All':\n",
    "        tanimoto_sim = d.get(\"tanimoto_sim\", [])\n",
    "    else:\n",
    "        tanimoto_sim = d.get(\"tanimoto_scores_all\", [])\n",
    "    if len(tanimoto_sim) > 0:\n",
    "        data_for_violin.append(tanimoto_sim)\n",
    "        filtered_labels.append(label)\n",
    "\n",
    "if not data_for_violin:\n",
    "    print(\"Error: All datasets are empty. Unable to create violin plot.\")\n",
    "else:\n",
    "    # Create the violin plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "    # Define positions for the violins\n",
    "    positions = np.arange(1, len(filtered_labels) + 1)\n",
    "\n",
    "    # Plot violins\n",
    "    parts = ax.violinplot(data_for_violin, positions=positions, showmeans=True, showmedians=False, showextrema=False)\n",
    "\n",
    "    # Customizing colors\n",
    "    color = '#A1C8F3'\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(color)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.7)\n",
    "\n",
    "    # Customizing the axes and labels\n",
    "    ax.set_title('Average Greedy Sampled Tanimoto Similarity', fontsize=22)\n",
    "    #ax.set_xlabel('Model Variation', fontsize=22)\n",
    "    ax.set_ylabel('Tanimoto Similarity', fontsize=22)\n",
    "\n",
    "    # Set x-ticks in the middle of each group\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(filtered_labels, rotation=45, ha='center', fontsize=22)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "\n",
    "    # Adding a legend\n",
    "    mmti_patch = plt.Line2D([0], [0], color='#A1C8F3', lw=4, label='MMST')\n",
    "    #ax.legend(handles=[mmti_patch], loc='lower left', fontsize=22)\n",
    "\n",
    "    # Add grid and set the limits\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Calculate and add mean values as text\n",
    "    for pos, data in zip(positions, data_for_violin):\n",
    "        mean_value = np.mean(data)\n",
    "        ax.text(pos, mean_value, f'{mean_value:.2f}', ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/2.1_Ablation_Tanimoto_v3.png'\n",
    "    plt.savefig(save_path, format='png')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Print the data for debugging\n",
    "print(\"Data for violin plot:\", data_for_violin)\n",
    "print(\"Filtered labels:\", filtered_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb39698-bcea-49a9-8057-464de1ad5668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accf245c-6ed5-4924-aab1-c7c28edec987",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### 3.0 Percentage Calculations V8 and V8i with TRUE or FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2833c5-ec8b-42af-8f00-8f19ae1f3f36",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Generate a table with Greedy/Top 1/3/5/10 accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c25a9-c2c4-4146-b837-47f5bb747bb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 3.2 Load/process and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a93f17-c4ff-42f2-ac11-53d922217eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from argparse import Namespace\n",
    "\n",
    "# Data processing and scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "import operator\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# RDKit for cheminformatics\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors, MolFromSmiles, MolToSmiles\n",
    "\n",
    "# Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "\n",
    "# Local utilities/modules\n",
    "import utils_MMT.sgnn_code_pl_v15_4 as sc\n",
    "import utils_MMT.train_test_functions_pl_v15_4 as ttf\n",
    "import utils_MMT.helper_functions_pl_v15_4 as hf\n",
    "import utils_MMT.validate_generate_MMT_v15_4 as vgmmt\n",
    "import utils_MMT.run_batch_gen_val_MMT_v15_4 as rbgvm\n",
    "from utils_MMT.dataloaders_pl_v15_4 import MultimodalData, collate_fn\n",
    "from utils_MMT.models_MMT_v15_4 import MultimodalTransformer, TransformerMultiGPU\n",
    "from utils_MMT.models_CLIP_v15_4 import CLIPMultiGPU  \n",
    "from utils_MMT.models_BLIP_v15_4 import BLIPMultiGPU  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(torch.initial_seed() % (2**32))\n",
    "    random.seed(torch.initial_seed() % (2**32))\n",
    "\n",
    "def prepare_HSQC_data_from_src_2(src_HSQC_list):\n",
    "    \"\"\"\n",
    "    Processes and scales HSQC spectral data from the source list.\n",
    "    \"\"\"\n",
    "    processed_HSQC = []\n",
    "\n",
    "    for src in src_HSQC_list:\n",
    "        #for src in src_HSQC:\n",
    "            # Filter out rows where both elements are not zero\n",
    "            non_zero_mask = (src != 0).all(dim=1)\n",
    "            filtered_src = src[non_zero_mask]\n",
    "\n",
    "            if filtered_src.nelement() != 0:  # Check if tensor is not empty\n",
    "                scaled_tensors = [filtered_src[:, 0] * 10, filtered_src[:, 1] * 200]\n",
    "                combined_tensor = torch.stack(scaled_tensors, dim=1)\n",
    "                processed_HSQC.append(combined_tensor)\n",
    "            else:\n",
    "                processed_HSQC.append(torch.tensor([]))  # Append an empty tensor for consistency\n",
    "\n",
    "    return processed_HSQC\n",
    "\n",
    "def prepare_COSY_data_from_src_2(src_COSY_list):\n",
    "    \"\"\"\n",
    "    Processes and scales HSQC spectral data from the source list.\n",
    "    \"\"\"\n",
    "    processed_COSY = []\n",
    "\n",
    "    for src in src_COSY_list:\n",
    "        #for src in src_HSQC:\n",
    "\n",
    "            # Filter out rows where both elements are not zero\n",
    "            non_zero_mask = (src != 0).all(dim=1)\n",
    "            filtered_src = src[non_zero_mask]\n",
    "\n",
    "            if filtered_src.nelement() != 0:  # Check if tensor is not empty\n",
    "                scaled_tensors = [filtered_src[:, 0] * 10, filtered_src[:, 1] * 10]\n",
    "                combined_tensor = torch.stack(scaled_tensors, dim=1)\n",
    "                processed_COSY.append(combined_tensor)\n",
    "            else:\n",
    "                processed_COSY.append(torch.tensor([]))  # Append an empty tensor for consistency\n",
    "\n",
    "    return processed_COSY\n",
    "\n",
    "def generate_df_for_HSQC_calculations(gen_conv_SMI_list, trg_conv_SMI_list, src_HSQC_list):\n",
    "    \"\"\"\n",
    "    Generates a DataFrame containing successfully generated SMILES along with their corresponding target SMILES\n",
    "    and a unique sample identifier. It also filters and returns new lists for source HSQC data and failed SMILES pairs.\n",
    "    \"\"\"\n",
    "    succ_gen_list =[]\n",
    "    src_HSQC_list_new = []\n",
    "    failed_list = []\n",
    "    for i, (gen_smi, trg_smi, src_HSQC) in enumerate(zip(gen_conv_SMI_list, trg_conv_SMI_list, src_HSQC_list)):\n",
    "            mol = Chem.MolFromSmiles(gen_smi)\n",
    "            if mol is not None:\n",
    "                ran_num = random.randint(0, 100000)\n",
    "                sample_id = f\"{i}_{ran_num}\"\n",
    "                succ_gen_list.append([sample_id, gen_smi, trg_smi])\n",
    "                src_HSQC_list_new.append(src_HSQC)\n",
    "            else:\n",
    "                failed_list.append([gen_smi,trg_smi])\n",
    "                continue\n",
    "\n",
    "    # Create a DataFrame of successful SMILES generations\n",
    "    df_succ_smis = pd.DataFrame(succ_gen_list, columns=['sample-id', 'SMILES', \"trg_SMILES\"])\n",
    "    return df_succ_smis, src_HSQC_list_new, failed_list\n",
    "\n",
    "def generate_df_for_COSY_calculations(gen_conv_SMI_list, trg_conv_SMI_list, src_COSY_list):\n",
    "    \"\"\"\n",
    "    Generates a DataFrame containing successfully generated SMILES along with their corresponding target SMILES\n",
    "    and a unique sample identifier. It also filters and returns new lists for source HSQC data and failed SMILES pairs.\n",
    "    \"\"\"\n",
    "    succ_gen_list =[]\n",
    "    src_COSY_list_new = []\n",
    "    failed_list = []\n",
    "    for i, (gen_smi, trg_smi, src_HSQC) in enumerate(zip(gen_conv_SMI_list, trg_conv_SMI_list, src_COSY_list)):\n",
    "            mol = Chem.MolFromSmiles(gen_smi)\n",
    "            if mol is not None:\n",
    "                ran_num = random.randint(0, 100000)\n",
    "                sample_id = f\"{i}_{ran_num}\"\n",
    "                succ_gen_list.append([sample_id, gen_smi, trg_smi])\n",
    "                src_COSY_list_new.append(src_HSQC)\n",
    "            else:\n",
    "                failed_list.append([gen_smi,trg_smi])\n",
    "                continue\n",
    "\n",
    "    # Create a DataFrame of successful SMILES generations\n",
    "    df_succ_smis = pd.DataFrame(succ_gen_list, columns=['sample-id', 'SMILES', \"trg_SMILES\"])\n",
    "    return df_succ_smis, src_COSY_list_new, failed_list\n",
    "\n",
    "\n",
    "def calculate_corr_max_prob(config, model_MMT, val_dataloader, stoi, itos):\n",
    "    \"\"\"\n",
    "    Calculates and aggregates the probabilities of correct token predictions and maximum probabilities\n",
    "    across all batches in a validation dataloader using a given model.\n",
    "    \"\"\"\n",
    "    aggregated_corr_prob_multi, aggregated_corr_prob_avg, aggregated_max_prob_multi, aggregated_max_prob_avg =[],[],[],[]\n",
    "    prob_dict_results = {}\n",
    "    for idx, data_dict in enumerate(tqdm(val_dataloader)):\n",
    "\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC, src_COSY = vgmmt.run_model(model_MMT, data_dict, config) \n",
    "        trg_tensor, corr_token_prob, trg_tensor_max, max_token_prob = predict_prop_correct_max_sequence_3(model_MMT, stoi, memory, src_padding_mask, trg_enc_SMI, config)\n",
    "\n",
    "        # Ensure we're working with 2D tensors even for single molecules\n",
    "        if corr_token_prob.dim() == 1:\n",
    "            corr_token_prob = corr_token_prob.unsqueeze(1)\n",
    "            max_token_prob = max_token_prob.unsqueeze(1)\n",
    "        if isinstance(trg_tensor, int):\n",
    "            trg_tensor = [trg_tensor]\n",
    "        if isinstance(trg_tensor_max, int):\n",
    "            trg_tensor_max = [trg_tensor_max]\n",
    "\n",
    "        for corr_prob_list, max_prob_list, token_list, token_list_max in zip(corr_token_prob.T, max_token_prob.T, trg_tensor, trg_tensor_max):\n",
    "            seq_corr_probs, seq_max_probs  = [], []\n",
    "            for corr_prob, max_prob, token in zip(corr_prob_list, max_prob_list, token_list):                                                  \n",
    "                if token == stoi[\"<EOS>\"]:  # End of sequence\n",
    "                    break\n",
    "                seq_corr_probs.append(corr_prob.detach().item())\n",
    "                seq_max_probs.append(max_prob.detach().item())\n",
    "                    # Populate dictionaries with calculated probabilities\n",
    "\n",
    "            prob_corr_multi = reduce(operator.mul, seq_corr_probs, 1)\n",
    "            prob_corr_avg = statistics.mean(seq_corr_probs) if seq_corr_probs else 0\n",
    "            prob_max_multi = reduce(operator.mul, seq_max_probs, 1)\n",
    "            prob_max_avg = statistics.mean(seq_max_probs) if seq_max_probs else 0\n",
    "\n",
    "            aggregated_corr_prob_multi.append(prob_corr_multi)\n",
    "            aggregated_corr_prob_avg.append(prob_corr_avg)  \n",
    "            aggregated_max_prob_multi.append(prob_max_multi)\n",
    "            aggregated_max_prob_avg.append(prob_max_avg) \n",
    "        #import IPython; IPython.embed();\n",
    "\n",
    "\n",
    "    prob_dict_results[\"aggregated_corr_prob_multi\"] = aggregated_corr_prob_multi\n",
    "    prob_dict_results[\"aggregated_corr_prob_avg\"] = aggregated_corr_prob_avg\n",
    "    prob_dict_results[\"aggregated_max_prob_multi\"] = aggregated_max_prob_multi\n",
    "    prob_dict_results[\"aggregated_max_prob_avg\"] = aggregated_max_prob_avg\n",
    "    return prob_dict_results\n",
    "\n",
    "\n",
    "def evaluate_greedy_2(model, stoi, itos, val_dataloader, config, randomize=False):\n",
    "    \"\"\"\n",
    "    Evaluates the greedy generation approach over a dataset.\n",
    "    \"\"\"    \n",
    "    gen_conv_SMI_list = []\n",
    "    trg_conv_SMI_list = []\n",
    "    src_HSQC_list = []\n",
    "    src_COSY_list = []\n",
    "    token_probs_list = []\n",
    "    data_dict_list = []\n",
    "    # generate all the smiles of trg and greedy gen\n",
    "    for i, data_dict in tqdm(enumerate(val_dataloader)):\n",
    "        #import IPython; IPython.embed();\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC, src_COSY = vgmmt.run_model(model,\n",
    "                                                                       data_dict, \n",
    "                                                                       config)\n",
    "        #print(\"eval_greedy\")\n",
    "        #print(src_HSQC)\n",
    "        greedy_tensor, greedy_token_prob = greedy_sequence_2(model, stoi, itos, memory, src_padding_mask, config)\n",
    "        gen_conv_SMI = hf.tensor_to_smiles(greedy_tensor, itos)\n",
    "        #gen_conv_SMI, token_probs = ttf.tensor_to_smiles_and_prob(greedy_tensor.squeeze(1), greedy_token_prob, itos)\n",
    "        token_probs_list.append(greedy_token_prob)\n",
    "        gen_conv_SMI_list.extend(gen_conv_SMI)\n",
    "        #gen_conv_SMI_list = gen_conv_SMI_list + gen_conv_SMI\n",
    "        \n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"]\n",
    "        trg_enc_SMI = trg_enc_SMI.transpose(0, 1)\n",
    "        trg_SMI_input = trg_enc_SMI[1:, :] # Remove <EOS> token from target sequence\n",
    "        trg_conv_SMI = hf.tensor_to_smiles(trg_SMI_input, itos)\n",
    "        trg_conv_SMI_list = trg_conv_SMI_list + trg_conv_SMI\n",
    "        src_HSQC_list.extend(src_HSQC)\n",
    "        src_COSY_list.extend(src_COSY)\n",
    "        data_dict_list.append(data_dict)\n",
    "    # Calculate validity of gen smiles\n",
    "    validity_term = hf.get_validity_term(gen_conv_SMI_list) \n",
    "    # Calculate tanimoto similarity\n",
    "    if randomize == True:\n",
    "        random.shuffle(gen_conv_SMI_list)\n",
    "\n",
    "    tanimoto_mean, tanimoto_std_dev, failed_pairs, tanimoto_scores_, tanimoto_scores_all, gen_conv_SMI_list_, trg_conv_SMI_list_, idx_list = hf.calculate_tanimoto_similarity_2(gen_conv_SMI_list, trg_conv_SMI_list)\n",
    "\n",
    "    results_dict = {\n",
    "            'gen_conv_SMI_list': gen_conv_SMI_list,\n",
    "            'trg_conv_SMI_list': trg_conv_SMI_list,\n",
    "            'gen_conv_SMI_list_': gen_conv_SMI_list_,\n",
    "            'trg_conv_SMI_list_': trg_conv_SMI_list_,            \n",
    "            'idx_list': idx_list,\n",
    "            'token_probs_list': token_probs_list,\n",
    "            'validity_term': validity_term,\n",
    "            'tanimoto_scores_': tanimoto_scores_,\n",
    "            'tanimoto_scores_all': tanimoto_scores_all,\n",
    "            'data_dict_list': data_dict_list,\n",
    "            'failed':failed_pairs}\n",
    "    return results_dict, src_HSQC_list, src_COSY_list    \n",
    "\n",
    "\n",
    "\n",
    "def predict_prop_correct_max_sequence_3(model, stoi, memory, src_padding_mask, trg_enc_SMI, config):\n",
    "    \"\"\"\n",
    "    Predicts the properties of each token in a sequence generated by a transformer model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define the initial target tensor with <SOS> tokens\n",
    "    N = memory.size(1)\n",
    "    trg_tensor = torch.full((1, N), stoi[\"<SOS>\"], dtype=torch.long, device=config.device)\n",
    "    trg_tensor_max = torch.full((1, N), stoi[\"<SOS>\"], dtype=torch.long, device=config.device)\n",
    "\n",
    "    # Token probabilities containers\n",
    "    corr_token_prob, max_token_prob = [], []\n",
    "\n",
    "    # Transpose target encoded SMILES and remove <EOS> token\n",
    "    trg_enc_SMI_T = trg_enc_SMI.transpose(0, 1)\n",
    "    real_trg = trg_enc_SMI_T[1:, :]\n",
    "    \n",
    "    # Iterate over each token in the target sequence\n",
    "    with torch.no_grad():\n",
    "        for idx in range(real_trg.shape[0]):\n",
    "            # Prepare input for the decoder\n",
    "            gen_seq_length, N = trg_tensor.shape\n",
    "            gen_positions = torch.arange(gen_seq_length).unsqueeze(1).expand(gen_seq_length, N).to(config.device)\n",
    "            embedding_gen = model.dropout2(model.embed_trg(trg_tensor) + model.pe_trg(gen_positions))\n",
    "            gen_mask = model.generate_square_subsequent_mask(gen_seq_length).to(config.device)\n",
    "\n",
    "            # Generate output from the decoder\n",
    "            output = model.decoder(embedding_gen, memory, tgt_mask=gen_mask, memory_key_padding_mask=src_padding_mask)\n",
    "            output = model.fc_out(output)\n",
    "            probabilities = F.softmax(output / config.temperature, dim=2)\n",
    "\n",
    "            # Process token probabilities\n",
    "            next_word = torch.argmax(probabilities[-1], dim=1)\n",
    "            max_prob = probabilities[-1].gather(1, next_word.unsqueeze(-1)).squeeze()\n",
    "            max_token_prob.append(max_prob)\n",
    "\n",
    "            # Update target tensor with max probability token\n",
    "            trg_tensor_max = torch.cat((trg_tensor_max, next_word.unsqueeze(0)), dim=0)\n",
    "\n",
    "            # Correct token probability\n",
    "            if idx <= real_trg.shape[0]:\n",
    "                corr_probability = probabilities[-1].gather(1, real_trg[idx].unsqueeze(-1)).squeeze()\n",
    "                corr_token_prob.append(corr_probability)\n",
    "\n",
    "            # Update target tensor with actual next token\n",
    "            next_word = real_trg[idx].unsqueeze(0)\n",
    "            trg_tensor = torch.cat((trg_tensor, next_word), dim=0)\n",
    "\n",
    "    #import IPython; IPython.embed();\n",
    "    # Organize and return probabilities\n",
    "    max_token_prob = torch.stack(max_token_prob)#.transpose(0, 1)\n",
    "    corr_token_prob = torch.stack(corr_token_prob)#.transpose(0, 1)\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    # Remove <SOS> token from target sequences\n",
    "    trg_tensor = trg_tensor.transpose(0, 1)[:, 1:]\n",
    "    trg_tensor_max = trg_tensor_max.transpose(0, 1)[:, 1:]\n",
    "    return trg_tensor, corr_token_prob, trg_tensor_max, max_token_prob\n",
    "\n",
    "\n",
    "def run_model_analysis(config, model_MMT, val_dataloader, stoi, itos):\n",
    "    #import IPython; IPython.embed();\n",
    "    print(\"calculate_corr_max_prob\")\n",
    "\n",
    "    prob_dict_results = calculate_corr_max_prob(config, model_MMT, val_dataloader, stoi, itos)\n",
    "    try:\n",
    "        final_prob_max_multi_sum = sum(prob_dict_results[\"aggregated_max_prob_multi\"])\n",
    "        final_prob_max_multi_avg = statistics.mean(prob_dict_results[\"aggregated_max_prob_multi\"])\n",
    "        final_prob_max_avg_avg = statistics.mean(prob_dict_results[\"aggregated_max_prob_avg\"])\n",
    "        final_prob_corr_multi_sum = sum(prob_dict_results[\"aggregated_corr_prob_multi\"])\n",
    "        final_prob_corr_multi_avg = statistics.mean(prob_dict_results[\"aggregated_corr_prob_multi\"])\n",
    "        final_prob_corr_avg_avg = statistics.mean(prob_dict_results[\"aggregated_corr_prob_avg\"])\n",
    "    except:\n",
    "        print(\"failed statistics\")\n",
    "\n",
    "    print(\"evaluate_greedy_2\")\n",
    "    results_dict, src_HSQC_list, src_COSY_list = evaluate_greedy_2(model_MMT, stoi, itos, val_dataloader, config, randomize=False)\n",
    "\n",
    "    trg_conv_SMI_list = results_dict[\"trg_conv_SMI_list\"]\n",
    "    gen_conv_SMI_list = results_dict[\"gen_conv_SMI_list\"]\n",
    "\n",
    "    print(\"generate_df_for_HSQC_calculations\")\n",
    "    df_succ_smis, src_HSQC_list, failed_list = generate_df_for_HSQC_calculations(gen_conv_SMI_list, trg_conv_SMI_list, src_HSQC_list)\n",
    "    df_succ_smis, src_COSY_list, failed_list = generate_df_for_COSY_calculations(gen_conv_SMI_list, trg_conv_SMI_list, src_COSY_list)\n",
    "    tensor_HSQC = prepare_HSQC_data_from_src_2(src_HSQC_list)\n",
    "    tensor_COSY = prepare_COSY_data_from_src_2(src_COSY_list)\n",
    "\n",
    "    print(\"run_sgnn_sim_calculations_if_possible_return_spectra\")\n",
    "    #sgnn_avg_sim_error, HSQC_sim_error_list = ttf.run_sgnn_sim_calculations_if_possible(df_succ_smis, tensor_HSQC, vgmmt.sgnn_means_stds, config)\n",
    "    avg_sim_error_HSQC, avg_sim_error_COSY, HSQC_sim_error_list, COSY_sim_error_list, batch_data = ttf.run_sgnn_sim_calculations_if_possible_return_spectra(df_succ_smis, tensor_HSQC, tensor_COSY, vgmmt.sgnn_means_stds, config)\n",
    "\n",
    "    results_dict[\"HSQC_sim_error_list\"] = HSQC_sim_error_list\n",
    "    results_dict[\"COSY_sim_error_list\"] = COSY_sim_error_list\n",
    "    results_dict[\"batch_data\"] = batch_data\n",
    "    results_dict[\"df_succ_smis\"] = df_succ_smis\n",
    "    results_dict[\"tensor_HSQC\"] = tensor_HSQC\n",
    "    results_dict[\"tensor_COSY\"] = tensor_COSY\n",
    "    return prob_dict_results, results_dict\n",
    "\n",
    "\n",
    "\n",
    "def load_data(config, stoi, stoi_MF, single=True, mode=\"val\"):\n",
    "    \"\"\"Loads the dataset and Multimodal Transformer (MMT) model.\"\"\"\n",
    "\n",
    "    # Load and prepare the validation dataset\n",
    "    data = MultimodalData(config, stoi, stoi_MF, mode=mode)\n",
    "    if single:\n",
    "        dataloader = DataLoader(data, \n",
    "                                    batch_size=1, \n",
    "                                    shuffle=False, \n",
    "                                    collate_fn=collate_fn,\n",
    "                                    drop_last=True, \n",
    "                                    worker_init_fn=worker_init_fn)\n",
    "    else:\n",
    "        dataloader = DataLoader(data, \n",
    "                            batch_size=config.batch_size, \n",
    "                            shuffle=False, \n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last=False, \n",
    "                            worker_init_fn=worker_init_fn)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "\n",
    "def load_MMT_model(config):\n",
    "    \"\"\"Loads the dataset and Multimodal Transformer (MMT) model.\"\"\"\n",
    "    # Initialize and load the multi-GPU model\n",
    "\n",
    "    multi_gpu_model = TransformerMultiGPU(config)\n",
    "    multi_gpu_model = multi_gpu_model.load_from_checkpoint(config.checkpoint_path, config=config)\n",
    "    multi_gpu_model.model.to(\"cuda\")\n",
    "\n",
    "    return multi_gpu_model.model\n",
    "\n",
    "\n",
    "\n",
    "def load_CLIP_model(config):\n",
    "\n",
    "    CLIP_multi_gpu_model = CLIPMultiGPU(config)\n",
    "    checkpoint_path = config.CLIP_model_path\n",
    "    CLIP_model = CLIP_multi_gpu_model.load_from_checkpoint(config=config, checkpoint_path=checkpoint_path)\n",
    "\n",
    "    #CLIP_model, optimizer = CLIP_make(config, stoi, stoi_MF, itos)\n",
    "    CLIP_model.to(config.device)\n",
    "\n",
    "    return CLIP_model.CLIP_model\n",
    "\n",
    "\n",
    "\n",
    "def load_BLIP_model(config):\n",
    "\n",
    "    BLIP_multi_gpu_model = BLIPMultiGPU(config)\n",
    "    checkpoint_path = config.BLIP_model_path\n",
    "    BLIP_model = BLIP_multi_gpu_model.load_from_checkpoint(config=config, checkpoint_path=checkpoint_path)\n",
    "\n",
    "    #CLIP_model, optimizer = CLIP_make(config, stoi, stoi_MF, itos)\n",
    "    BLIP_model.to(config.device)\n",
    "\n",
    "    return BLIP_model.BLIP_model\n",
    "\n",
    "\n",
    "def run_test_mns_performance_CLIP_3(config, \n",
    "                                model_MMT,\n",
    "                                model_CLIP,\n",
    "                                val_dataloader,                                \n",
    "                                 stoi, \n",
    "                                 itos, \n",
    "                                 MW_filter):\n",
    "    ### Same code as function: run_multinomial_sampling\n",
    "    n_times = config.multinom_runs\n",
    "    results_dict = {} #defaultdict(list)\n",
    "    temperature_orig = config.temperature\n",
    "    for idx, data_dict in enumerate(val_dataloader):\n",
    "        if idx % 10 == 0:\n",
    "            print(idx)\n",
    "        gen_conv_SMI_list, trg_conv_SMI_list, token_probs_list, src_HSQC_list, prob_list = [], [], [], [], []\n",
    "        data_dict_dup = rbgvm.duplicate_dict(data_dict, 128)\n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"][0]\n",
    "        trg_conv_SMI = hf.tensor_to_smiles(trg_enc_SMI[1:], itos)\n",
    "        # to confirm that this smies is valid\n",
    "        if Chem.MolFromSmiles(trg_conv_SMI) == None:\n",
    "            continue\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC, src_COSY = vgmmt.run_model(model_MMT,\n",
    "                                                                                    data_dict_dup, \n",
    "                                                                                    config)\n",
    "        counter = 1\n",
    "        while len(gen_conv_SMI_list)<n_times:\n",
    "            # increase the temperature if not enough different molecules get generated               \n",
    "            print(counter, len(gen_conv_SMI_list), config.temperature)\n",
    "            if counter%20==0:\n",
    "                print(trg_conv_SMI)\n",
    "                break\n",
    "            multinom_tensor, multinom_token_prob = multinomial_sequence_multi_2(model_MMT, memory, src_padding_mask, stoi, config)\n",
    "            gen_conv_SMI, token_probs = hf.tensor_to_smiles_and_prob_2(multinom_tensor, multinom_token_prob, itos)\n",
    "\n",
    "            # import IPython; IPython.embed();\n",
    "            gen_conv_SMI, token_probs = filter_probs_and_valid_smiles_and_canonicolize(gen_conv_SMI, token_probs)   ### for 10.000 commented out\n",
    "            if MW_filter == True:\n",
    "                gen_conv_SMI, token_probs = filter_for_MW_2(trg_conv_SMI, gen_conv_SMI, token_probs)\n",
    "            gen_conv_SMI_list.extend(gen_conv_SMI)\n",
    "            prob_list.extend(token_probs)\n",
    "            gen_conv_SMI_list, prob_list = deduplicate_smiles(gen_conv_SMI_list, prob_list)\n",
    "            #gen_conv_SMI_list = list(set(gen_conv_SMI_list)) ### for 10.000 commented out\n",
    "            counter += 1\n",
    "            config.temperature = config.temperature + 0.1  \n",
    "        config.temperature = temperature_orig\n",
    "        gen_conv_SMI_list = gen_conv_SMI_list[:n_times]\n",
    "        prob_list = prob_list[:n_times]\n",
    "        trg_conv_SMI_list = [trg_conv_SMI for i in range(len(gen_conv_SMI_list))]\n",
    "        data_dict_dup_CLIP = rbgvm.duplicate_dict(data_dict, len(gen_conv_SMI_list))\n",
    "        if len(gen_conv_SMI_list) != 0:\n",
    "            mean_loss, losses, logits, targets, dot_similarity= model_CLIP.inference(data_dict_dup_CLIP, \n",
    "                                                                                gen_conv_SMI_list)\n",
    "\n",
    "            combined_list = [[smile, num.item(), dot_sim.item(), prob] for smile, num, dot_sim, prob in zip(gen_conv_SMI_list, losses, dot_similarity, prob_list)]\n",
    "            ### Sort by the lowest similarity\n",
    "            #sorted_list = sorted(combined_list, key=lambda x: x[1])\n",
    "\n",
    "            combined_list, failed_combined_list = add_tanimoto_similarity(trg_conv_SMI, combined_list)\n",
    "            combined_list, batch_data = rbgvm.add_HSQC_COSY_error(config, combined_list, data_dict_dup, gen_conv_SMI_list, trg_conv_SMI, config.multinom_runs) # config.MMT_batch\n",
    "\n",
    "            sorted_list = sorted(combined_list, key=lambda x: -x[4]) # SMILES = 0, losses =1, dot_sim= 2, propb = 3, tanimoto = 4\n",
    "\n",
    "            results_dict[trg_conv_SMI] = [sorted_list, batch_data]\n",
    "        else:\n",
    "            results_dict[trg_conv_SMI] = [None, None]\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "def run_test_performance_CLIP_greedy_3(config, \n",
    "                                 model_MMT,\n",
    "                                 model_CLIP,\n",
    "                                 val_dataloader,                                        \n",
    "                                 stoi, \n",
    "                                 stoi_MF, \n",
    "                                 itos, \n",
    "                                 itos_MF):\n",
    "\n",
    "\n",
    "    results_dict = defaultdict(list)\n",
    "    gen_conv_SMI_list = []\n",
    "    token_probs_list = []\n",
    "    src_HSQC_list = []\n",
    "    failed = []\n",
    "\n",
    "    # generate all the smiles of trg and greedy gen\n",
    "    for idx, data_dict in enumerate(val_dataloader):\n",
    "        if idx % 10 == 0:\n",
    "            print(idx)\n",
    "        data_dict_dup = rbgvm.duplicate_dict(data_dict, 1)  # Maybe should hardcode it here as 64 - it will always cut it down to the number needed with ntimes\n",
    "\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC = vgmmt.run_model(model_MMT,\n",
    "                                                                        data_dict_dup, \n",
    "                                                                        config)\n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"][0]\n",
    "        trg_conv_SMI = hf.tensor_to_smiles(trg_enc_SMI[1:], itos)\n",
    "\n",
    "        greedy_tensor, greedy_token_prob = greedy_sequence_2(model_MMT, stoi, itos, memory, src_padding_mask, config)\n",
    "        gen_conv_SMI, token_probs = hf.tensor_to_smiles_and_prob(greedy_tensor.squeeze(1), greedy_token_prob, itos)\n",
    "        tan_sim = try_calculate_tanimoto_from_two_smiles(trg_conv_SMI, gen_conv_SMI, 512, extra_info = False)\n",
    "        mean_loss, losses, logits, targets, dot_similarity = model_CLIP.inference(data_dict_dup, gen_conv_SMI)\n",
    "\n",
    "        sgnn_avg_sim_error, sim_error_list, batch_data = rbgvm.calculate_HSQC_error(config, data_dict_dup, gen_conv_SMI)\n",
    "        combined_list =[gen_conv_SMI, losses.item(), dot_similarity.item(), tan_sim, sgnn_avg_sim_error]\n",
    "        if tan_sim == None:\n",
    "            failed.append([trg_conv_SMI, gen_conv_SMI, combined_list, batch_data])\n",
    "            continue\n",
    "        else:\n",
    "            results_dict[trg_conv_SMI] = [combined_list, batch_data]\n",
    "    #if i == config.n_samples:\n",
    "    #    break\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    return results_dict, failed\n",
    "\n",
    "def predict_corr_max_performance_metric(trg_tensor, corr_token_prob, max_token_prob, stoi):\n",
    "    \"\"\"\n",
    "    Calculates performance metrics for token predictions in sequences.\n",
    "\n",
    "    Parameters:\n",
    "    trg_tensor (torch.Tensor): The target tensor containing sequences.\n",
    "    corr_token_prob (torch.Tensor): Probabilities of correct tokens.\n",
    "    max_token_prob (torch.Tensor): Probabilities of tokens with maximum likelihood.\n",
    "    multinom_token_prob (torch.Tensor): Probabilities of tokens chosen via multinomial sampling.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Contains two dictionaries - one with aggregated probabilities and another with sample-wise probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize dictionaries for storing results\n",
    "    prop_dict, sample_dict = {}, {}\n",
    "    sample_prob_list_corr, sample_prob_list_max = [], []\n",
    "    prob_corr_multi, prob_corr_avg, prob_max_multi, prob_max_avg = [], [], [], []\n",
    "\n",
    "    # Iterate over each sequence to calculate probabilities\n",
    "    seq_corr_probs, seq_max_probs, seq_multinom_probs = [], [], []\n",
    "\n",
    "    for corr_prob, max_prob, token in zip(corr_token_prob, max_token_prob, trg_tensor[0]):\n",
    "        # Initialize lists for individual sequence probabilities\n",
    "        #import IPython; IPython.embed();\n",
    "        # Iterate over each token in the sequence\n",
    "        #for idx, (corr_prob, max_prob, multinom_prob, token) in enumerate(zip(corr_probs, max_probs, multinom_probs, tokens)):\n",
    "        if token == stoi[\"<EOS>\"]:  # End of sequence\n",
    "            break\n",
    "        seq_corr_probs.append(corr_prob.item())\n",
    "        seq_max_probs.append(max_prob.item())\n",
    "\n",
    "    # Calculate and append aggregated probabilities\n",
    "    prob_corr_multi = reduce(operator.mul, seq_corr_probs, 1)\n",
    "    prob_corr_avg = statistics.mean(seq_corr_probs) if seq_corr_probs else 0\n",
    "    prob_max_multi = reduce(operator.mul, seq_max_probs, 1)\n",
    "    prob_max_avg = statistics.mean(seq_max_probs) if seq_max_probs else 0\n",
    "\n",
    "    # Populate dictionaries with calculated probabilities\n",
    "    sample_dict = {\n",
    "        \"sample_prob_list_corr\": seq_corr_probs,\n",
    "        \"sample_prob_list_max\": seq_max_probs    \n",
    "        }\n",
    "\n",
    "    prop_dict = {\n",
    "        \"prob_corr_multi\": prob_corr_multi,\n",
    "        \"prob_corr_avg\": prob_corr_avg,\n",
    "        \"prob_max_multi\": prob_max_multi,\n",
    "        \"prob_max_avg\": prob_max_avg\n",
    "        }\n",
    "\n",
    "    return prop_dict, sample_dict\n",
    "\n",
    "## There is something wrong with the predict_corr_max_performance_metric function\n",
    "def calculate_corr_max_prob_2(config, model, stoi, val_dataloader, gen_num):\n",
    "    \n",
    "    prob_dict_results = {}\n",
    "    aggregated_corr_prob_multi = []\n",
    "    aggregated_corr_prob_avg = []\n",
    "    aggregated_max_prob_multi = []\n",
    "    aggregated_max_prob_avg = []\n",
    "    #for _ in range(2):  # Num_Runs is the number of times you want to run the entire process for randomized smiles\n",
    "\n",
    "    for idx, data_dict in enumerate(tqdm(val_dataloader)):\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC, src_COSY = vgmmt.run_model(model, data_dict, config) \n",
    "        trg_tensor, corr_token_prob, trg_tensor_max, max_token_prob = predict_prop_correct_max_sequence_3(model, stoi, memory, src_padding_mask, trg_enc_SMI, config)\n",
    "        #import IPython; IPython.embed();\n",
    "\n",
    "        prop_dict, sample_dict = predict_corr_max_performance_metric(trg_tensor, corr_token_prob, max_token_prob, stoi)\n",
    "        aggregated_corr_prob_multi.append(prop_dict[\"prob_corr_multi\"])\n",
    "        aggregated_corr_prob_avg.append(prop_dict[\"prob_corr_avg\"])  \n",
    "        aggregated_max_prob_multi.append(prop_dict[\"prob_max_multi\"])\n",
    "        aggregated_max_prob_avg.append(prop_dict[\"prob_max_avg\"]) \n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    prob_dict_results[\"aggregated_corr_prob_multi\"] = aggregated_corr_prob_multi\n",
    "    prob_dict_results[\"aggregated_corr_prob_avg\"] = aggregated_corr_prob_avg\n",
    "    prob_dict_results[\"aggregated_max_prob_multi\"] = aggregated_max_prob_multi\n",
    "    prob_dict_results[\"aggregated_max_prob_avg\"] = aggregated_max_prob_avg\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    return prob_dict_results, sample_dict\n",
    "\n",
    "\n",
    "def run_test_performance_CLIP_3(config, \n",
    "                                model_MMT,\n",
    "                                val_dataloader,                                   \n",
    "                                stoi):\n",
    "\n",
    "\n",
    "    total_results = {}\n",
    "    # Number of times to duplicate each tensor \n",
    "    gen_num = 1 # Multinomial sampling number\n",
    "    prob_dict_results, _ = calculate_corr_max_prob_2(config, model_MMT, stoi, val_dataloader, gen_num)\n",
    "    try:\n",
    "        final_prob_max_multi_sum = sum(prob_dict_results[\"aggregated_max_prob_multi\"])\n",
    "        final_prob_max_multi_avg = statistics.mean(prob_dict_results[\"aggregated_max_prob_multi\"])\n",
    "        final_prob_max_avg_avg = statistics.mean(prob_dict_results[\"aggregated_max_prob_avg\"])\n",
    "        final_prob_corr_multi_sum = sum(prob_dict_results[\"aggregated_corr_prob_multi\"])\n",
    "        final_prob_corr_multi_avg = statistics.mean(prob_dict_results[\"aggregated_corr_prob_multi\"])\n",
    "        final_prob_corr_avg_avg = statistics.mean(prob_dict_results[\"aggregated_corr_prob_avg\"])\n",
    "    except:\n",
    "        print(\"failed statistics\")\n",
    "    total_results[\"statistics_multiplication_avg\"] = [final_prob_corr_multi_avg,\n",
    "                                                    final_prob_max_multi_avg]\n",
    "\n",
    "    total_results[\"statistics_multiplication_sum\"] = [final_prob_corr_multi_sum,\n",
    "                                                    final_prob_max_multi_sum]\n",
    "\n",
    "    total_results[\"statistics_avg_avg\"] = [final_prob_corr_avg_avg,\n",
    "                                            final_prob_max_avg_avg]\n",
    "    return total_results\n",
    "\n",
    "\n",
    "#__________________________________________________\n",
    "### Sample 1000 unique molecules and plot their tanimoto similartyy \n",
    "### compared to the target\n",
    "def run_multinomial_sampling(config, model_MMT, val_dataloader, itos, stoi, MW_filter=False):\n",
    "    n_times = config.multinom_runs\n",
    "    results_dict = defaultdict(list)\n",
    "    temperature_orig = config.temperature\n",
    "    for idx, data_dict in tqdm(enumerate(val_dataloader)):\n",
    "        if idx % 10 ==0:\n",
    "            print(idx)\n",
    "\n",
    "        gen_conv_SMI_list, trg_conv_SMI_list, token_probs_list, src_HSQC_list, prob_list = [], [], [], [], []\n",
    "        data_dict_dup = rbgvm.duplicate_dict(data_dict, 128)\n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"][0]\n",
    "        trg_conv_SMI = hf.tensor_to_smiles(trg_enc_SMI[1:], itos)\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC = vgmmt.run_model(model_MMT,\n",
    "                                                                   data_dict_dup, \n",
    "                                                                   config)\n",
    "        counter = 1\n",
    "        while len(gen_conv_SMI_list)<n_times:\n",
    "            # increase the temperature if not enough different molecules get generated               \n",
    "            if counter%20==0:\n",
    "                print(trg_conv_SMI)\n",
    "                break\n",
    "            multinom_tensor, multinom_token_prob = multinomial_sequence_multi_2(model_MMT, memory, src_padding_mask, stoi, config)\n",
    "            gen_conv_SMI, token_probs = hf.tensor_to_smiles_and_prob_2(multinom_tensor, multinom_token_prob, itos)\n",
    "\n",
    "            # import IPython; IPython.embed();\n",
    "            gen_conv_SMI, token_probs = filter_probs_and_valid_smiles_and_canonicolize(gen_conv_SMI, token_probs)   ### for 10.000 commented out\n",
    "            if MW_filter == True:\n",
    "                gen_conv_SMI, token_probs = filter_for_MW_2(trg_conv_SMI, gen_conv_SMI, token_probs)\n",
    "            gen_conv_SMI_list.extend(gen_conv_SMI)\n",
    "            prob_list.extend(token_probs)\n",
    "            gen_conv_SMI_list, prob_list = deduplicate_smiles(gen_conv_SMI_list, prob_list)\n",
    "            #gen_conv_SMI_list = list(set(gen_conv_SMI_list)) ### for 10.000 commented out\n",
    "            counter += 1\n",
    "            config.temperature = config.temperature + 0.1    \n",
    "        gen_conv_SMI_list = gen_conv_SMI_list[:n_times]\n",
    "        prob_list = prob_list[:n_times]\n",
    "        trg_conv_SMI_list = [trg_conv_SMI for i in range(len(gen_conv_SMI_list))]\n",
    "\n",
    "        tanimoto_mean, tanimoto_std_dev, failed, tanimoto_list_all = vgmmt.calculate_tanimoto_similarity(gen_conv_SMI_list, trg_conv_SMI_list)\n",
    "        results_dict[idx].append({\n",
    "            'gen_conv_SMI_list': gen_conv_SMI_list,\n",
    "            'trg_conv_SMI_list': trg_conv_SMI_list,\n",
    "            'tanimoto_sim': tanimoto_list_all,\n",
    "            'tanimoto_mean': tanimoto_mean,\n",
    "            'tanimoto_std_dev': tanimoto_std_dev,\n",
    "            'failed': failed,\n",
    "            'prob_list': prob_list,\n",
    "        })\n",
    "        config.temperature = temperature_orig \n",
    "    return config, results_dict\n",
    "\n",
    "\n",
    "\n",
    "# Multinomial\n",
    "def multinomial_sequence_multi_2(model, memory, src_padding_mask, stoi, config):\n",
    "    # Initialization\n",
    "\n",
    "    model.eval()\n",
    "    N = memory.size(1)\n",
    "    multinom_tensor = torch.full((1, N), stoi[\"<SOS>\"], dtype=torch.long, device=config.device)\n",
    "    multinom_token_prob = []  \n",
    "\n",
    "    # Sequence Prediction\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, config.max_len):\n",
    "            # [The same logic you already had]\n",
    "            gen_seq_length, N = multinom_tensor.shape\n",
    "            gen_positions = (\n",
    "                torch.arange(0, gen_seq_length)\n",
    "                .unsqueeze(1)\n",
    "                .expand(gen_seq_length, N)\n",
    "                .to(config.device))\n",
    "\n",
    "            embedding_gen = model.dropout2((model.embed_trg(multinom_tensor) + model.pe_trg(gen_positions)))\n",
    "            gen_mask = model.generate_square_subsequent_mask(gen_seq_length).to(config.device)\n",
    "            output = model.decoder(embedding_gen, memory, tgt_mask=gen_mask, memory_key_padding_mask=src_padding_mask)\n",
    "            output = model.fc_out(output)\n",
    "\n",
    "            probabilities = F.softmax(output / config.temperature, dim=2)\n",
    "            ## Capturing the probability of the next predicted token with multinomial sampling\n",
    "            next_word = torch.multinomial(probabilities[-1, :, :], 1)  \n",
    "            sel_prob = probabilities[-1, :, :].gather(1, next_word).squeeze()  # Get the probability of the predicted token\n",
    "            multinom_token_prob.append(sel_prob)\n",
    "            next_word = next_word.squeeze(1).unsqueeze(0)\n",
    "            multinom_tensor = torch.cat((multinom_tensor, next_word), dim=0)\n",
    "    # import IPython; IPython.embed();\n",
    "    multinom_token_prob = torch.stack(multinom_token_prob) \n",
    "\n",
    "    # remove \"SOS\" token\n",
    "    multinom_tensor = multinom_tensor[1:,:]\n",
    "    multinom_token_prob = multinom_token_prob[1:,:]\n",
    "    \n",
    "    return multinom_tensor, multinom_token_prob\n",
    "\n",
    "\n",
    "def run_greedy_sampling(config, model_MMT, val_dataloader, itos, stoi):\n",
    "\n",
    "    results_dict = defaultdict(list)\n",
    "    #model_MMT, val_dataloader = vgmmt.load_data_and_MMT_model(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "\n",
    "    gen_conv_SMI_list, trg_conv_SMI_list, prob_list, src_HSQC_list, src_COSY_list = [], [], [], [], []\n",
    "    for idx, data_dict in enumerate(val_dataloader):\n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"]\n",
    "        trg_conv_SMI = hf.tensor_to_smiles(trg_enc_SMI.T[1:], itos)\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC, src_COSY = vgmmt.run_model(model_MMT,\n",
    "                                                                   data_dict, \n",
    "                                                                   config)\n",
    "\n",
    "        greedy_tensor, greedy_token_prob = greedy_sequence_2(model_MMT, stoi, itos, memory, src_padding_mask, config)\n",
    "\n",
    "        gen_conv_SMI, token_probs = hf.tensor_to_smiles_and_prob(greedy_tensor, greedy_token_prob.T, itos)\n",
    "\n",
    "        gen_conv_SMI_list.extend(gen_conv_SMI)\n",
    "        trg_conv_SMI_list.extend(trg_conv_SMI)\n",
    "        prob_list.extend(token_probs)\n",
    "        src_HSQC_list.extend(src_HSQC)\n",
    "        src_COSY_list.extend(src_COSY)\n",
    "        \n",
    "    tanimoto_mean, tanimoto_std_dev, failed, tanimoto_list_all = vgmmt.calculate_tanimoto_similarity(gen_conv_SMI_list, trg_conv_SMI_list)\n",
    "    results_dict = {\n",
    "        'gen_conv_SMI_list': gen_conv_SMI_list,\n",
    "        'trg_conv_SMI_list': trg_conv_SMI_list,\n",
    "        'tanimoto_sim': tanimoto_list_all,\n",
    "        'tanimoto_mean': tanimoto_mean,\n",
    "        'tanimoto_std_dev': tanimoto_std_dev,\n",
    "        'failed': failed,\n",
    "        'prob_list': prob_list,\n",
    "        \"src_HSQC_list\": src_HSQC_list,\n",
    "        \"src_COSY_list\": src_COSY_list,\n",
    "        }\n",
    "    \n",
    "    return config, results_dict\n",
    "\n",
    "    \n",
    "\n",
    "def greedy_sequence_2(model, stoi, itos, memory, src_padding_mask, config):\n",
    "    \"\"\"\n",
    "    Generates a sequence of tokens using a greedy approach.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    N = memory.size(1)  # Batch size\n",
    "    greedy_tensor = torch.full((1, N), stoi[\"<SOS>\"], dtype=torch.long, device=config.device)\n",
    "    greedy_token_prob = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(config.max_len):\n",
    "            gen_seq_length = greedy_tensor.size(0)\n",
    "            gen_positions = torch.arange(gen_seq_length, device=config.device).unsqueeze(1).expand(gen_seq_length, N)\n",
    "            embedding_gen = model.embed_trg(greedy_tensor) + model.pe_trg(gen_positions)\n",
    "            if model.training:\n",
    "                embedding_gen = model.dropout2((embedding_gen))\n",
    "            gen_mask = model.generate_square_subsequent_mask(gen_seq_length).to(config.device)\n",
    "\n",
    "            output = model.decoder(embedding_gen, memory, tgt_mask=gen_mask, memory_key_padding_mask=src_padding_mask)\n",
    "           \n",
    "            output = model.fc_out(output)\n",
    "            probabilities = F.softmax(output / config.temperature, dim=2)\n",
    "\n",
    "            next_word = torch.argmax(probabilities[-1, :, :], dim=1)\n",
    "            max_prob = probabilities[-1, :, :].gather(1, next_word.unsqueeze(-1)).squeeze()\n",
    "            greedy_token_prob.append(max_prob)\n",
    "            next_word = next_word.unsqueeze(0)\n",
    "\n",
    "            greedy_tensor = torch.cat((greedy_tensor, next_word), dim=0)\n",
    "            if (next_word == 0).all():\n",
    "                break\n",
    "\n",
    "    greedy_token_prob = torch.stack(greedy_token_prob)\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    # Remove \"SOS\" token\n",
    "    greedy_tensor = greedy_tensor[1:]\n",
    "    greedy_token_prob = greedy_token_prob\n",
    "\n",
    "\n",
    "    # Handle single molecule case\n",
    "    if N == 1:\n",
    "        greedy_tensor = greedy_tensor#.squeeze(1)\n",
    "        greedy_token_prob = greedy_token_prob.unsqueeze(-1)\n",
    "    # else:\n",
    "    #     greedy_tensor = greedy_tensor.transpose(0, 1)\n",
    "    #     greedy_token_prob = greedy_token_prob.transpose(0, 1)\n",
    "    \n",
    "    return greedy_tensor, greedy_token_prob\n",
    "\n",
    "\n",
    "def deduplicate_smiles(smiles_list, prob_list):\n",
    "    # Create a dictionary to hold unique smiles and their corresponding probabilities\n",
    "    unique_smiles = {}\n",
    "\n",
    "    # Loop over the SMILES and their corresponding probabilities\n",
    "    for smi, prob in zip(smiles_list, prob_list):\n",
    "        if smi not in unique_smiles:\n",
    "            unique_smiles[smi] = prob\n",
    "\n",
    "    # Extracting the deduplicated lists\n",
    "    deduped_smiles = list(unique_smiles.keys())\n",
    "    deduped_probs = list(unique_smiles.values())\n",
    "\n",
    "    return deduped_smiles, deduped_probs\n",
    "\n",
    "# Function to filter valid SMILES\n",
    "def filter_probs_and_valid_smiles_and_canonicolize(smiles_list, token_probs, canonical=True, isomericSmiles=False):\n",
    "    valid_smiles = []\n",
    "    valid_token_probs = []\n",
    "    for smi, prob in zip(smiles_list, token_probs):\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol is not None:\n",
    "            gen_smi = Chem.MolToSmiles(mol, canonical=canonical, doRandom=False, isomericSmiles=isomericSmiles)\n",
    "            valid_smiles.append(gen_smi)\n",
    "            valid_token_probs.append(prob)\n",
    "    return valid_smiles, valid_token_probs\n",
    "\n",
    "\n",
    "# Function to calculate the rounded molecular weight\n",
    "def calc_rounded_mw(smi):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        return round(Descriptors.MolWt(mol))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def filter_for_MW(trg_conv_SMI, gen_conv_SMI):\n",
    "\n",
    "    # Calculate the rounded molecular weight of the target molecule\n",
    "    trg_mw = calc_rounded_mw(trg_conv_SMI)\n",
    "\n",
    "    # Filter the list based on molecular weight\n",
    "    filtered_gen_smis = [smi for smi in gen_conv_SMI if calc_rounded_mw(smi) == trg_mw]  \n",
    "    return filtered_gen_smis\n",
    "\n",
    "\n",
    "def filter_for_MW_2(trg_conv_SMI, gen_conv_SMI, prob_list):\n",
    "\n",
    "    # Calculate the rounded molecular weight of the target molecule\n",
    "    trg_mw = calc_rounded_mw(trg_conv_SMI)\n",
    "\n",
    "    # Filter the list based on molecular weight\n",
    "    filtered_gen_smis = [smi for (smi, token_prob) in zip(gen_conv_SMI, prob_list) if calc_rounded_mw(smi) == trg_mw]  \n",
    "    filtered_prob_list = [token_prob for (smi, token_prob) in zip(gen_conv_SMI, prob_list) if calc_rounded_mw(smi) == trg_mw]  \n",
    "    return filtered_gen_smis, filtered_prob_list\n",
    "\n",
    "    \n",
    "def filter_dict_results_for_MW(results_dict):\n",
    "    tanimoto_values = []\n",
    "    gen_trg_smi_lists = []\n",
    "    for i, idx in enumerate(results_dict.keys()):\n",
    "        # Collect all tanimoto_list_all for the current idx\n",
    "\n",
    "        for result in results_dict[idx]:\n",
    "            trg_smi = result[\"trg_conv_SMI_list\"][0]\n",
    "            smi_list = result[\"gen_conv_SMI_list\"]\n",
    "\n",
    "            # Calculate the rounded molecular weight of the target molecule\n",
    "            trg_mw = calc_rounded_mw(trg_smi)\n",
    "\n",
    "            # Filter the list based on molecular weight\n",
    "            filtered_gen_smis = [smi for smi in smi_list if calc_rounded_mw(smi) == trg_mw]  \n",
    "            trg_conv_SMI_list = [trg_smi for i in range(len(filtered_gen_smis))]\n",
    "            gen_trg_smi_lists.append([filtered_gen_smis, trg_conv_SMI_list])\n",
    "            tanimoto_mean, tanimoto_std_dev, failed, tanimoto_list_all = vgmmt.calculate_tanimoto_similarity(filtered_gen_smis, trg_conv_SMI_list)\n",
    "            tanimoto_values.append(tanimoto_list_all)\n",
    "    return tanimoto_values, gen_trg_smi_lists\n",
    "\n",
    "\n",
    "def plot_hist_MN_sampling(config, results_dict):\n",
    "    # Number of unique idx values\n",
    "    num_idx = len(results_dict)\n",
    "\n",
    "    # Create a figure with subplots (if there are many idx, you might need to adjust the size and layout)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for i, idx in enumerate(results_dict.keys()):\n",
    "        # Collect all tanimoto_list_all for the current idx\n",
    "        tanimoto_values = []\n",
    "        for result in results_dict[idx]:\n",
    "            tanimoto_values.extend(result['tanimoto_sim'])\n",
    "        #tanimoto_values = [val for result in results_dict[idx] for val in result['tanimoto_sim'] if val != 0]\n",
    "\n",
    "        # Create a subplot for each idx\n",
    "       \n",
    "        plt.hist(tanimoto_values, bins=100+idx*3, alpha=0.7, label=f'Idx {idx}, Nr: {len(tanimoto_values)}')\n",
    "    plt.xlabel('Tanimoto Similarity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of Tanimoto Similarity for {idx+1} Molecule generations')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_hist_MN_sampling_all(config, results_dict):\n",
    "    # Number of unique idx values\n",
    "    num_idx = len(results_dict)\n",
    "\n",
    "    # Create a figure with subplots (if there are many idx, you might need to adjust the size and layout)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    tanimoto_values = []\n",
    "    for i, key in enumerate(results_dict.keys()):\n",
    "        # Collect all tanimoto_list_all for the current idx\n",
    "        for result in results_dict[key]:\n",
    "            tanimoto_values.extend(result['tanimoto_sim'])\n",
    "        #tanimoto_values = [val for result in results_dict[idx] for val in result['tanimoto_sim'] if val != 0]\n",
    "\n",
    "        # Create a subplot for each idx\n",
    "       \n",
    "    plt.hist(tanimoto_values, bins=100+idx*3, alpha=0.7, label=f'Idx {idx}, Nr: {len(tanimoto_values)}')\n",
    "    plt.xlabel('Tanimoto Similarity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of Tanimoto Similarity for {i+1} Molecule generations')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_hist_MN_sampling_filtered(config, results_dict):\n",
    "    ##filter out all molecules with the same MW as the target\n",
    "\n",
    "    # Number of unique idx values\n",
    "    num_idx = len(results_dict)\n",
    "    tanimoto_values, gen_trg_smi_lists = filter_dict_results_for_MW(results_dict)\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot each list in the histogram\n",
    "    for idx, lst in enumerate(tanimoto_values):\n",
    "        \n",
    "        plt.hist(lst, bins=20, alpha=0.5, label=f'List {idx+1}, Nr: {len(lst)}')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Tanimoto Similarity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of Tanimoto Similarity with same MW')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    return tanimoto_values, gen_trg_smi_lists\n",
    "\n",
    "\n",
    "def calc_percentage_top_x_correct(results_dict, top_x):\n",
    "    count_yes = 0\n",
    "    count_no = 0\n",
    "    for i, idx in enumerate(results_dict.keys()):\n",
    "        # Collect all tanimoto_list_all for the current idx\n",
    "\n",
    "        for result in results_dict[idx]:\n",
    "            tanimoto_sim = result[\"tanimoto_sim\"]\n",
    "            tanimoto_sim = tanimoto_sim[:top_x]\n",
    "            if 1 in tanimoto_sim:\n",
    "                count_yes += 1\n",
    "            else:\n",
    "                count_no += 1\n",
    "        percentage = count_yes/(count_yes +count_no)\n",
    "    return percentage\n",
    "    \n",
    "def calc_percentage_top_x_correct_greedy(results_dict):\n",
    "    count_yes = 0\n",
    "    count_no = 0\n",
    "\n",
    "    for i in results_dict[\"tanimoto_sim\"]:\n",
    "        if i==1:\n",
    "            count_yes += 1\n",
    "        else:\n",
    "            count_no += 1\n",
    "\n",
    "    percentage = count_yes/(count_yes + count_no)\n",
    "    return percentage\n",
    "    \n",
    "\n",
    "def run_precentage_calculation(config, itos, stoi, stoi_MF, MW_filter):\n",
    "    \n",
    "    model_MMT = load_MMT_model(config)\n",
    "    val_dataloader = load_data(config, stoi, stoi_MF, single=True, mode=\"val\")  \n",
    "    config.temperature = 1\n",
    "    config, results_dict_mns_10 = run_multinomial_sampling(config, model_MMT, val_dataloader, itos, stoi, MW_filter=MW_filter)\n",
    "    top_x = 10\n",
    "    percentage_top_10 = calc_percentage_top_x_correct(results_dict_mns_10, top_x)\n",
    "    top_x = 5\n",
    "    percentage_top_5 = calc_percentage_top_x_correct(results_dict_mns_10, top_x)\n",
    "    top_x = 3\n",
    "    percentage_top_3 = calc_percentage_top_x_correct(results_dict_mns_10, top_x)\n",
    "    top_x = 1\n",
    "    percentage_top_1 = calc_percentage_top_x_correct(results_dict_mns_10, top_x)\n",
    "    \n",
    "    val_dataloader_multi = load_data(config, stoi, stoi_MF, single=False, mode=\"val\")  \n",
    "    config, results_dict_greedy = run_greedy_sampling(config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "\n",
    "    percentage_1_greedy = calc_percentage_top_x_correct_greedy(results_dict_greedy)\n",
    "\n",
    "    percentage_collection = [percentage_1_greedy, percentage_top_1, percentage_top_3, percentage_top_5, percentage_top_10]\n",
    "\n",
    "    return percentage_collection, results_dict_mns_10, results_dict_greedy\n",
    "\n",
    "    \n",
    "def add_tanimoto_similarity(trg_conv_SMI, combined_list):\n",
    "    # Generate fingerprint for the ground truth molecule\n",
    "    ground_truth_mol = Chem.MolFromSmiles(trg_conv_SMI)\n",
    "    ground_truth_fp = AllChem.GetMorganFingerprintAsBitVect(ground_truth_mol, 2, nBits=512)\n",
    "    # Calculate Tanimoto similarity and add to the list\n",
    "    new_combined_list = []\n",
    "    failed_combined_list = []\n",
    "    for item in combined_list:\n",
    "\n",
    "        smiles = item[0]\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:  # Check if the molecule is valid\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512)\n",
    "            tanimoto_similarity = DataStructs.TanimotoSimilarity(ground_truth_fp, fp)\n",
    "            item.append(tanimoto_similarity)\n",
    "            new_combined_list.append(item)\n",
    "        else:\n",
    "            item.append(None)\n",
    "            failed_combined_list.append(item)\n",
    "    return new_combined_list, failed_combined_list\n",
    "#print(combined_list)\n",
    "\n",
    "\n",
    "def try_calculate_tanimoto_from_two_smiles(smi1, smi2, nbits, extra_info = False):\n",
    "    \"\"\"This function takes two smile_stings and \n",
    "    calculates the Tanimoto similarity and returns it and prints it out\"\"\"\n",
    "    \n",
    "    try:\n",
    "        pattern1 = Chem.MolFromSmiles(smi1)\n",
    "        pattern2 = Chem.MolFromSmiles(smi2)\n",
    "        fp1 = AllChem.GetMorganFingerprintAsBitVect(pattern1, 2, nBits=nbits)\n",
    "        fp2 = AllChem.GetMorganFingerprintAsBitVect(pattern2, 2, nBits=nbits)\n",
    "\n",
    "        tan_sim = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "        tan_sim = round(tan_sim,4)\n",
    "        if extra_info:\n",
    "            print(f\"Smiles 1: {smi1} \\n Target Smiles: {smi2} \\nTanimoto score:{tan_sim}\")\n",
    "\n",
    "        return tan_sim\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_tanimoto_of_all_compared_to_trg(trg_conv_SMI, gen_conv_SMI_list):\n",
    "    tani_list = []\n",
    "    ground_truth_mol = Chem.MolFromSmiles(trg_conv_SMI)\n",
    "    ground_truth_fp = AllChem.GetMorganFingerprintAsBitVect(ground_truth_mol, 2, nBits=512)\n",
    "    for smi in gen_conv_SMI_list:\n",
    "        #smiles = item[0]\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol:  # Check if the molecule is valid\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512)\n",
    "            tanimoto_similarity = DataStructs.TanimotoSimilarity(ground_truth_fp, fp)\n",
    "            tani_list.append(tanimoto_similarity)\n",
    "    return tani_list\n",
    "\n",
    "\n",
    "def run_mns_hit_counter_experiment(config, model_MMT, val_dataloader, itos, stoi, MW_filter, max_runs):\n",
    "    percentage_collection = []\n",
    "    molecule_tani_comparison_lists = []\n",
    "    one_finder_list = []\n",
    "    n_times = config.multinom_runs\n",
    "\n",
    "    results_dict = defaultdict(list)\n",
    "    # generate all the smiles of trg and greedy gen\n",
    "    for i, data_dict in enumerate(val_dataloader):\n",
    "        gen_conv_SMI_list = []\n",
    "        gen_conv_SMI_list, trg_conv_SMI_list,  prob_list = [], [], []\n",
    "\n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"][0]\n",
    "        trg_conv_SMI = hf.tensor_to_smiles(trg_enc_SMI[1:], itos)\n",
    "\n",
    "        ### multiply the input to paralellize the generation\n",
    "        data_dict_dup = rbgvm.duplicate_dict(data_dict, 128)\n",
    "\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC = vgmmt.run_model(model_MMT,\n",
    "                                                                       data_dict_dup, \n",
    "                                                                       config)\n",
    "        counter = 0\n",
    "        ### Here I increase the temperature in case if it does not generate enough diverse molecules but sets it back to the original\n",
    "        ### value after enough molecules were found.\n",
    "        temp_orig = config.temperature\n",
    "        while len(gen_conv_SMI_list)<n_times and counter<max_runs:\n",
    "            # increase the temperature if not enough different molecules get generated\n",
    "            if counter %10 == 0:\n",
    "                print(counter, len(gen_conv_SMI_list), config.temperature )\n",
    "                \n",
    "            multinom_tensor, multinom_token_prob = multinomial_sequence_multi_2(model_MMT, memory, src_padding_mask, stoi, config)\n",
    "            gen_conv_SMI, token_probs = hf.tensor_to_smiles_and_prob_2(multinom_tensor, multinom_token_prob, itos)\n",
    "\n",
    "            # import IPython; IPython.embed();\n",
    "            gen_conv_SMI, token_probs = filter_probs_and_valid_smiles_and_canonicolize(gen_conv_SMI, token_probs)   ### for 10.000 commented out\n",
    "            if MW_filter == True:\n",
    "                gen_conv_SMI, token_probs = filter_for_MW_2(trg_conv_SMI, gen_conv_SMI, token_probs)\n",
    "            gen_conv_SMI_list.extend(gen_conv_SMI)\n",
    "            prob_list.extend(token_probs)\n",
    "            gen_conv_SMI_list, prob_list = deduplicate_smiles(gen_conv_SMI_list, prob_list)\n",
    "            \n",
    "            tani_list = calculate_tanimoto_of_all_compared_to_trg(trg_conv_SMI, gen_conv_SMI_list)\n",
    "            if 1 in tani_list:\n",
    "                break\n",
    "            #print(counter, len(gen_conv_SMI_list))\n",
    "            counter += 1\n",
    "            config.temperature = config.temperature + 0.1    \n",
    "            \n",
    "        try:\n",
    "            one_finder_list.append(tani_list.index(1.0)+1)  # because indices start with 0\n",
    "        except:\n",
    "            one_finder_list.append(-5)\n",
    "        trg_SMI_list = [trg_conv_SMI for i in range(len(gen_conv_SMI_list))]\n",
    "        molecule_tani_comparison_lists.append([gen_conv_SMI_list,trg_SMI_list, tani_list])\n",
    "        config.temperature = temp_orig \n",
    "        #break\n",
    "    return one_finder_list, molecule_tani_comparison_lists\n",
    "\n",
    "def sel_data_slice_and_save_as_csv(config):\n",
    "    \"\"\" Saves the selected molecules in a new csv and replaces the csv_SMI_targets\"\"\"\n",
    "    # File path\n",
    "    file_path = config.csv_path_val  # Replace with your file path\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Select the first X rows\n",
    "    df_selected = df.head(config.data_size)\n",
    "\n",
    "    # Save the selected rows to a new CSV file\n",
    "    new_file_path = file_path.replace('.csv', f'_sel_{config.data_size}.csv')\n",
    "    df_selected.to_csv(new_file_path, index=False)\n",
    "    config.csv_SMI_targets = new_file_path\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "def filter_smiles(df, smi_list):\n",
    "    \"\"\"\n",
    "    Filter out SMILES strings from smi_list that are present in the DataFrame df.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with a 'SMILES' column.\n",
    "    smi_list (list): List of SMILES strings.\n",
    "\n",
    "    Returns:\n",
    "    list: Filtered list of SMILES strings.\n",
    "    \"\"\"\n",
    "    df_smiles_set = set(df['SMILES'])\n",
    "    filtered_list = [smiles for smiles in smi_list if smiles not in df_smiles_set]\n",
    "    return filtered_list\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_and_plot(results_dict, mode):\n",
    "    ranks = []\n",
    "    failed = []\n",
    "    \n",
    "    for key, value in results_dict.items():\n",
    "        # Extracting second and third numbers from each sublist\n",
    "        if mode == \"HSQC_sim\":\n",
    "            similaritys = [item[4] for item in value]\n",
    "        elif mode == \"dot_sim\":\n",
    "            similaritys = [item[2] for item in value]\n",
    "        tani_sims = [item[3] for item in value]\n",
    "        \n",
    "        if tani_sims[0] == 1:\n",
    "            # First number\n",
    "            first_number = similaritys[0]\n",
    "\n",
    "            # Sorting the numbers in descending order\n",
    "            if mode == \"HSQC_sim\":\n",
    "                sorted_numbers = sorted(similaritys, reverse=False)\n",
    "            elif mode == \"dot_sim\":\n",
    "                sorted_numbers = sorted(similaritys, reverse=True)\n",
    "\n",
    "            # Finding the rank of the first number\n",
    "            rank_of_first_number = sorted_numbers.index(first_number) + 1  # Adding 1 because index starts from 0\n",
    "\n",
    "            ranks.append(rank_of_first_number)\n",
    "        else:\n",
    "            failed.append([key, value])\n",
    "            #print(third_numbers)\n",
    "            \n",
    "    # Plotting the histogram of ranks\n",
    "    plt.hist(ranks, bins=range(1, len(value) + 2), align='left')\n",
    "    plt.xlabel('Rank')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Rank Histogram of {mode} corresponding correct Molecule')\n",
    "    plt.xticks(range(1, len(value) + 1))\n",
    "    plt.show()\n",
    "    return failed\n",
    "    \n",
    "    \n",
    "# Function to plot a molecule with additional data\n",
    "def plot_molecule_with_data(smiles, cosine_sim, tanimoto, HSQC_error):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    cosine_sim_rounded = round(float(cosine_sim), 3) if cosine_sim else ''\n",
    "    tanimoto_rounded = round(float(tanimoto), 3) if tanimoto else ''\n",
    "    HSQC_error_rounded = round(float(HSQC_error), 4) if HSQC_error else ''\n",
    "    fig, ax = plt.subplots()\n",
    "    img = Draw.MolToImage(mol, size=(300, 300))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"CLIP: {cosine_sim_rounded}, Tanimoto: {tanimoto_rounded},  HSQC_err: {HSQC_error_rounded}\")\n",
    "    plt.show()\n",
    "\n",
    "    ### PLOT Molecules\n",
    "\n",
    "def plot_CLIP_molecules(results_dict, investigate_number, stop_nr):\n",
    "    #investigate_number = 5\n",
    "    # Plot the key SMILES\n",
    "\n",
    "\n",
    "    # Plot the first item of each list with the third and fourth elements\n",
    "    for idx, data_val in enumerate(results_dict.values()):\n",
    "        \n",
    "        if idx == investigate_number:\n",
    "            key_smiles = list(results_dict.keys())[investigate_number]   \n",
    "            plot_molecule_with_data(key_smiles, '', '', '')\n",
    "            \n",
    "            for idy, lists in enumerate(data_val[0]):\n",
    "                first_smiles, _, cosine_sim, tanimoto, HSQC_error = lists\n",
    "                plot_molecule_with_data(first_smiles, cosine_sim, tanimoto, HSQC_error)\n",
    "                if idy == stop_nr:\n",
    "                    break\n",
    "                    \n",
    "def generate_mns_list(config, \n",
    "                  model_MMT, \n",
    "                  val_dataloader,\n",
    "                  stoi, \n",
    "                  itos, \n",
    "                  MW_filter):\n",
    "    ### Same code as function: run_multinomial_sampling\n",
    "    n_times = config.multinom_runs\n",
    "    gen_dict = {} #defaultdict(list)\n",
    "    temperature_orig = config.temperature\n",
    "    for idx, data_dict in enumerate(val_dataloader):\n",
    "        if idx % 10 == 0:\n",
    "            print(idx)\n",
    "        gen_conv_SMI_list, trg_conv_SMI_list, token_probs_list, src_HSQC_list, prob_list = [], [], [], [], []\n",
    "        data_dict_dup = rbgvm.duplicate_dict(data_dict, 128)\n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"][0]\n",
    "        trg_conv_SMI = ttf.tensor_to_smiles(trg_enc_SMI[1:], itos)\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC = vgmmt.run_model(model_MMT,\n",
    "                                                                   data_dict_dup, \n",
    "                                                                   config)\n",
    "        counter = 1\n",
    "        while len(gen_conv_SMI_list)<n_times:\n",
    "            # increase the temperature if not enough different molecules get generated               \n",
    "            print(counter, len(gen_conv_SMI_list), config.temperature)\n",
    "            if counter%30==0:\n",
    "                print(trg_conv_SMI)\n",
    "                break\n",
    "\n",
    "            multinom_tensor, multinom_token_prob = multinomial_sequence_multi_2(model_MMT, memory, src_padding_mask, stoi, config)\n",
    "            gen_conv_SMI, token_probs = hf.tensor_to_smiles_and_prob_2(multinom_tensor, multinom_token_prob, itos)\n",
    "            # import IPython; IPython.embed();\n",
    "            gen_conv_SMI, token_probs = filter_probs_and_valid_smiles_and_canonicolize(gen_conv_SMI, token_probs)   ### for 10.000 commented out\n",
    "            if MW_filter == True:\n",
    "                gen_conv_SMI, token_probs = filter_for_MW_2(trg_conv_SMI, gen_conv_SMI, token_probs)\n",
    "            gen_conv_SMI_list.extend(gen_conv_SMI)\n",
    "            prob_list.extend(token_probs)\n",
    "            gen_conv_SMI_list, prob_list = deduplicate_smiles(gen_conv_SMI_list, prob_list)\n",
    "            #gen_conv_SMI_list = list(set(gen_conv_SMI_list)) ### for 10.000 commented out\n",
    "            counter += 1\n",
    "            config.temperature = config.temperature + 0.1  \n",
    "            #print(time.time() -start)\n",
    "            #start = time.time()\n",
    "        config.temperature = temperature_orig\n",
    "\n",
    "        gen_conv_SMI_list = gen_conv_SMI_list[:n_times]\n",
    "        prob_list = prob_list[:n_times]\n",
    "        trg_conv_SMI_list = [trg_conv_SMI for i in range(len(gen_conv_SMI_list))]\n",
    "        \n",
    "        gen_dict[trg_conv_SMI] = [gen_conv_SMI_list, trg_conv_SMI_list, data_dict]\n",
    "    return gen_dict\n",
    "\n",
    "def run_clip_similarity_check(config, model_CLIP, gen_dict):\n",
    "    results_dict ={}\n",
    "    for trg_conv_SMI, values in gen_dict.items():\n",
    "        gen_conv_SMI_list, trg_conv_SMI_list, data_dict = values\n",
    "        data_dict_dup = rbgvm.duplicate_dict(data_dict, len(gen_conv_SMI_list))\n",
    "\n",
    "        mean_loss, losses, logits, targets, dot_similarity= model_CLIP.inference(data_dict_dup, \n",
    "                                                                    gen_conv_SMI_list)\n",
    "\n",
    "        combined_list = [[smile, num.item(), dot_sim.item()] for smile, num, dot_sim in zip(gen_conv_SMI_list, losses, dot_similarity)]\n",
    "        ### Sort by the lowest similarity\n",
    "        #sorted_list = sorted(combined_list, key=lambda x: x[1])\n",
    "\n",
    "        combined_list, failed_combined_list = add_tanimoto_similarity(trg_conv_SMI, combined_list)\n",
    "        #combined_list, batch_data = rbgvm.add_HSQC_error(config, combined_list, data_dict_dup, gen_conv_SMI_list, trg_conv_SMI, config.multinom_runs) # config.MMT_batch\n",
    "        #sorted_list = sorted(combined_list, key=lambda x: -x[3]) # SMILES = 0, losses =1, dot_sim= 2, tanimoto = 3 \n",
    "\n",
    "\n",
    "        results_dict[trg_conv_SMI] = [combined_list]\n",
    "    return results_dict\n",
    "\n",
    "def run_HSQC_similarity_check(config, gen_dict, results_dict):\n",
    "    results_dict_HSQC ={}\n",
    "    for trg_conv_SMI, values in gen_dict.items():\n",
    "        gen_conv_SMI_list, trg_conv_SMI_list, data_dict = values\n",
    "        data_dict_dup = rbgvm.duplicate_dict(data_dict, len(gen_conv_SMI_list))\n",
    "\n",
    "        src_HSQC_list = [data_dict_dup[\"src_HSQC\"]]\n",
    "        tensor_HSQC = rbgvm.prepare_HSQC_data_from_src(src_HSQC_list)\n",
    "\n",
    "        sgnn_avg_sim_error, sim_error_list, batch_data = rbgvm.calculate_HSQC_error(config, data_dict_dup, gen_conv_SMI_list)\n",
    "        results_dict_HSQC[trg_conv_SMI] = [gen_conv_SMI_list, sim_error_list]# batch_data]\n",
    "    return results_dict_HSQC\n",
    "\n",
    "def combine_CLIP_HSQC_data(results_dict_CLIP, results_dict_HSQC):\n",
    "\n",
    "    final_results = {}\n",
    "    for trg, data in results_dict_CLIP.items():\n",
    "        for idx, data_list in enumerate(data[0]):\n",
    "            try:\n",
    "                hsqc_error = results_dict_HSQC[trg][1][idx]\n",
    "                data[0][idx].append(hsqc_error)\n",
    "            except:\n",
    "                data[0][idx].append(-9)            \n",
    "        data = sorted(data[0], key=lambda x: -x[3]) # SMILES = 0, losses =1, dot_sim= 2, tanimoto = 3 \n",
    "        final_results[trg] = data\n",
    "    return final_results\n",
    "\n",
    "\n",
    "def filter_invalid_inputs(results_dict):\n",
    "    \"\"\" Check if there is just a [None,None] entry from the run_test_mns_performance_CLIP_3 function\"\"\"\n",
    "    filtered_dict = {}\n",
    "    counter = 0\n",
    "    for key, value in results_dict.items():\n",
    "        # Assuming 'combined_list' is the first item in the list which is the value of the dictionary.\n",
    "        # And we're checking if the first item in 'combined_list' is not '[None, None]'.\n",
    "        if value[0] is not None:# and value[1] is not None:\n",
    "            filtered_dict[key] = value\n",
    "        else:\n",
    "            counter+=1\n",
    "    return filtered_dict, counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85f675-a38e-4165-ba14-e3664ee0d032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb67d1e-0688-4a47-952f-2237d5a1a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.rdMolDescriptors import CalcMolFormula\n",
    "\n",
    "def calc_molecular_formula(smi):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        return CalcMolFormula(mol)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def filter_for_MF_2(trg_conv_SMI, gen_conv_SMI, prob_list):\n",
    "    # Calculate the molecular formula of the target molecule\n",
    "    trg_mf = calc_molecular_formula(trg_conv_SMI)\n",
    "\n",
    "    # Filter the list based on molecular formula\n",
    "    filtered_gen_smis = [smi for (smi, token_prob) in zip(gen_conv_SMI, prob_list) if calc_molecular_formula(smi) == trg_mf]\n",
    "    filtered_prob_list = [token_prob for (smi, token_prob) in zip(gen_conv_SMI, prob_list) if calc_molecular_formula(smi) == trg_mf]\n",
    "    return filtered_gen_smis, filtered_prob_list\n",
    "\n",
    "\n",
    "def run_multinomial_sampling_v2(config, model_MMT, val_dataloader, itos, stoi, MW_filter=False, MF_filter=False):\n",
    "    n_times = config.multinom_runs\n",
    "    results_dict = defaultdict(list)\n",
    "    temperature_orig = config.temperature\n",
    "\n",
    "    for idx, data_dict in tqdm(enumerate(val_dataloader)):\n",
    "        if idx % 10 == 0:\n",
    "            print(idx)\n",
    "\n",
    "        gen_conv_SMI_list, trg_conv_SMI_list, token_probs_list, src_HSQC_list, prob_list = [], [], [], [], []\n",
    "        data_dict_dup = rbgvm.duplicate_dict(data_dict, 16)\n",
    "\n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"][0]\n",
    "        trg_conv_SMI = hf.tensor_to_smiles(trg_enc_SMI[1:], itos)\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC, src_COSY = vgmmt.run_model(model_MMT,\n",
    "                                                                   data_dict_dup, \n",
    "                                                                   config)\n",
    "        counter = 1\n",
    "        removed = 0\n",
    "        while len(gen_conv_SMI_list) < n_times:\n",
    "            # Increase the temperature if not enough different molecules get generated               \n",
    "            if counter % 80 == 0:\n",
    "                print(trg_conv_SMI)\n",
    "                break\n",
    "            multinom_tensor, multinom_token_prob = multinomial_sequence_multi_2(model_MMT, memory, src_padding_mask, stoi, config)\n",
    "            gen_conv_SMI, token_probs = hf.tensor_to_smiles_and_prob_2(multinom_tensor, multinom_token_prob, itos)\n",
    "\n",
    "            # Filter valid SMILES and canonicalize\n",
    "            gen_conv_SMI, token_probs = filter_probs_and_valid_smiles_and_canonicolize(gen_conv_SMI, token_probs)\n",
    "            #print(f\"valid smi: {len(set(gen_conv_SMI))}\")\n",
    "            #import IPython; IPython.embed();\n",
    "            before_gen = len(gen_conv_SMI)\n",
    "            if MW_filter:\n",
    "                gen_conv_SMI, token_probs = filter_for_MW_2(trg_conv_SMI, gen_conv_SMI, token_probs)\n",
    "                #print(f\"MW_filter: {before_gen - len(gen_conv_SMI)}\")\n",
    "                removed_1 = before_gen - len(gen_conv_SMI)\n",
    "                removed += removed_1\n",
    "            if MF_filter:\n",
    "                gen_conv_SMI, token_probs = filter_for_MF_2(trg_conv_SMI, gen_conv_SMI, token_probs)\n",
    "                #print(f\"MF_filter: {before_gen - len(gen_conv_SMI)}\")\n",
    "                removed_2 = before_gen - len(gen_conv_SMI)\n",
    "                removed += removed_2\n",
    "\n",
    "            gen_conv_SMI_list.extend(gen_conv_SMI)\n",
    "            prob_list.extend(token_probs)\n",
    "            gen_conv_SMI_list, prob_list = deduplicate_smiles(gen_conv_SMI_list, prob_list)\n",
    "            counter += 1\n",
    "            config.temperature = config.temperature + 0.1\n",
    "        #print(removed, len(gen_conv_SMI_list))\n",
    "        gen_conv_SMI_list = gen_conv_SMI_list[:n_times]\n",
    "        prob_list = prob_list[:n_times]\n",
    "        trg_conv_SMI_list = [trg_conv_SMI for _ in range(len(gen_conv_SMI_list))]\n",
    "\n",
    "        tanimoto_mean, tanimoto_std_dev, failed, tanimoto_list_all = vgmmt.calculate_tanimoto_similarity(gen_conv_SMI_list, trg_conv_SMI_list)\n",
    "        results_dict[idx].append({\n",
    "            'gen_conv_SMI_list': gen_conv_SMI_list,\n",
    "            'trg_conv_SMI_list': trg_conv_SMI_list,\n",
    "            'tanimoto_sim': tanimoto_list_all,\n",
    "            'tanimoto_mean': tanimoto_mean,\n",
    "            'tanimoto_std_dev': tanimoto_std_dev,\n",
    "            'failed': failed,\n",
    "            'prob_list': prob_list,\n",
    "        })\n",
    "        config.temperature = temperature_orig\n",
    "    return config, results_dict\n",
    "\n",
    "def run_precentage_calculation_v2(config, itos, stoi, stoi_MF, MW_filter=False, MF_filter=False):\n",
    "    model_MMT = load_MMT_model(config)\n",
    "    val_dataloader = load_data(config, stoi, stoi_MF, single=True, mode=\"val\")  \n",
    "    config.temperature = 1\n",
    "    config, results_dict_mns_10 = run_multinomial_sampling_v2(config, model_MMT, val_dataloader, itos, stoi, MW_filter=MW_filter, MF_filter=MF_filter)\n",
    "    top_x = 10\n",
    "    percentage_top_10 = calc_percentage_top_x_correct(results_dict_mns_10, top_x)\n",
    "    top_x = 5\n",
    "    percentage_top_5 = calc_percentage_top_x_correct(results_dict_mns_10, top_x)\n",
    "    top_x = 3\n",
    "    percentage_top_3 = calc_percentage_top_x_correct(results_dict_mns_10, top_x)\n",
    "    top_x = 1\n",
    "    percentage_top_1 = calc_percentage_top_x_correct(results_dict_mns_10, top_x)\n",
    "    \n",
    "    val_dataloader_multi = load_data(config, stoi, stoi_MF, single=False, mode=\"val\")  \n",
    "    config, results_dict_greedy = run_greedy_sampling_v2(config, model_MMT, val_dataloader_multi, itos, stoi, MW_filter=False, MF_filter=False)\n",
    "    #config, results_dict_greedy = run_greedy_sampling(config, model_MMT, val_dataloader_multi, itos, stoi, MW_filter=MW_filter)\n",
    "\n",
    "    percentage_1_greedy = calc_percentage_top_x_correct_greedy(results_dict_greedy)\n",
    "\n",
    "    percentage_collection = [percentage_1_greedy, percentage_top_1, percentage_top_3, percentage_top_5, percentage_top_10]\n",
    "\n",
    "    return percentage_collection, results_dict_mns_10, results_dict_greedy\n",
    "\n",
    "def run_greedy_sampling_v2(config, model_MMT, val_dataloader, itos, stoi, MW_filter=False, MF_filter=False):\n",
    "    results_dict = defaultdict(list)\n",
    "    gen_conv_SMI_list, trg_conv_SMI_list, prob_list, src_HSQC_list, src_COSY_list = [], [], [], [], []\n",
    "    for idx, data_dict in enumerate(val_dataloader):\n",
    "        trg_enc_SMI = data_dict[\"trg_enc_SMI\"]\n",
    "        trg_conv_SMI = hf.tensor_to_smiles(trg_enc_SMI.T[1:], itos)\n",
    "        memory, src_padding_mask, trg_enc_SMI, fingerprint, src_HSQC, src_COSY = vgmmt.run_model(model_MMT,\n",
    "                                                                   data_dict, \n",
    "                                                                   config)\n",
    "\n",
    "        greedy_tensor, greedy_token_prob = greedy_sequence_2(model_MMT, stoi, itos, memory, src_padding_mask, config)\n",
    "\n",
    "        gen_conv_SMI, token_probs = hf.tensor_to_smiles_and_prob(greedy_tensor, greedy_token_prob.T, itos)\n",
    "\n",
    "        # Filter valid SMILES and canonicalize\n",
    "        \"\"\"gen_conv_SMI, token_probs = filter_probs_and_valid_smiles_and_canonicolize(gen_conv_SMI, token_probs)\n",
    "        if MW_filter:\n",
    "            gen_conv_SMI, token_probs = filter_for_MW_2(trg_conv_SMI[0], gen_conv_SMI, token_probs)\n",
    "        if MF_filter:\n",
    "            gen_conv_SMI, token_probs = filter_for_MF_2(trg_conv_SMI[0], gen_conv_SMI, token_probs)\n",
    "        \"\"\"\n",
    "        gen_conv_SMI_list.extend(gen_conv_SMI)\n",
    "        trg_conv_SMI_list.extend(trg_conv_SMI)\n",
    "        prob_list.extend(token_probs)\n",
    "        src_HSQC_list.extend(src_HSQC)\n",
    "        src_COSY_list.extend(src_COSY)\n",
    "        \n",
    "    tanimoto_mean, tanimoto_std_dev, failed, tanimoto_list_all = vgmmt.calculate_tanimoto_similarity(gen_conv_SMI_list, trg_conv_SMI_list)\n",
    "    results_dict = {\n",
    "        'gen_conv_SMI_list': gen_conv_SMI_list,\n",
    "        'trg_conv_SMI_list': trg_conv_SMI_list,\n",
    "        'tanimoto_sim': tanimoto_list_all,\n",
    "        'tanimoto_mean': tanimoto_mean,\n",
    "        'tanimoto_std_dev': tanimoto_std_dev,\n",
    "        'failed': failed,\n",
    "        'prob_list': prob_list,\n",
    "        \"src_HSQC_list\": src_HSQC_list,\n",
    "        \"src_COSY_list\": src_COSY_list,\n",
    "        }\n",
    "    \n",
    "    return config, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e710610-eab0-4a2f-a4dd-3c17b15c9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_13C.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_HSQC.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_COSY.csv'\n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_test_V8_355655.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280a1ef-5392-40b9-b12d-e8cbfd20e805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b87539-07ae-4f93-acb7-453dfa8251e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "config.training_mode = \"1H_13C_HSQC_COSY_IR_MF_MW\"\n",
    "config.IR_data_folder=\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.temperature = 1\n",
    "config.multinom_runs = 10\n",
    "config.data_size = 10000\n",
    "MW_filter = False\n",
    "MF_filter = False\n",
    "\n",
    "percentage_collection_FALSE_FALSE, results_dict_mns_10_FALSE_FALSE, results_dict_greedy_FALSE_FALSE = run_precentage_calculation_v2(config, itos, stoi, stoi_MF, MW_filter, MF_filter)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.1_results_dict_greedy_FALSE_FALSE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(results_dict_greedy_FALSE_FALSE, file)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.2_results_dict_mns_10_FALSE_FALSE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(results_dict_mns_10_FALSE_FALSE, file)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.3_percentage_collection_FALSE_FALSE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(percentage_collection_FALSE_FALSE, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ae9cf-8479-4bb1-b6a7-39c63d65097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "config.training_mode = \"1H_13C_HSQC_COSY_IR_MF_MW\"\n",
    "config.IR_data_folder=\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.temperature = 1\n",
    "config.multinom_runs = 10\n",
    "config.data_size = 10000\n",
    "MW_filter = True\n",
    "MF_filter = False\n",
    "\n",
    "percentage_collection_TRUE_FALSE, results_dict_mns_10_TRUE_FALSE, results_dict_greedy_TRUE_FALSE = run_precentage_calculation_v2(config, itos, stoi, stoi_MF, MW_filter, MF_filter)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.1_results_dict_greedy_TRUE_FALSE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(results_dict_greedy_TRUE_FALSE, file)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.2_results_dict_mns_10_TRUE_FALSE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(results_dict_mns_10_TRUE_FALSE, file)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.3_percentage_collection_TRUE_FALSE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(percentage_collection_TRUE_FALSE, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a66c1-b086-40c2-bfca-dd37f3af9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V8 MW Drop\n",
    "import pickle\n",
    "\n",
    "config.training_mode = \"1H_13C_HSQC_COSY_IR_MF_MW\"\n",
    "config.IR_data_folder=\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.temperature = 1\n",
    "config.multinom_runs = 10\n",
    "config.data_size = 10000\n",
    "MW_filter = False\n",
    "MF_filter = True\n",
    "\n",
    "percentage_collection_FALSE_TRUE, results_dict_mns_10_FALSE_TRUE, results_dict_greedy_FALSE_TRUE = run_precentage_calculation_v2(config, itos, stoi, stoi_MF, MW_filter, MF_filter)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.1_results_dict_greedy_FALSE_TRUE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(results_dict_greedy_FALSE_TRUE, file)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.2_results_dict_mns_10_FALSE_TRUE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(results_dict_mns_10_FALSE_TRUE, file)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.3_percentage_collection_FALSE_TRUE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(percentage_collection_FALSE_TRUE, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f1da6-58a8-489b-a87a-2f877135343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V8 MW Drop\n",
    "import pickle\n",
    "\n",
    "config.training_mode = \"1H_13C_HSQC_COSY_IR_MF_MW\"\n",
    "config.IR_data_folder=\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.temperature = 1\n",
    "config.multinom_runs = 10\n",
    "config.data_size = 10000\n",
    "MW_filter = True\n",
    "MF_filter = True\n",
    "\n",
    "percentage_collection_TRUE_TRUE, results_dict_mns_10_TRUE_TRUE, results_dict_greedy_TRUE_TRUE = run_precentage_calculation_v2(config, itos, stoi, stoi_MF, MW_filter, MF_filter)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.1_results_dict_greedy_TRUE_TRUE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(results_dict_greedy_TRUE_TRUE, file)\n",
    "\n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.2_results_dict_mns_10_TRUE_TRUE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    \n",
    "file_path_c = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.3_percentage_collection_TRUE_TRUE_10000.pkl'\n",
    "with open(file_path_c, 'wb') as file:\n",
    "    pickle.dump(percentage_collection_TRUE_TRUE, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74e7cb-7e83-42c2-a84b-636a35c0dd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c83e0dc-7311-4d0a-b7b8-2555b7ae0cd2",
   "metadata": {},
   "source": [
    "##### Plot new Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b994a-50f9-4c88-a58f-48c58eee72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "def calc_percentage_and_count_top_x_correct_greedy(results_dict):\n",
    "    count_yes = 0\n",
    "    count_no = 0\n",
    "\n",
    "    for i in results_dict[\"tanimoto_sim\"]:\n",
    "        if i == 1:\n",
    "            count_yes += 1\n",
    "        else:\n",
    "            count_no += 1\n",
    "\n",
    "    total = count_yes + count_no\n",
    "    percentage = (count_yes / total) * 100 if total > 0 else 0\n",
    "    return percentage, count_yes, total\n",
    "\n",
    "\n",
    "def calc_percentage_and_count_top_x_correct(results_dict, top_x):\n",
    "    count_yes = 0\n",
    "    count_no = 0\n",
    "    for idx in results_dict.keys():\n",
    "        for result in results_dict[idx]:\n",
    "            tanimoto_sim = result[\"tanimoto_sim\"][:top_x]\n",
    "            if 1 in tanimoto_sim:\n",
    "                count_yes += 1\n",
    "            else:\n",
    "                count_no += 1\n",
    "    total = count_yes + count_no\n",
    "    percentage = (count_yes / total) * 100 if total > 0 else 0\n",
    "    return percentage, count_yes, total\n",
    "\n",
    "def prepare_data(results_dict_FALSE_FALSE, results_dict_FALSE_TRUE, \n",
    "                 results_dict_TRUE_FALSE, results_dict_TRUE_TRUE, \n",
    "                 results_dict_greedy):\n",
    "    \n",
    "    # Calculate percentages for each filter combination\n",
    "    def calc_percentages(results_dict):\n",
    "        percentage_greedy, count_greedy, _ = calc_percentage_and_count_top_x_correct_greedy(results_dict_greedy)\n",
    "        percentage_top_1, count_top_1, _ = calc_percentage_and_count_top_x_correct(results_dict, 1)\n",
    "        percentage_top_3, count_top_3, _ = calc_percentage_and_count_top_x_correct(results_dict, 3)\n",
    "        percentage_top_5, count_top_5, _ = calc_percentage_and_count_top_x_correct(results_dict, 5)\n",
    "        percentage_top_10, count_top_10, _ = calc_percentage_and_count_top_x_correct(results_dict, 10)\n",
    "        \n",
    "        return [(percentage_greedy, count_greedy), (percentage_top_1, count_top_1),\n",
    "                (percentage_top_3, count_top_3), (percentage_top_5, count_top_5),\n",
    "                (percentage_top_10, count_top_10)]\n",
    "\n",
    "    no_filter = calc_percentages(results_dict_FALSE_FALSE)\n",
    "    mf_filter = calc_percentages(results_dict_FALSE_TRUE)\n",
    "    mw_filter = calc_percentages(results_dict_TRUE_FALSE)\n",
    "    mw_mf_filter = calc_percentages(results_dict_TRUE_TRUE)\n",
    "\n",
    "    return no_filter, mf_filter, mw_filter, mw_mf_filter\n",
    "\n",
    "\n",
    "def plot_results(no_filter, mf_filter, mw_filter, mw_mf_filter):\n",
    "    labels = ['Greedy', '1 Sample', '3 Samples', '5 Samples', '10 Samples']\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2  # Reduced width to accommodate 4 bars\n",
    "    colors = ['#A1C8F3', '#FFB381', '#8BE5A0', '#FF9D9A']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Plot bars in the desired order\n",
    "    rects1 = ax.bar(x - 1 * width, [d[0] for d in no_filter], width, label='No Filter', color=colors[0])\n",
    "    rects2 = ax.bar(x - 0.0 * width, [d[0] for d in mw_filter], width, label='MW Filter', color=colors[1])\n",
    "    rects3 = ax.bar(x + 1 * width, [d[0] for d in mf_filter], width, label='MF Filter', color=colors[2])\n",
    "    #rects4 = ax.bar(x + 1.5 * width, [d[0] for d in mw_mf_filter], width, label='MW + MF Filter', color=colors[3])\n",
    "\n",
    "    # Set labels and title with larger font sizes\n",
    "    ax.set_ylabel('Percentage', fontsize=30)\n",
    "    ax.set_title('Performance Comparison with Different Filters', fontsize=30)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, fontsize=30)\n",
    "    ax.legend(fontsize=30)\n",
    "    ax.tick_params(axis='y', labelsize=30)\n",
    "    ax.set_ylim(40, 100)\n",
    "\n",
    "    # Function to add annotations to the bars\n",
    "    def autolabel(rects, data):\n",
    "        for rect, (percentage, count) in zip(rects, data):\n",
    "            height = rect.get_height()\n",
    "            visible_height = height - 40  # Adjust for the 40% lower limit\n",
    "            \n",
    "            # Add rotated percentage on top of the bar\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2, height + 2, f'{percentage:.1f}%',\n",
    "                    ha='center', va='bottom', fontsize=20, rotation=90)\n",
    "            \n",
    "            # Add count at the middle of the visible part of the bar\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2, 40 + visible_height / 2, f'{count}',\n",
    "                    ha='center', va='center', fontsize=20, rotation=90)\n",
    "\n",
    "    # Add annotations to each bar\n",
    "    autolabel(rects1, no_filter)\n",
    "    autolabel(rects2, mw_filter)\n",
    "    autolabel(rects3, mf_filter)\n",
    "    #autolabel(rects4, mw_mf_filter)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/performance_comparison_with_counts_all_filters_10000_v1a.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf3404-5a3f-47d7-8b52-7a8a9529c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your new data\n",
    "file_path_base = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/'\n",
    "\n",
    "with open(file_path_base + '3.0.2_results_dict_mns_10_FALSE_FALSE_10000.pkl', 'rb') as file:\n",
    "    results_dict_FALSE_FALSE = pickle.load(file)\n",
    "\n",
    "with open(file_path_base + '3.0.2_results_dict_mns_10_FALSE_TRUE_10000.pkl', 'rb') as file:\n",
    "    results_dict_FALSE_TRUE = pickle.load(file)\n",
    "\n",
    "with open(file_path_base + '3.0.2_results_dict_mns_10_TRUE_FALSE_10000.pkl', 'rb') as file:\n",
    "    results_dict_TRUE_FALSE = pickle.load(file)\n",
    "\n",
    "with open(file_path_base + '3.0.2_results_dict_mns_10_TRUE_TRUE_10000.pkl', 'rb') as file:\n",
    "    results_dict_TRUE_TRUE = pickle.load(file)\n",
    "\n",
    "with open(\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240923_Experiment_3_v2/3.0.1_results_dict_greedy_FALSE_FALSE_10000.pkl\", 'rb') as file:\n",
    "    results_dict_greedy = pickle.load(file)\n",
    "\n",
    "# Prepare and plot data\n",
    "no_filter, mf_filter, mw_filter, mw_mf_filter = prepare_data(\n",
    "    results_dict_FALSE_FALSE, \n",
    "    results_dict_FALSE_TRUE,\n",
    "    results_dict_TRUE_FALSE, \n",
    "    results_dict_TRUE_TRUE,\n",
    "    results_dict_greedy\n",
    "    )\n",
    "plot_results(no_filter, mf_filter, mw_filter, mw_mf_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2fcbce-8fa0-4904-a5c5-d558b1bc199d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 5.0. Similarity reduction plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308b80c-5688-471d-8da4-b9a68d3ec741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d568a54-a567-45ec-9499-a6908be8ebaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.1 Tanimoto Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1420bcc-1974-47b6-bda9-15082702ae11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)  # Set random seed for reproducibility   \n",
    "    zinc_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_train_V8.csv' \n",
    "    pubchem_paths = [\n",
    "        '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000.csv',\n",
    "        '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000.csv',\n",
    "        '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "    ]\n",
    "    weight_ranges = ['0-250 Da', '250-350 Da', '350-500 Da']\n",
    "\n",
    "    print(\"Loading ZINC data...\")\n",
    "    zinc_smiles = exp_fun.load_data(zinc_path)\n",
    "    zinc_smiles = exp_fun.load_data(zinc_path, sample_size=3000)\n",
    "\n",
    "    zinc_fp = exp_fun.calculate_fingerprints(zinc_smiles)  # Limit to 10000 compounds for performance\n",
    "\n",
    "    for pubchem_path, weight_range in zip(pubchem_paths, weight_ranges):\n",
    "        print(f\"Processing PubChem data for {weight_range}...\")\n",
    "        pubchem_smiles = exp_fun.load_data(pubchem_path)\n",
    "        pubchem_fp = calculate_fingerprints(pubchem_smiles[:100])  # Limit to 100 compounds for performance\n",
    "\n",
    "        combined_fp = np.vstack((zinc_fp, pubchem_fp))\n",
    "        labels = np.array(['ZINC'] * len(zinc_fp) + ['PubChem'] * len(pubchem_fp))\n",
    "\n",
    "        print(\"Performing dimensionality reduction...\")\n",
    "        tsne_result, pca_result, umap_result = exp_fun.perform_dimensionality_reduction(combined_fp)\n",
    "\n",
    "        print(\"Plotting results...\")\n",
    "        exp_fun.plot_tsne_umap_pca([tsne_result, pca_result, umap_result], labels, \n",
    "                     f\"ZINC vs PubChem ({weight_range})\", \n",
    "                     ['t-SNE', 'PCA', 'UMAP'])\n",
    "\n",
    "    print(\"All plots generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f669e-d68e-4c6f-911d-62a010cb17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c9cd3f-e148-40b7-9bba-b6a0b2422be7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2 Vector Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de554f3-7def-4be9-9605-1b477dbca802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast  # For safely evaluating strings containing Python literals\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.DataStructs import FingerprintSimilarity\n",
    "from rdkit.DataStructs import TanimotoSimilarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f30de8d-20c7-49ba-94d3-bd8353c71e61",
   "metadata": {},
   "source": [
    "4.2.1 Pubchem vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff627a4-50f5-4bb6-aa08-6f74a16f04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "#config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_13C_V1_test_350_500_x1000.csv'    \n",
    "#config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_HSQC_V1_test_350_500_x1000.csv'    \n",
    "#config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_COSY_V1_test_350_500_x1000.csv'   \n",
    "#config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "#config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_185242.pkl\"\n",
    "\n",
    "#config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000.csv'\n",
    "#config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_13C_V1_test_0_250_x1000.csv'\n",
    "#config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_HSQC_V1_test_0_250_x1000.csv'    \n",
    "#config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_COSY_V1_test_0_250_x1000.csv'   \n",
    "#config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000.csv'\n",
    "#config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_933335.pkl\"\n",
    "\n",
    "\n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_13C_V1_test_250_350_x1000.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_HSQC_V1_test_250_350_x1000.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_COSY_V1_test_250_350_x1000.csv'   \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000_285005.pkl\"\n",
    "\n",
    "# V8 Raw \n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/IR_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbc810-4628-484a-9667-0e2493bb1e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_13C_V1_test_350_500_x1000.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_HSQC_V1_test_350_500_x1000.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_COSY_V1_test_350_500_x1000.csv'   \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_185242.pkl\"\n",
    "\n",
    "# V8 Raw \n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/IR_data\"\n",
    "config.data_size = 1000\n",
    "\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.vector_db = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_Vectors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca7142-70a5-4d30-8c1a-0f382c020084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Data needs to be loaded in csv_1H_path_SGNN 13C ...etc\n",
    "# path to store db\n",
    "config = exp_func.vectorize_db(config, stoi, stoi_MF, \"db\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0db7a4-d14b-4b50-a193-7ef407f48892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "vector_db = config.vector_db\n",
    "# Load CSV data\n",
    "df = pd.read_csv(vector_db)\n",
    "\n",
    "# Convert 'Fingerprints' to tensors\n",
    "tqdm.pandas()\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(ast.literal_eval)\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "# Save the DataFrame to Pickle\n",
    "pickle_file = vector_db.replace('.csv', '_v2.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"Data saved to {pickle_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31e6c5-9bbf-47a7-8c75-0a00d35af962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_13C_V1_test_250_350_x1000.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_HSQC_V1_test_250_350_x1000.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_COSY_V1_test_250_350_x1000.csv'   \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000_285005.pkl\"\n",
    "\n",
    "# V8 Raw \n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/IR_data\"\n",
    "config.data_size = 1000\n",
    "\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.vector_db = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000_Vectors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42056b89-8cfb-44da-b519-cd766a213f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data needs to be loaded in csv_1H_path_SGNN 13C ...etc\n",
    "# path to store db\n",
    "config = exp_func.vectorize_db(config, stoi, stoi_MF, \"db\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbff6d7-03a6-452a-bda0-1b958c8f3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "vector_db = config.vector_db\n",
    "# Load CSV data\n",
    "df = pd.read_csv(vector_db)\n",
    "\n",
    "# Convert 'Fingerprints' to tensors\n",
    "tqdm.pandas()\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(ast.literal_eval)\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "# Save the DataFrame to Pickle\n",
    "pickle_file = vector_db.replace('.csv', '_v2.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"Data saved to {pickle_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73df20d-5fcd-4f5f-90df-19933774769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_13C_V1_test_0_250_x1000.csv'\n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_HSQC_V1_test_0_250_x1000.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_COSY_V1_test_0_250_x1000.csv'   \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_933335.pkl\"\n",
    "\n",
    "# V8 Raw \n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/IR_data\"\n",
    "config.data_size = 1000\n",
    "\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.vector_db = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_Vectors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af78c4-f00c-4275-adc8-cf16d7676da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data needs to be loaded in csv_1H_path_SGNN 13C ...etc\n",
    "# path to store db\n",
    "config = exp_func.vectorize_db(config, stoi, stoi_MF, \"db\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059685f7-7e81-47bf-8ddf-a30d8ae30e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "vector_db = config.vector_db\n",
    "# Load CSV data\n",
    "df = pd.read_csv(vector_db)\n",
    "\n",
    "# Convert 'Fingerprints' to tensors\n",
    "tqdm.pandas()\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(ast.literal_eval)\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "# Save the DataFrame to Pickle\n",
    "pickle_file = vector_db.replace('.csv', '_v2.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"Data saved to {pickle_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbce98e-7a5c-4f7e-bc63-432d6cc78b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdf14a-82ca-44b6-8ee2-5f81fc333bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155ffd9-9d00-4d55-804a-307aef760459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cc1e2d4-35e6-428c-9ea8-d2446ce87c36",
   "metadata": {},
   "source": [
    "##### UMAP, tSNE, PCA Set 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac2248-a400-48ea-88ca-fc531c9dc74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86479e-7221-4258-91d2-51b090133330",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10159e40-ce1d-4296-84a4-abc37a12d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_files = [\n",
    "    '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_Vectors_v2.pkl',\n",
    "    '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000_Vectors_v2.pkl',\n",
    "    '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_Vectors_v2.pkl'\n",
    "]\n",
    "\n",
    "weight_ranges = ['0-250 Da', '250-350 Da', '350-500 Da']\n",
    "weight_ranges = [\"Set 1\", \"Set 2\", \"Set 3\"]\n",
    "\n",
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "train_vectors, train_smiles = exp_func.load_pickle_data('/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/vector_db_train_5Mod_4M_v2_v2.pkl', sample_size=3000)\n",
    "\n",
    "for test_file, weight_range in zip(test_files, weight_ranges):\n",
    "    print(f\"Processing test data for {weight_range}...\")\n",
    "    test_vectors, test_smiles = exp_func.load_pickle_data(test_file)\n",
    "    \n",
    "    # Use only the first 100 test vectors\n",
    "    test_vectors_sample = test_vectors[:300]\n",
    "    \n",
    "    combined_vectors = np.vstack((train_vectors, test_vectors_sample))\n",
    "    labels = ['Train'] * len(train_vectors) + ['Test'] * len(test_vectors_sample)\n",
    "    \n",
    "    print(f\"Shape of combined vectors: {combined_vectors.shape}\")\n",
    "    print(f\"Number of labels: {len(labels)}\")\n",
    "    \n",
    "    print(\"Performing dimensionality reduction...\")\n",
    "    tsne_result, pca_result, umap_result = exp_func.perform_dimensionality_reduction(combined_vectors)\n",
    "    \n",
    "    print(\"Plotting results...\")\n",
    "    exp_func.plot_tsne_umap_pca_train_test([tsne_result, pca_result, umap_result], labels, \n",
    "                 f\"Train vs Test Vectors ({weight_range})\", \n",
    "                 ['t-SNE', 'PCA', 'UMAP'])\n",
    "\n",
    "print(\"All plots generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682aa73-4359-46f2-bc2b-7f47427b30ad",
   "metadata": {},
   "source": [
    "##### 5.2.1 ZINC 1000 vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66490ac4-98e1-4b8a-890b-7c03b4b0fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGNN_smi_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_5M_XL_1H_comb_test_V8_1000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2fa67-c723-4544-97be-43726d98eec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.SGNN_csv_gen_smi = SGNN_smi_path\n",
    "config.SGNN_gen_folder_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/46_Project_3_Data/test\"\n",
    "config = ex.gen_sim_aug_data(config, IR_config)\n",
    "config.csv_path_val = config.csv_1H_path_SGNN\n",
    "#config = ex.filter_invalid_criteria(config.csv_1H_path_SGNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a215a82-9de0-4910-af2a-5d8acccee552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define your source CSV paths (these are just placeholders)\n",
    "source_csv_1H = config.csv_1H_path_SGNN\n",
    "source_csv_13C = config.csv_13C_path_SGNN\n",
    "source_csv_HSQC = config.csv_HSQC_path_SGNN\n",
    "source_csv_COSY = config.csv_COSY_path_SGNN\n",
    "source_IR_folder = config.IR_data_folder\n",
    "\n",
    "# Define the destination folder (replace with your actual path)\n",
    "destination_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/test\"\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Copy the files\n",
    "shutil.copy(source_csv_1H, destination_folder)\n",
    "shutil.copy(source_csv_13C, destination_folder)\n",
    "shutil.copy(source_csv_HSQC, destination_folder)\n",
    "shutil.copy(source_csv_COSY, destination_folder)\n",
    "\n",
    "# If IR_data_folder contains multiple files, you can copy them like this:\n",
    "for file_name in os.listdir(source_IR_folder):\n",
    "    full_file_name = os.path.join(source_IR_folder, file_name)\n",
    "    if os.path.isfile(full_file_name):\n",
    "        shutil.copy(full_file_name, destination_folder)\n",
    "\n",
    "print(f\"All files have been copied to {destination_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0758b22-4a34-4c21-8675-c04e891af375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/data_1H_791960.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/data_13C_791960.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/data_HSQC_791960.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/data_COSY_791960.csv'   \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/data_1H_791960.csv'\n",
    "config.pickle_file_path = \"\"\n",
    "\n",
    "# V8 Raw \n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/IR_Data\"\n",
    "config.data_size = 1000\n",
    "\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.vector_db = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/ZINC_1000_vectors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859a148-aa05-4262-93ab-b61a33204952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Data needs to be loaded in csv_1H_path_SGNN 13C ...etc\n",
    "# path to store db\n",
    "config = exp_func.vectorize_db(config, stoi, stoi_MF, \"db\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870170b3-c9a9-416a-8c1a-6d64506984f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "vector_db = config.vector_db\n",
    "# Load CSV data\n",
    "df = pd.read_csv(vector_db)\n",
    "\n",
    "# Convert 'Fingerprints' to tensors\n",
    "tqdm.pandas()\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(ast.literal_eval)\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "# Save the DataFrame to Pickle\n",
    "pickle_file = vector_db.replace('.csv', '_v2.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"Data saved to {pickle_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921cd39a-a94c-4c4b-9042-08e064557faf",
   "metadata": {},
   "source": [
    "##### 5.2.1 Sim 34 molecules vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce15933-2ef3-4908-a089-4ba56a75f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGNN_smi_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/ACD_1H_with_SN_filtered_v3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1987b6-251e-4e01-9595-277ea7a2c5af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.SGNN_csv_gen_smi = SGNN_smi_path\n",
    "config.SGNN_gen_folder_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/46_Project_3_Data/test\"\n",
    "config = ex.gen_sim_aug_data(config, IR_config)\n",
    "config.csv_path_val = config.csv_1H_path_SGNN\n",
    "#config = ex.filter_invalid_criteria(config.csv_1H_path_SGNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944bf7e5-c69c-4681-a6e2-522472b89ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define your source CSV paths (these are just placeholders)\n",
    "source_csv_1H = config.csv_1H_path_SGNN\n",
    "source_csv_13C = config.csv_13C_path_SGNN\n",
    "source_csv_HSQC = config.csv_HSQC_path_SGNN\n",
    "source_csv_COSY = config.csv_COSY_path_SGNN\n",
    "source_IR_folder = config.IR_data_folder\n",
    "\n",
    "# Define the destination folder (replace with your actual path)\n",
    "destination_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations\"\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Copy the files\n",
    "shutil.copy(source_csv_1H, destination_folder)\n",
    "shutil.copy(source_csv_13C, destination_folder)\n",
    "shutil.copy(source_csv_HSQC, destination_folder)\n",
    "shutil.copy(source_csv_COSY, destination_folder)\n",
    "\n",
    "# If IR_data_folder contains multiple files, you can copy them like this:\n",
    "for file_name in os.listdir(source_IR_folder):\n",
    "    full_file_name = os.path.join(source_IR_folder, file_name)\n",
    "    if os.path.isfile(full_file_name):\n",
    "        shutil.copy(full_file_name, destination_folder)\n",
    "\n",
    "print(f\"All files have been copied to {destination_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190e1c4-c7e7-4441-b00d-bf075d2fd1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_sim data\n",
    "\n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations/data_1H_812119.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations/data_13C_812119.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations/data_HSQC_812119.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations/data_COSY_812119.csv'   \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations/data_1H_812119.csv'\n",
    "\n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations/IR_spectra\"\n",
    "\n",
    "config.pickle_file_path = \"\"\n",
    "\n",
    "config.data_size = 34\n",
    "\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.vector_db = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations/real_sim_34_vectors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33a371-5ccc-4f6a-93c8-00a942f9810d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Data needs to be loaded in csv_1H_path_SGNN 13C ...etc\n",
    "# path to store db\n",
    "config = exp_func.vectorize_db(config, stoi, stoi_MF, \"db\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef005cdd-302d-44f8-88de-0cd614a5ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "vector_db = config.vector_db\n",
    "# Load CSV data\n",
    "df = pd.read_csv(vector_db)\n",
    "\n",
    "# Convert 'Fingerprints' to tensors\n",
    "tqdm.pandas()\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(ast.literal_eval)\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "# Save the DataFrame to Pickle\n",
    "pickle_file = vector_db.replace('.csv', '_v2.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"Data saved to {pickle_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18f2153-2f25-418b-95a9-92b0bb16a71a",
   "metadata": {},
   "source": [
    "##### 5.2.1 Exp 34 molecules vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf9092-706c-42a3-b68d-46c1440ff889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_sim data\n",
    "base_path_exp = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/36_Richard_43_dataset/experimenal_data/\"\n",
    "config.csv_1H_path_exp = f\"{base_path_exp}real_1H_with_AZ_SMILES_v3.csv\"\n",
    "config.csv_13C_path_exp = f\"{base_path_exp}real_13C_with_AZ_SMILES_v3.csv\"\n",
    "config.csv_HSQC_path_exp = f\"{base_path_exp}real_HSQC_with_AZ_SMILES_v3.csv\"\n",
    "config.csv_COSY_path_exp = f\"{base_path_exp}real_COSY_with_AZ_SMILES_v3.csv\"\n",
    "config.IR_data_folder_exp = f\"{base_path_exp}IR_data\"\n",
    "config.csv_path_val = config.csv_1H_path_exp\n",
    "\n",
    "config.pickle_file_path = \"\"\n",
    "\n",
    "config.data_size = 34\n",
    "\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.vector_db = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/36_Richard_43_dataset/experimenal_data/exp_34_vectors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab443c27-61fd-4ef5-b79b-ed0a030b0198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = exp_func.vectorize_db(config, stoi, stoi_MF, \"db\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b19855-55ad-4a5d-9ba9-87e0a37dc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "vector_db = config.vector_db\n",
    "# Load CSV data\n",
    "df = pd.read_csv(vector_db)\n",
    "\n",
    "# Convert 'Fingerprints' to tensors\n",
    "tqdm.pandas()\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(ast.literal_eval)\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "# Save the DataFrame to Pickle\n",
    "pickle_file = vector_db.replace('.csv', '_v2.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"Data saved to {pickle_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2740a5-390e-4a4d-991c-6f3cb8c2e5c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5.3 Plot exp, Sim with TSNE, UMAP, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4613b-9549-495c-bc1e-105cec2a01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Figures\"  # Replace this with your desired folder path\n",
    "\n",
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "train_vectors, train_smiles = exp_func.load_pickle_data('/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/vector_db_train_5Mod_4M_v2_v2.pkl', sample_size=3000)\n",
    "\n",
    "# Load experimental data\n",
    "print(\"Loading experimental data...\")\n",
    "exp_test_file = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/36_Richard_43_dataset/experimenal_data/exp_34_vectors_v2.pkl\"\n",
    "\n",
    "exp_vectors, exp_smiles = exp_func.load_pickle_data(exp_test_file)\n",
    "\n",
    "# Combine all vectors\n",
    "combined_vectors = np.vstack((train_vectors,  exp_vectors))\n",
    "labels = ['Train'] * len(train_vectors) + ['Experimental'] * len(exp_vectors)\n",
    "\n",
    "print(f\"Shape of combined vectors: {combined_vectors.shape}\")\n",
    "print(f\"Number of labels: {len(labels)}\")\n",
    "\n",
    "print(\"Performing dimensionality reduction...\")\n",
    "tsne_result, pca_result, umap_result = exp_func.perform_dimensionality_reduction(combined_vectors)\n",
    "\n",
    "\n",
    "# When calling plot_results, specify the save folder\n",
    "exp_func.plot_tsne_umap_pca_train_test_folder([tsne_result, pca_result, umap_result], labels, \n",
    "             \"Train vs Experimental Vectors\", \n",
    "             ['t-SNE', 'PCA', 'UMAP'],\n",
    "             save_folder)\n",
    "print(\"All plots generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9def6a-acdf-4a9f-a2dd-105c7280bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental data\n",
    "print(\"Loading experimental data...\")\n",
    "sim_test_file = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/SGNN_simulations/real_sim_34_vectors_v2.pkl\"\n",
    "\n",
    "sim_vectors, sim_smiles = exp_func.load_pickle_data(sim_test_file)\n",
    "\n",
    "# Combine all vectors\n",
    "combined_vectors = np.vstack((train_vectors,  sim_vectors))\n",
    "labels = ['Train'] * len(train_vectors) + ['Simulated'] * len(sim_vectors)\n",
    "\n",
    "print(f\"Shape of combined vectors: {combined_vectors.shape}\")\n",
    "print(f\"Number of labels: {len(labels)}\")\n",
    "\n",
    "print(\"Performing dimensionality reduction...\")\n",
    "tsne_result, pca_result, umap_result = exp_func.perform_dimensionality_reduction(combined_vectors)\n",
    "\n",
    "print(\"Plotting results...\")\n",
    "\n",
    "# When calling plot_results, specify the save folder\n",
    "exp_func.plot_tsne_umap_pca_train_test_folder([tsne_result, pca_result, umap_result], labels,              \"Train vs Simulated Vectors\", \n",
    "            ['t-SNE', 'PCA', 'UMAP'],\n",
    "            save_folder)\n",
    "\n",
    "print(\"All plots generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1144708-b295-44d9-9b83-d7c58a368759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7656706a-9992-4169-a09c-1b4c1b8aae91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7242844a-f1ae-492b-a73c-3c27db4bdeb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load MMT PubChem 100 Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addffdb7-04cd-4133-a7d5-feed2a70dcbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.4 1000 Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82014729-86c3-48a5-bfd0-1a518e640af2",
   "metadata": {},
   "source": [
    "##### PC and ZINC Latent space comparison for correct and incorrect molecules\n",
    "- calculations done: /projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MultiModalTransformer/scripts\n",
    "\n",
    "-- FIX VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43ac6b4-8698-415b-94c8-3dbb973f9591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(data_configs, train_data_path, output_folder, ranking_method):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    print(\"Loading training data...\")\n",
    "    train_vectors, train_smiles = exp_func.load_pickle_data(train_data_path, sample_size=3000)\n",
    "\n",
    "    for data_config in data_configs:\n",
    "        exp_func.process_dataset(data_config, train_vectors, train_smiles, output_folder, ranking_method)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_configs = [\n",
    "        {\n",
    "            'weight_range': 'PC_0-250',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_0_250',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/sim_mol_0_250/experiment_results_0_250.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'PC_250-350',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_250_350',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/sim_mol_250_350/experiment_results_250_350.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'PC_350-500',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_350_500',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/sim_mol_350_500/experiment_results_350_500.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'ZINC_250-350',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/ZINC_1000_vectors_v2.pkl.pkl'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    train_data_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/vector_db_train_5Mod_4M_v2_v2.pkl'\n",
    "    output_folder = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/1.0_Experiment_baseline'\n",
    "    ranking_method = 'HSQC & COSY'\n",
    "\n",
    "    main(data_configs, train_data_path, output_folder, ranking_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4f50c-4178-4d06-9152-f082ea2ec64e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/sim_mol_0_250/experiment_results_0_250.pkl\" \n",
    "with open(file_path, 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f19de-6daf-4214-8d25-a68f68a199bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a215fa7-3573-4dd2-aba1-32a2a09315b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5.5 Histograms for NN\n",
    "\n",
    "-- FIX VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a89eb8c-5c43-431a-a423-dcecbf2a77c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "def main_csv_generation(data_configs, output_folder, ranking_method):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for data_config in data_configs:\n",
    "        print(f\"Processing {data_config['weight_range']}...\")\n",
    "        pos_csv_path, neg_csv_path = exp_func.process_dataset_and_save_csv(data_config, output_folder, ranking_method)\n",
    "        print(f\"Positive examples saved to: {pos_csv_path}\")\n",
    "        print(f\"Negative examples saved to: {neg_csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_configs = [\n",
    "        {\n",
    "            'weight_range': 'PC_0-250',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_0_250',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'PC_250-350',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_250_350',\n",
    "            'file_path': '/projects/cc/se_users/knlr326//knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'PC_350-500',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_350_500',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'ZINC_250-350',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/ZINC_1000_vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'ZINC_250-350_4000',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350_4000',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/ZINC_1000_vectors_v2.pkl'\n",
    "        } ,       \n",
    "    ]\n",
    "\n",
    "    \n",
    "    data_configs = [            \n",
    "        {\n",
    "            'weight_range': 'ZINC_250-350_4000',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350_4000',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/ZINC_1000_vectors_v2.pkl'\n",
    "        }  \n",
    "    ]\n",
    "    output_folder = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2'\n",
    "    ranking_method = 'HSQC & COSY'\n",
    "\n",
    "    #main_csv_generation(data_configs, output_folder, ranking_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1501a-b1dd-4754-96ed-c9ce6fb4e406",
   "metadata": {},
   "source": [
    "#### After Fine-tuning for 100 neg compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc9e56-f15f-4b47-be4a-386ec890f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "def main_csv_generation(data_configs, output_folder, ranking_method):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for data_config in data_configs:\n",
    "        print(f\"Processing {data_config['weight_range']}...\")\n",
    "        pos_csv_path, neg_csv_path = exp_func.process_dataset_and_save_csv(data_config, output_folder, ranking_method)\n",
    "        print(f\"Positive examples saved to: {pos_csv_path}\")\n",
    "        print(f\"Negative examples saved to: {neg_csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_configs = [\n",
    "        {\n",
    "            'weight_range': 'PC_0-250_neg_100',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_0_250',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'PC_250-350_neg_100',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_250_350',\n",
    "            'file_path': '/projects/cc/se_users/knlr326//knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'PC_350-500_neg_100',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/PC_350_500',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'ZINC_250-350_neg_100',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350',\n",
    "            'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_1000_data/ZINC_1000_vectors_v2.pkl'\n",
    "        },\n",
    "     \n",
    "    ]\n",
    "\n",
    "    \n",
    "    output_folder = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2'\n",
    "    ranking_method = 'HSQC & COSY'\n",
    "\n",
    "    main_csv_generation(data_configs, output_folder, ranking_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51893c63-262b-4341-99a2-8c270e0755c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59518c8-7c8c-48c5-ab43-464d14f8d9d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of file paths\n",
    "file_paths = [\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_0-250_negative.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_0-250_positive.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_250-350_negative.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_250-350_positive.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_350-500_negative.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_350-500_positive.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/ZINC_250-350_negative.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/ZINC_250-350_positive.csv\"\n",
    "]\n",
    "\n",
    "# Process each file\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        exp_func.rename_column_in_csv(file_path, \"sample_id\", \"sample-id\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "print(\"All files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac20c50-8237-4f4a-9864-1008777a718d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_0-250_negative.csv\"\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_0-250_positive.csv\"\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_250-350_negative.csv\"\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_250-350_positive.csv\"\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_350-500_negative.csv\"\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_350-500_positive.csv\"\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/ZINC_250-350_negative.csv\"\n",
    "#config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/ZINC_250-350_positive.csv\"\n",
    "\n",
    "\n",
    "config.SGNN_gen_folder_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/46_Project_3_Data/test\"\n",
    "config = ex.gen_sim_aug_data(config, IR_config)\n",
    "config.csv_path_val = config.csv_1H_path_SGNN\n",
    "#config = ex.filter_invalid_criteria(config.csv_1H_path_SGNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731ac5d-54d6-41c6-a711-5d2ff8d9c448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.pickle_file_path = \"\"\n",
    "config.data_size = 1000\n",
    "\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "config.vector_db = config.SGNN_csv_gen_smi[:-4] + \"vector.csv\"\n",
    "config = vectorize_db(config, stoi, stoi_MF, \"db\", \"all\")\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "vector_db = config.vector_db\n",
    "# Load CSV data\n",
    "df = pd.read_csv(vector_db)\n",
    "\n",
    "# Convert 'Fingerprints' to tensors\n",
    "tqdm.pandas()\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(ast.literal_eval)\n",
    "df['Fingerprints'] = df['Fingerprints'].progress_apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "# Save the DataFrame to Pickle\n",
    "pickle_file = vector_db.replace('.csv', '_v2.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"Data saved to {pickle_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59d2b8-1b04-48ee-8a3b-516e8ef95132",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_0_250_pkl_pos = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_0-250_positivevector_v2.pkl\"\n",
    "PC_250_350_pkl_pos = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_250-350_positivevector_v2.pkl\"\n",
    "PC_350_500_pkl_pos = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_350-500_positivevector_v2.pkl\"\n",
    "ZINC_250_350_pkl_pos = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/ZINC_250-350_positivevector_v2.pkl\"\n",
    "\n",
    "PC_0_250_pkl_neg = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_0-250_negativevector_v2.pkl\"\n",
    "PC_250_350_pkl_neg = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_250-350_negativevector_v2.pkl\"\n",
    "PC_350_500_pkl_neg = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_350-500_negativevector_v2.pkl\"\n",
    "ZINC_250_350_pkl_neg = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/ZINC_250-350_negativevector_v2.pkl\"\n",
    "\n",
    "#big_vector_db = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/vector_db_train_5Mod_4M_v2_v2.pkl\"\n",
    "#output_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples\"\n",
    "#database_nr = 3975764\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97174dc6-d611-4fdc-92ba-3129640a49b2",
   "metadata": {},
   "source": [
    "##### Chart for Anna Paper PubChem, ZINC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552a8d6-355e-4550-afa8-e5307e9bb68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "PC_0_250_pos = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_0-250_positive.csv\"\n",
    "PC_250_350_pos = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_250-350_positive.csv\"\n",
    "PC_350_500_pos = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_350-500_positive.csv\"\n",
    "ZINC_250_350_pos = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/ZINC_250-350_positive.csv\"\n",
    "PC_0_250_neg = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_0-250_negative.csv\"\n",
    "PC_250_350_neg = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_250-350_negative.csv\"\n",
    "PC_350_500_neg = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/PC_350-500_negative.csv\"\n",
    "ZINC_250_350_neg = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples_2/ZINC_250-350_negative.csv\"\n",
    "\n",
    "# Save location for the figure\n",
    "save_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2\"\n",
    "\n",
    "#def load_pickle(file_path):\n",
    "#    with open(file_path, 'rb') as file:\n",
    "#        return pickle.load(file)\n",
    "def load_pickle(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def process_data(pos_df, neg_df):\n",
    "    total_compounds = 1000  # Assuming 1000 compounds per range\n",
    "    pos_count = len(pos_df)\n",
    "    neg_count = len(neg_df)\n",
    "    failed_count = total_compounds - (pos_count + neg_count)\n",
    "    \n",
    "    return {\n",
    "        'Correct': (pos_count / total_compounds) * 100,\n",
    "        'Incorrect': (neg_count / total_compounds) * 100,\n",
    "        'Failed': (failed_count / total_compounds) * 100\n",
    "    }\n",
    "\n",
    "# Load DataFrames\n",
    "PC_0_250_pos_df = pd.read_csv(PC_0_250_pos)\n",
    "PC_0_250_neg_df = pd.read_csv(PC_0_250_neg)\n",
    "PC_250_350_pos_df = pd.read_csv(PC_250_350_pos)\n",
    "PC_250_350_neg_df = pd.read_csv(PC_250_350_neg)\n",
    "PC_350_500_pos_df = pd.read_csv(PC_350_500_pos)\n",
    "PC_350_500_neg_df = pd.read_csv(PC_350_500_neg)\n",
    "ZINC_250_350_pos_df = pd.read_csv(ZINC_250_350_pos)\n",
    "ZINC_250_350_neg_df = pd.read_csv(ZINC_250_350_neg)\n",
    "\n",
    "# Process data\n",
    "data_0_250 = process_data(PC_0_250_pos_df, PC_0_250_neg_df)\n",
    "data_250_350 = process_data(PC_250_350_pos_df, PC_250_350_neg_df)\n",
    "data_350_500 = process_data(PC_350_500_pos_df, PC_350_500_neg_df)\n",
    "data_ZINC_250_350 = process_data(ZINC_250_350_pos_df, ZINC_250_350_neg_df)\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = {\n",
    "    'Correct': [data_0_250['Correct'], data_250_350['Correct'], data_350_500['Correct'], data_ZINC_250_350['Correct']],\n",
    "    'Incorrect': [data_0_250['Incorrect'], data_250_350['Incorrect'], data_350_500['Incorrect'], data_ZINC_250_350['Incorrect']],\n",
    "    'Failed': [data_0_250['Failed'], data_250_350['Failed'], data_350_500['Failed'], data_ZINC_250_350['Failed']]\n",
    "}\n",
    "\n",
    "def create_stacked_bar_chart(data, categories, title, save_path):\n",
    "    fontsize = 22\n",
    "    colors = [\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "]\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    bottom = np.zeros(4)\n",
    "    bars = []\n",
    "    for i, category in enumerate(categories):\n",
    "        values = data[category]\n",
    "        bar = ax.bar(range(4), values, bottom=bottom, label=category, color=colors[i], edgecolor='black')\n",
    "        # Set black edges for each bar patch\n",
    "        for patch in bar:\n",
    "            patch.set_edgecolor('black')\n",
    "        bottom += values\n",
    "        bars.append(bar)\n",
    "    \n",
    "    ax.set_title(title, fontsize=fontsize, pad=20)\n",
    "    ax.set_xticks(range(4))\n",
    "    ax.set_xticklabels(['PC (0-250 Da)', 'PC (250-350 Da)', 'PC (350-500 Da)', 'ZINC (250-350 Da)'], fontsize=12)\n",
    "    ax.set_xticklabels(['Set 1', 'Set 2', 'Set 3', 'ZINC'], fontsize=fontsize)\n",
    "    ax.set_ylabel('Percentage', fontsize=fontsize)\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    ax.tick_params(axis='y', labelsize=fontsize)\n",
    "    \n",
    "    ax.legend(loc='lower right', fontsize=fontsize-4)\n",
    "    \n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i, fmt='%.1f%%', label_type='center', fontsize=fontsize)\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "categories = ['Correct', 'Incorrect', 'Failed']\n",
    "\n",
    "# Create save path\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'PubChem_ZINC_Dataset_Results_v2.png')\n",
    "\n",
    "fig = create_stacked_bar_chart(plot_data, categories, 'PubChem and ZINC Dataset Results', save_path)\n",
    "\"\"\"\n",
    "# Print the percentages for each range\n",
    "for range_name, data in zip(['PC 0-250', 'PC 250-350', 'PC 350-500', 'ZINC 250-350'], \n",
    "                            [data_0_250, data_250_350, data_350_500, data_ZINC_250_350]):\n",
    "    print(f\"\\nPercentages for {range_name} Da range:\")\n",
    "    for category, percentage in data.items():\n",
    "        print(f\"{category}: {percentage:.1f}%\")\n",
    "\n",
    "# Print DataFrame information\n",
    "for name, df in [\n",
    "    (\"PC_0_250_pos\", PC_0_250_pos_df),\n",
    "    (\"PC_0_250_neg\", PC_0_250_neg_df),\n",
    "    (\"PC_250_350_pos\", PC_250_350_pos_df),\n",
    "    (\"PC_250_350_neg\", PC_250_350_neg_df),\n",
    "    (\"PC_350_500_pos\", PC_350_500_pos_df),\n",
    "    (\"PC_350_500_neg\", PC_350_500_neg_df),\n",
    "    (\"ZINC_250_350_pos\", ZINC_250_350_pos_df),\n",
    "    (\"ZINC_250_350_neg\", ZINC_250_350_neg_df)\n",
    "]:\n",
    "    print(f\"\\n{name} DataFrame:\")\n",
    "    print(df.info())\n",
    "    print(df.head())\n",
    "\n",
    "print(f\"\\nFigure saved to: {save_path}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbebeef1-f598-4aa2-9220-9eab8a6395d9",
   "metadata": {},
   "source": [
    "##### Save 100 neg molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1c82c-b394-4ea1-a528-973c0838e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "negative_files = {\n",
    "    'PC_0_250': \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_0-250_negativevector_v2.pkl\",\n",
    "    'PC_250_350': \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_250-350_negativevector_v2.pkl\",\n",
    "    'PC_350_500': \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_350-500_negativevector_v2.pkl\",\n",
    "    'ZINC_250_350': \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/ZINC_250-350_negativevector_v2.pkl\"\n",
    "}\n",
    "\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def sample_and_save(file_path, sample_size=100):\n",
    "    # Load the DataFrame\n",
    "    df = load_pickle(file_path)\n",
    "    \n",
    "    # Sample 100 rows\n",
    "    sampled_df = df.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Create the new file name\n",
    "    dir_path = os.path.dirname(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    new_file_name = file_name.replace('.pkl', '_100_neg.csv')\n",
    "    new_file_path = os.path.join(dir_path, new_file_name)\n",
    "    \n",
    "    # Save the sampled DataFrame as CSV\n",
    "    sampled_df.to_csv(new_file_path, index=False)\n",
    "    \n",
    "    print(f\"Saved {sample_size} samples to: {new_file_path}\")\n",
    "\n",
    "# Process each negative file\n",
    "for name, file_path in negative_files.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    sample_and_save(file_path)\n",
    "\n",
    "print(\"All files processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a8246-1237-492c-a51c-a46c6097fae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "csv_files = [\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_0-250_negativevector_v2_100_neg.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_250-350_negativevector_v2_100_neg.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_350-500_negativevector_v2_100_neg.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/ZINC_250-350_negativevector_v2_100_neg.csv\"\n",
    "]\n",
    "\n",
    "def add_sample_id(file_path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Create the sample-id column\n",
    "    df['sample-id'] = [f'NEG{i:05d}' for i in range(1, len(df) + 1)]\n",
    "    \n",
    "    # Move the sample-id column to the first position\n",
    "    cols = df.columns.tolist()\n",
    "    cols = ['sample-id'] + [col for col in cols if col != 'sample-id']\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Save the updated DataFrame back to CSV\n",
    "    df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"Added sample-id column to: {file_path}\")\n",
    "    print(f\"First 5 rows of the updated file:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Process each CSV file\n",
    "for file_path in csv_files:\n",
    "    add_sample_id(file_path)\n",
    "\n",
    "print(\"All files processed and updated with sample-id column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ae5ed-08b5-4317-8342-377a826b69c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80337cdb-38ad-4248-9337-42f436f6c823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420133cd-c513-4f18-94df-eb01ebf1c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/ZINC_250-350_negativevector_v2_100_neg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3359dbd-b431-49d7-bdba-0106b35af97e",
   "metadata": {},
   "source": [
    "#### 5.6 Use 100 of each failed categories to do the improvment cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bfa28-d7be-48e6-8910-70bafdc8ebaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "from typing import List, Dict, Any, Union, Tuple\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def split_dataset(config, chunk_size: int) -> List[pd.DataFrame]:\n",
    "    df = pd.read_csv(config.SGNN_csv_gen_smi)\n",
    "    return [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "\n",
    "def create_chunk_folder(config, idx: int) -> str:\n",
    "    base_dir = config.model_save_dir\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    chunk_folder_name = f\"chunk_{idx:03d}_{current_datetime}\"\n",
    "    chunk_folder_path = os.path.join(base_dir, chunk_folder_name)\n",
    "    \n",
    "    os.makedirs(chunk_folder_path, exist_ok=True)\n",
    "    print(f\"Created folder for chunk {idx}: {chunk_folder_path}\")\n",
    "    \n",
    "    return chunk_folder_path\n",
    "\n",
    "def test_pretrained_model_on_sim_data_before(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, idx):\n",
    "    MW_filter, greedy_full = True, False\n",
    "    \n",
    "    print(\"prepare_data\")\n",
    "    config = prepare_data(config, chunk)\n",
    "    print(\"generate_simulated_data\")\n",
    "    config = generate_simulated_data(config, IR_config)\n",
    "\n",
    "    print(\"load_model_and_data\")\n",
    "    model_MMT, val_dataloader, val_dataloader_multi = load_model_and_data(config, stoi, stoi_MF)\n",
    "\n",
    "    print(\"run_model_analysis\")\n",
    "    prob_dict_results_1c_, results_dict_1c_ = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "    results = test_model_performance(config, model_MMT, val_dataloader, val_dataloader_multi, stoi, itos, stoi_MF, itos_MF)\n",
    "\n",
    "    save_results_before(results, config, idx)\n",
    "\n",
    "    return config\n",
    "\n",
    "def prepare_data(config: Any, chunk: pd.DataFrame) -> Any:\n",
    "    chunk_csv_path = os.path.join(config.pkl_save_folder, \"SGNN_csv_gen_smi.csv\")\n",
    "    chunk.to_csv(chunk_csv_path)\n",
    "    config.SGNN_csv_gen_smi = chunk_csv_path \n",
    "    config.data_size = len(chunk)\n",
    "    return config\n",
    "\n",
    "def generate_simulated_data(config: Any, IR_config: Any) -> Any:\n",
    "    config.execution_type = \"data_generation\"\n",
    "    if config.execution_type == \"data_generation\":\n",
    "        print(\"\\033[1m\\033[31mThis is: data_generation\\033[0m\")\n",
    "        #import IPython; IPython.embed();\n",
    "\n",
    "        config = ex.gen_sim_aug_data(config, IR_config)\n",
    "        backup_config_paths(config)\n",
    "    return config\n",
    "\n",
    "def backup_config_paths(config: Any) -> None:\n",
    "    config.csv_1H_path_SGNN_backup = copy.deepcopy(config.csv_1H_path_SGNN)\n",
    "    config.csv_13C_path_SGNN_backup = copy.deepcopy(config.csv_13C_path_SGNN)\n",
    "    config.csv_HSQC_path_SGNN_backup = copy.deepcopy(config.csv_HSQC_path_SGNN)\n",
    "    config.csv_COSY_path_SGNN_backup = copy.deepcopy(config.csv_COSY_path_SGNN)\n",
    "    config.IR_data_folder_backup = copy.deepcopy(config.IR_data_folder)\n",
    "\n",
    "def save_results_before(results: Dict[str, Any], config: Any, idx: int) -> None:\n",
    "    variables_to_save = {\n",
    "        'avg_tani_bl_ZINC': results['avg_tani_bl_ZINC_'],\n",
    "        'results_dict_greedy_bl_ZINC': results.get('results_dict_greedy_bl_ZINC_'),\n",
    "        'failed_bl_ZINC': results.get('failed_bl_ZINC_'),\n",
    "        'avg_tani_greedy_bl_ZINC': results['avg_tani_greedy_bl_ZINC_'],\n",
    "        'results_dict_ZINC_greedy_bl': results.get('results_dict_ZINC_greedy_bl_'),\n",
    "        'total_results_bl_ZINC': results['total_results_bl_ZINC_'],\n",
    "        'corr_sampleing_prob_bl_ZINC': results['corr_sampleing_prob_bl_ZINC_'],\n",
    "        'results_dict_bl_ZINC': results['results_dict_bl_ZINC_'],\n",
    "    }\n",
    "    save_data_with_datetime_index(variables_to_save, config.pkl_save_folder, \"before_sim_data\", idx)\n",
    "\n",
    "def create_run_folder(chunk_folder, idx):\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_folder_name = f\"run_{idx}_{current_datetime}\"\n",
    "    run_folder_path = os.path.join(chunk_folder, run_folder_name)\n",
    "    \n",
    "    os.makedirs(run_folder_path, exist_ok=True)\n",
    "    print(f\"Created folder for run {idx}: {run_folder_path}\")\n",
    "    \n",
    "    return run_folder_path\n",
    "\n",
    "def fine_tune_model_aug_mol(config, stoi, stoi_MF, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "    config, all_gen_smis, aug_mol_df = generate_augmented_molecules_from_aug_mol(config, chunk, idx)\n",
    "    \n",
    "    config.parent_model_save_dir = config.model_save_dir\n",
    "    config.model_save_dir = config.current_run_folder \n",
    "    \n",
    "    if config.execution_type == \"transformer_improvement\":\n",
    "        print(\"\\033[1m\\033[31mThis is: transformer_improvement, sim_data_gen == TRUE\\033[0m\")\n",
    "        config.training_setup = \"pretraining\"\n",
    "        mtf.run_MMT(config, stoi, stoi_MF)\n",
    "    \n",
    "    config.model_save_dir = config.parent_model_save_dir\n",
    "    #config = ex.update_model_path(config)\n",
    "\n",
    "    return config, aug_mol_df, all_gen_smis\n",
    "\n",
    "\n",
    "def generate_augmented_molecules_from_aug_mol(config, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    ############# THis is just relevant for the augmented molecules #############\n",
    "    #chunk.rename(columns={'SMILES': 'SMILES_orig', 'SMILES_regio_isomers': 'SMILES'}, inplace=True)\n",
    "    #############################################################################\n",
    "    \n",
    "    script_dir = os.getcwd()\n",
    "    \n",
    "    base_path = os.path.abspath(os.path.join(script_dir, 'deep-molecular-optimization'))\n",
    "\n",
    "    csv_file_path = f'{base_path}/data/MMP/test_selection_2.csv'\n",
    "    chunk.to_csv(csv_file_path, index=False)\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "    config.data_size = len(chunk)\n",
    "    config.n_samples = config.data_size\n",
    "\n",
    "    config, results_dict_MF = generate_smiles_mf(config)\n",
    "\n",
    "    combined_list_MF = process_generated_smiles(results_dict_MF, config)\n",
    "\n",
    "    all_gen_smis = filter_and_combine_smiles(combined_list_MF)\n",
    "\n",
    "    aug_mol_df = create_augmented_dataframe(all_gen_smis)\n",
    "\n",
    "    config, final_df = ex.blend_aug_with_train_data(config, aug_mol_df)\n",
    "\n",
    "    config = ex.gen_sim_aug_data(config, IR_config)\n",
    "    config.execution_type = \"transformer_improvement\"\n",
    "\n",
    "    return config, all_gen_smis, aug_mol_df\n",
    "\n",
    "\n",
    "def fine_tune_model(config, stoi, stoi_MF, chunk, idx):\n",
    "    \"\"\"\n",
    "    Fine-tune the model on a chunk of data.\n",
    "    \"\"\"\n",
    "    config, aug_mol_df, all_gen_smis = generate_augmented_molecules(config, chunk, idx)\n",
    "    \n",
    "    config.parent_model_save_dir = config.model_save_dir\n",
    "    new_model_save_dir = create_model_save_dir(config.parent_model_save_dir, idx)\n",
    "    config.model_save_dir = new_model_save_dir\n",
    "    \n",
    "    # Fine-tune the model\n",
    "    if config.execution_type == \"transformer_improvement\":\n",
    "        print(\"\\033[1m\\033[31mThis is: transformer_improvement, sim_data_gen == TRUE\\033[0m\")\n",
    "        config.training_setup = \"pretraining\"\n",
    "        mtf.run_MMT(config, stoi, stoi_MF)\n",
    "        \n",
    "    #config = ex.update_model_path(config)\n",
    "    config.model_save_dir = config.parent_model_save_dir\n",
    "    \n",
    "    return config, aug_mol_df, all_gen_smis\n",
    "\n",
    "def generate_augmented_molecules(config, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "    script_dir = os.getcwd()\n",
    "    \n",
    "    base_path = os.path.abspath(os.path.join(script_dir, 'deep-molecular-optimization'))\n",
    "\n",
    "    csv_file_path = f'{base_path}/data/MMP/test_selection_2.csv'\n",
    "    chunk.to_csv(csv_file_path, index=False)\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "    config.data_size = len(chunk)\n",
    "    config.n_samples = config.data_size\n",
    "\n",
    "    config, results_dict_MF = generate_smiles_mf(config)\n",
    "\n",
    "    combined_list_MF = process_generated_smiles(results_dict_MF, config)\n",
    "\n",
    "    all_gen_smis = filter_and_combine_smiles(combined_list_MF)\n",
    "\n",
    "    aug_mol_df = create_augmented_dataframe(all_gen_smis)\n",
    "\n",
    "    config, final_df = ex.blend_aug_with_train_data(config, aug_mol_df)\n",
    "\n",
    "    config = ex.gen_sim_aug_data(config, IR_config)\n",
    "    config.execution_type = \"transformer_improvement\"\n",
    "\n",
    "    return config, all_gen_smis, aug_mol_df\n",
    "\n",
    "\n",
    "def generate_smiles_mf(config):\n",
    "    print(\"\\033[1m\\033[31mThis is: SMI_generation_MF\\033[0m\")\n",
    "    return ex.SMI_generation_MF(config, stoi, stoi_MF, itos, itos_MF)\n",
    "\n",
    "def process_generated_smiles(results_dict_MF, config):\n",
    "    results_dict_MF = {key: value for key, value in results_dict_MF.items() if not hf.contains_only_nan(value)}\n",
    "    for key, value in results_dict_MF.items():\n",
    "        results_dict_MF[key] = hf.remove_nan_from_list(value)\n",
    "\n",
    "    combined_list_MF, _, _, _ = cv.plot_cluster_MF(results_dict_MF, config)\n",
    "    return combined_list_MF\n",
    "\n",
    "def filter_and_combine_smiles(combined_list_MF):\n",
    "    print(\"\\033[1m\\033[31mThis is: combine_MMT_MF\\033[0m\")\n",
    "    all_gen_smis = combined_list_MF\n",
    "    all_gen_smis = [smiles for smiles in all_gen_smis if smiles != 'NAN']\n",
    "\n",
    "    val_data = pd.read_csv(config.csv_path_val)\n",
    "    all_gen_smis = mrtf.filter_smiles(val_data, all_gen_smis)\n",
    "    return all_gen_smis\n",
    "\n",
    "def create_augmented_dataframe(all_gen_smis):\n",
    "    length_of_list = len(all_gen_smis)\n",
    "    random_number_strings = [f\"GT_{str(i).zfill(7)}\" for i in range(1, length_of_list + 1)]\n",
    "    return pd.DataFrame({'SMILES': all_gen_smis, 'sample-id': random_number_strings})\n",
    "\n",
    "def setup_data_paths(config):\n",
    "    base_path_acd = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/\"\n",
    "    config.csv_1H_path_ACD = f\"{base_path_acd}ACD_1H_with_SN_filtered_v3.csv\"\n",
    "    config.csv_13C_path_ACD = f\"{base_path_acd}ACD_13C_with_SN_filtered_v3.csv\"\n",
    "    config.csv_HSQC_path_ACD = f\"{base_path_acd}ACD_HSQC_with_SN_filtered_v3.csv\"\n",
    "    config.csv_COSY_path_ACD = f\"{base_path_acd}ACD_COSY_with_SN_filtered_v3.csv\"\n",
    "    config.IR_data_folder_ACD = f\"{base_path_acd}IR_spectra\"\n",
    "    \n",
    "    base_path_exp = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/36_Richard_43_dataset/experimenal_data/\"\n",
    "    config.csv_1H_path_exp = f\"{base_path_exp}real_1H_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_13C_path_exp = f\"{base_path_exp}real_13C_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_HSQC_path_exp = f\"{base_path_exp}real_HSQC_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_COSY_path_exp = f\"{base_path_exp}real_COSY_with_AZ_SMILES_v3.csv\"\n",
    "    config.IR_data_folder_exp = f\"{base_path_exp}IR_data\"\n",
    "    return config\n",
    "\n",
    "def test_model_on_neg_dataset(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, aug_mol_df, all_gen_smis):\n",
    "    checkpoint_path_backup = config.checkpoint_path    \n",
    "    config.pickle_file_path = \"\"\n",
    "    config.training_mode = \"1H_13C_HSQC_COSY_IR_MF_MW\"\n",
    "    config = test_on_data(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, \"sim\", aug_mol_df, all_gen_smis)\n",
    "    config.checkpoint_path = checkpoint_path_backup\n",
    "    return config\n",
    "\n",
    "def test_on_data(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, data_type, aug_mol_df, all_gen_smis):\n",
    "    if data_type == 'sim':\n",
    "        restore_backup_configs(config)\n",
    "    #else:\n",
    "    #    sample_ids = chunk['sample-id'].tolist()\n",
    "    #    process_spectrum_data(config, sample_ids, data_type)\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    update_config_settings(config)\n",
    "    last_checkpoint = get_last_checkpoint(config.current_run_folder)\n",
    "    config.checkpoint_path = last_checkpoint\n",
    "    \n",
    "    model_MMT, val_dataloader, val_dataloader_multi = load_model_and_data(config, stoi, stoi_MF)\n",
    "    \n",
    "    prob_dict_results_1c_, results_dict_1c_ = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "    results = test_model_performance(config, model_MMT, val_dataloader, val_dataloader_multi,\n",
    "                                     stoi, itos, stoi_MF, itos_MF)\n",
    "    \n",
    "    if data_type == 'sim':\n",
    "        results['aug_mol_df'] = aug_mol_df\n",
    "        results['all_gen_smis'] = all_gen_smis\n",
    "    \n",
    "    save_results_acd_exp(results, config, data_type, composite_idx)\n",
    "    return config\n",
    "\n",
    "def restore_backup_configs(config):\n",
    "    config.csv_1H_path_SGNN = config.csv_1H_path_SGNN_backup\n",
    "    config.csv_13C_path_SGNN = config.csv_13C_path_SGNN_backup\n",
    "    config.csv_HSQC_path_SGNN = config.csv_HSQC_path_SGNN_backup\n",
    "    config.csv_COSY_path_SGNN = config.csv_COSY_path_SGNN_backup\n",
    "    config.IR_data_folder = config.IR_data_folder_backup \n",
    "    config.csv_path_val = config.csv_1H_path_SGNN_backup\n",
    "    config.pickle_file_path = \"\"\n",
    "    \n",
    "\n",
    "def process_spectrum_data(config: Any, sample_ids: List[str], data_type: str) -> None:\n",
    "    spectrum_types = ['1H', '13C', 'HSQC', 'COSY']\n",
    "    for spectrum in spectrum_types:\n",
    "        csv_path = getattr(config, f'csv_{spectrum}_path_{data_type}')\n",
    "        df_data = pd.read_csv(csv_path)\n",
    "        df_data['sample-id'] = df_data['AZ_Number']\n",
    "        data = select_relevant_samples(df_data, sample_ids)\n",
    "        dummy_path, config = save_and_update_config(config, data_type, spectrum, data)\n",
    "        print(f\"Saved {spectrum} data to: {dummy_path}\")\n",
    "    if data_type == \"ACD\" or data_type == \"sim\":\n",
    "        config.IR_data_folder = config.IR_data_folder_backup \n",
    "    elif  data_type == \"exp\":\n",
    "        config.IR_data_folder = config.IR_data_folder_exp \n",
    "\n",
    "    \n",
    "    \n",
    "def select_relevant_samples(df: pd.DataFrame, sample_ids: List[str]) -> pd.DataFrame:\n",
    "    return df[df['sample-id'].isin(sample_ids)]\n",
    "\n",
    "def save_and_update_config(config, data_type: str, spectrum_type: str, data: pd.DataFrame) -> Tuple[str, Any]:\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    dummy_path = os.path.join(temp_dir, f\"{data_type}_{spectrum_type}_selected_samples.csv\")\n",
    "    \n",
    "    data.to_csv(dummy_path, index=False)\n",
    "    \n",
    "    config_key = f'csv_{spectrum_type}_path_SGNN'\n",
    "    setattr(config, config_key, dummy_path)\n",
    "    \n",
    "    return dummy_path, config\n",
    "\n",
    "def update_config_settings(config: Any) -> None:\n",
    "    config.csv_path_val = config.csv_1H_path_SGNN\n",
    "    config.pickle_file_path = \"\"\n",
    "\n",
    "def get_last_checkpoint(model_folder: str) -> str:\n",
    "    checkpoints = [f for f in os.listdir(model_folder) if f.endswith('.ckpt')]\n",
    "    if not checkpoints:\n",
    "        raise ValueError(f\"No checkpoints found in {model_folder}\")\n",
    "    \n",
    "    last_checkpoint = max(checkpoints, key=lambda x: os.path.getmtime(os.path.join(model_folder, x)))\n",
    "    return os.path.join(model_folder, last_checkpoint)\n",
    "\n",
    "def load_model_and_data(config: Any, stoi: Dict, stoi_MF: Dict) -> Tuple[Any, Any, Any]:\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    return model_MMT, val_dataloader, val_dataloader_multi\n",
    "\n",
    "def test_model_performance(config: Any, model_MMT: Any, val_dataloader: Any, val_dataloader_multi: Any, \n",
    "                           stoi: Dict, itos: Dict, stoi_MF: Dict, itos_MF: Dict) -> Dict[str, Any]:\n",
    "    print(\"\\033[1m\\033[31mThis is: test_performance\\033[0m\")\n",
    "    \n",
    "    MW_filter = True\n",
    "    greedy_full = False\n",
    "    \n",
    "    model_CLIP = mrtf.load_CLIP_model(config)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['results_dict_bl_ZINC_'] = mrtf.run_test_mns_performance_CLIP_3(\n",
    "        config, model_MMT, model_CLIP, val_dataloader, stoi, itos, MW_filter)\n",
    "    results['results_dict_bl_ZINC_'], counter = mrtf.filter_invalid_inputs(results['results_dict_bl_ZINC_'])\n",
    "\n",
    "    results['avg_tani_bl_ZINC_'], html_plot = rbgvm.plot_hist_of_results(results['results_dict_bl_ZINC_'])\n",
    "\n",
    "    if greedy_full:\n",
    "        results['results_dict_greedy_bl_ZINC_'], results['failed_bl_ZINC_'] = mrtf.run_test_performance_CLIP_greedy_3(\n",
    "            config, stoi, stoi_MF, itos, itos_MF)\n",
    "        results['avg_tani_greedy_bl_ZINC_'], html_plot_greedy = rbgvm.plot_hist_of_results_greedy(\n",
    "            results['results_dict_greedy_bl_ZINC_'])\n",
    "    else:\n",
    "        config, results['results_dict_ZINC_greedy_bl_'] = mrtf.run_greedy_sampling(\n",
    "            config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "        results['avg_tani_greedy_bl_ZINC_'] = results['results_dict_ZINC_greedy_bl_'][\"tanimoto_mean\"]\n",
    "\n",
    "    results['total_results_bl_ZINC_'] = mrtf.run_test_performance_CLIP_3(\n",
    "        config, model_MMT, val_dataloader, stoi)\n",
    "    results['corr_sampleing_prob_bl_ZINC_'] = results['total_results_bl_ZINC_'][\"statistics_multiplication_avg\"][0]\n",
    "\n",
    "    print(\"avg_tani, avg_tani_greedy, corr_sampleing_prob'\")\n",
    "    print(results['avg_tani_bl_ZINC_'], results['avg_tani_greedy_bl_ZINC_'], results['corr_sampleing_prob_bl_ZINC_'])\n",
    "    print(\"Greedy tanimoto results\")\n",
    "    rbgvm.plot_hist_of_results_greedy_new(results['results_dict_ZINC_greedy_bl_'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_results_acd_exp(results: Dict[str, Any], config: Any, data_type: str, composite_idx: str) -> None:\n",
    "    variables_to_save = {\n",
    "        'avg_tani_bl_ZINC': results['avg_tani_bl_ZINC_'],\n",
    "        'results_dict_greedy_bl_ZINC': results.get('results_dict_greedy_bl_ZINC_'),\n",
    "        'failed_bl_ZINC': results.get('failed_bl_ZINC_'),\n",
    "        'avg_tani_greedy_bl_ZINC': results['avg_tani_greedy_bl_ZINC_'],\n",
    "        'results_dict_ZINC_greedy_bl': results.get('results_dict_ZINC_greedy_bl_'),\n",
    "        'total_results_bl_ZINC': results['total_results_bl_ZINC_'],\n",
    "        'corr_sampleing_prob_bl_ZINC': results['corr_sampleing_prob_bl_ZINC_'],\n",
    "        'results_dict_bl_ZINC': results['results_dict_bl_ZINC_'],\n",
    "        'checkpoint_path': config.checkpoint_path,\n",
    "    }\n",
    "    \n",
    "    if data_type == 'sim':\n",
    "        variables_to_save['aug_mol_df'] = results.get('aug_mol_df')\n",
    "        variables_to_save['all_gen_smis'] = results.get('all_gen_smis')\n",
    "    \n",
    "    save_data_with_datetime_index(\n",
    "        variables_to_save, \n",
    "        config.pkl_save_folder, \n",
    "        f\"{data_type}_sim_data\", \n",
    "        composite_idx\n",
    "    )\n",
    "\n",
    "def save_data_with_datetime_index(data: Any, base_folder: str, name: str, idx: Union[int, str]) -> None:\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{current_datetime}_{name}_{idx}.pkl\"\n",
    "    os.makedirs(base_folder, exist_ok=True)\n",
    "    file_path = os.path.join(base_folder, filename)\n",
    "\n",
    "    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    \n",
    "    print(f\"Data saved to: {file_path}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517cfd6-aaaf-42a7-a139-421e55524a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_MMT.improvement_cycle_neg_examples_v15_4 as icne\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25583afa-fd78-47ed-8aea-52bb797b1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def main_IC_neg(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF, num_training_runs=3):\n",
    "    chunks = icne.split_dataset(config, chunk_size)\n",
    "    config.model_save_dir = config.pkl_save_folder\n",
    "    model_save_dir_backup = config.model_save_dir\n",
    "    original_checkpoint_path = config.checkpoint_path  # Store the original checkpoint path\n",
    "\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {chunk_idx+1} of {len(chunks)}\")\n",
    "        \n",
    "        chunk_folder = icne.create_chunk_folder(config, chunk_idx)\n",
    "        config.current_chunk_folder = chunk_folder\n",
    "            \n",
    "        config.blank_percentage = 0\n",
    "        config = icne.test_pretrained_model_on_sim_data_before(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, f\"{chunk_idx}_{0}\")\n",
    "        print(config.csv_1H_path_SGNN)\n",
    "        for run_idx in range(num_training_runs):\n",
    "            print(f\"Starting training run {run_idx+1} of {num_training_runs}\")\n",
    "            \n",
    "            run_folder = icne.create_run_folder(config.current_chunk_folder, f\"{chunk_idx}_{run_idx}\")\n",
    "            config.current_run_folder = run_folder\n",
    "            config.model_save_dir = run_folder\n",
    "\n",
    "            config.blank_percentage = 50\n",
    "            config, aug_mol_df, all_gen_smis = icne.fine_tune_model_aug_mol(config, IR_config, stoi, stoi_MF, chunk, f\"{chunk_idx}_{run_idx}\")\n",
    "            #import IPython; IPython.embed();\n",
    "\n",
    "            ### Retrun the labelling of the smiles to test it on the correct one\n",
    "            #chunk.rename(columns={'SMILES': 'SMILES_regio_isomers', 'SMILES_orig': 'SMILES'}, inplace=True)\n",
    "\n",
    "            config.blank_percentage = 0\n",
    "            config = icne.setup_data_paths(config)\n",
    "            config = icne.test_model_on_neg_dataset(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, f\"{chunk_idx}_{run_idx}\", aug_mol_df, all_gen_smis)\n",
    "\n",
    "            config.checkpoint_path = original_checkpoint_path\n",
    "        \n",
    "        print(f\"Chunk {chunk_idx+1} completed. All training runs finished.\")\n",
    "        config.model_save_dir = model_save_dir_backup\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93a291-8e06-4ad9-9f00-1a7c9bc2b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_skip_chunk(base_path, chunk_idx):\n",
    "    \"\"\"\n",
    "    Check if a chunk folder exists and contains sufficient processed data,\n",
    "    ignoring timestamps in folder names.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): Base directory path\n",
    "        chunk_idx (int): Index of the chunk to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the chunk should be skipped (already processed), False otherwise\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Format the chunk prefix to match (ensuring 3 digits with leading zeros)\n",
    "    chunk_prefix = f\"chunk_{chunk_idx:03d}_\"\n",
    "    \n",
    "    # Get all directories in base_path\n",
    "    try:\n",
    "        all_dirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "        \n",
    "        # Find matching chunk folder (ignoring timestamp)\n",
    "        matching_chunks = [d for d in all_dirs if d.startswith(chunk_prefix)]\n",
    "        \n",
    "        if not matching_chunks:\n",
    "            return False\n",
    "            \n",
    "        # Use the first matching chunk folder found\n",
    "        chunk_folder = matching_chunks[0]\n",
    "        chunk_path = os.path.join(base_path, chunk_folder)\n",
    "        \n",
    "        # Check if there are any run folders inside the chunk folder\n",
    "        run_folders = [d for d in os.listdir(chunk_path) if os.path.isdir(os.path.join(chunk_path, d))]\n",
    "        if not run_folders:\n",
    "            return False\n",
    "        \n",
    "        # Check if at least one run folder contains more than 5 files\n",
    "        for run_folder in run_folders:\n",
    "            run_path = os.path.join(chunk_path, run_folder)\n",
    "            files = [f for f in os.listdir(run_path) if os.path.isfile(os.path.join(run_path, f))]\n",
    "            if len(files) > 5:\n",
    "                return True\n",
    "                \n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking chunk {chunk_idx}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main_IC_neg(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF, num_training_runs=3):\n",
    "    chunks = icne.split_dataset(config, chunk_size)\n",
    "    config.model_save_dir = config.pkl_save_folder\n",
    "    model_save_dir_backup = config.model_save_dir\n",
    "    original_checkpoint_path = config.checkpoint_path  # Store the original checkpoint path\n",
    "\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {chunk_idx+1} of {len(chunks)}\")\n",
    "        \n",
    "        if should_skip_chunk(config.pkl_save_folder, chunk_idx):\n",
    "            print(f\"Skipping chunk {chunk_idx+1} as it appears to be already processed\")\n",
    "            continue\n",
    "            \n",
    "        # If we reach here, either the chunk doesn't exist or is incomplete\n",
    "        # Find and delete any existing incomplete chunk folder\n",
    "        chunk_prefix = f\"chunk_{chunk_idx:03d}_\"\n",
    "        try:\n",
    "            all_dirs = [d for d in os.listdir(config.pkl_save_folder) if os.path.isdir(os.path.join(config.pkl_save_folder, d))]\n",
    "            matching_chunks = [d for d in all_dirs if d.startswith(chunk_prefix)]\n",
    "            if matching_chunks:\n",
    "                chunk_to_delete = os.path.join(config.pkl_save_folder, matching_chunks[0])\n",
    "                print(f\"Removing incomplete chunk folder: {matching_chunks[0]}\")\n",
    "                shutil.rmtree(chunk_to_delete)\n",
    "        except Exception as e:\n",
    "            print(f\"Error while trying to delete incomplete chunk folder: {str(e)}\")\n",
    "            \n",
    "            \n",
    "        chunk_folder = icne.create_chunk_folder(config, chunk_idx)\n",
    "        config.current_chunk_folder = chunk_folder\n",
    "            \n",
    "        config.blank_percentage = 0\n",
    "        config = icne.test_pretrained_model_on_sim_data_before(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, f\"{chunk_idx}_{0}\")\n",
    "        print(config.csv_1H_path_SGNN)\n",
    "        for run_idx in range(num_training_runs):\n",
    "            print(f\"Starting training run {run_idx+1} of {num_training_runs}\")\n",
    "            \n",
    "            run_folder = icne.create_run_folder(config.current_chunk_folder, f\"{chunk_idx}_{run_idx}\")\n",
    "            config.current_run_folder = run_folder\n",
    "            config.model_save_dir = run_folder\n",
    "\n",
    "            config.blank_percentage = 50\n",
    "            config, aug_mol_df, all_gen_smis = icne.fine_tune_model_aug_mol(config, IR_config, stoi, stoi_MF, chunk, f\"{chunk_idx}_{run_idx}\")\n",
    "            #import IPython; IPython.embed();\n",
    "\n",
    "            ### Retrun the labelling of the smiles to test it on the correct one\n",
    "            #chunk.rename(columns={'SMILES': 'SMILES_regio_isomers', 'SMILES_orig': 'SMILES'}, inplace=True)\n",
    "\n",
    "            config.blank_percentage = 0\n",
    "            config = icne.setup_data_paths(config)\n",
    "            config = icne.test_model_on_neg_dataset(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, f\"{chunk_idx}_{run_idx}\", aug_mol_df, all_gen_smis)\n",
    "\n",
    "            config.checkpoint_path = original_checkpoint_path\n",
    "        \n",
    "        print(f\"Chunk {chunk_idx+1} completed. All training runs finished.\")\n",
    "        config.model_save_dir = model_save_dir_backup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a5d09-6c4f-428f-850c-9e43f6f9f6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### RUN \n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW2_Drop/MultimodalTransformer_time_1706856620.371885_Loss_0.202.ckpt\"\n",
    "\n",
    "config.pkl_save_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/PC_350_500_neg\"\n",
    "#config.model_save_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/small_8_3\" # Folder where networks are saved\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/CSV_examples/PC_350-500_negativevector_v2_100_neg.csv\"\n",
    "#config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/ACD_1H_with_SN_filtered_v3.csv\"\n",
    "\n",
    "config.MF_generations = 30 #50\n",
    "config.MF_delta_weight = 100\n",
    "config.max_scaffold_generations = 300\n",
    "config.blank_percentage = 50\n",
    "config.weight_MW = 100\n",
    "config.lr_pretraining = 3e-4\n",
    "config.tr_te_split = 0.9\n",
    "config.batch_size = 64\n",
    "config.num_epochs = 30\n",
    "config.temperature = 1\n",
    "config.multinom_runs = 20 #20\n",
    "config.train_data_blend = 0\n",
    "\n",
    "chunk_size = 1\n",
    "\n",
    "main_IC_neg(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3022e-e60c-4fd1-8232-832ec71ce627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1dc82b-5c03-499a-baee-a879264dc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def analyze_chunks(base_path):\n",
    "    \"\"\"\n",
    "    Analyze all chunk folders to find those that don't meet requirements.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): Path to the directory containing chunk folders\n",
    "    \"\"\"\n",
    "    incomplete_chunks = []\n",
    "    try:\n",
    "        # Get all directories in base_path\n",
    "        all_dirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "        chunk_dirs = [d for d in all_dirs if d.startswith('chunk_')]\n",
    "        \n",
    "        for chunk_dir in chunk_dirs:\n",
    "            chunk_path = os.path.join(base_path, chunk_dir)\n",
    "            \n",
    "            # Check run folders\n",
    "            run_folders = [d for d in os.listdir(chunk_path) if os.path.isdir(os.path.join(chunk_path, d))]\n",
    "            \n",
    "            has_sufficient_files = False\n",
    "            for run_folder in run_folders:\n",
    "                run_path = os.path.join(chunk_path, run_folder)\n",
    "                files = [f for f in os.listdir(run_path) if os.path.isfile(os.path.join(run_path, f))]\n",
    "                if len(files) > 5:\n",
    "                    has_sufficient_files = True\n",
    "                    break\n",
    "            \n",
    "            if not has_sufficient_files:\n",
    "                incomplete_chunks.append(chunk_dir)\n",
    "        \n",
    "        print(f\"\\nTotal chunks analyzed: {len(chunk_dirs)}\")\n",
    "        print(f\"Number of incomplete chunks: {len(incomplete_chunks)}\")\n",
    "        print(\"\\nIncomplete chunks:\")\n",
    "        for chunk in incomplete_chunks:\n",
    "            print(f\"- {chunk}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "\n",
    "# Run the analysis\n",
    "base_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/ZINC_250_350_neg\"\n",
    "analyze_chunks(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a516abf-8742-4fb7-92d3-e5d2e5029870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7e08126-8e6d-45be-bfdd-b43cf81ecc23",
   "metadata": {},
   "source": [
    "delete before files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b6ce7-668e-4f18-b3f2-78d8c3b540cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_before_files(base_path):\n",
    "    \"\"\"\n",
    "    Delete all files containing 'before' in their name from the directory and its subdirectories.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): Path to the directory to clean\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    try:\n",
    "        # Walk through all directories and subdirectories\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            # Find files containing 'before'\n",
    "            before_files = [f for f in files if 'before' in f.lower()]\n",
    "            \n",
    "            # Delete each file\n",
    "            for file in before_files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Deleted: {file_path}\")\n",
    "                    count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting {file_path}: {str(e)}\")\n",
    "        \n",
    "        print(f\"\\nTotal files deleted: {count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error walking through directory: {str(e)}\")\n",
    "\n",
    "# Run the deletion\n",
    "base_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/ZINC_250_350_neg\"\n",
    "delete_before_files(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c9cc0-6a15-4fbe-8251-876a7f3e2c0a",
   "metadata": {},
   "source": [
    "##### Calculate pos/neg after FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e77c0a-d76c-463d-8902-916026e9332f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_configs = [\n",
    "        {\n",
    "            'weight_range': 'PC_0-250_neg_100_IC',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/PC_0_250_neg_2',\n",
    "            #'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'PC_250-350_neg_100_IC',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/PC_250_350_neg',\n",
    "            #'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'PC_350-500_neg_100_IC',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/PC_350_500_neg',\n",
    "            #'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_Vectors_v2.pkl'\n",
    "        },\n",
    "        {\n",
    "            'weight_range': 'ZINC_250-350_neg_100_IC',\n",
    "            'pkl_folder': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/ZINC_250_350_neg',\n",
    "            #'file_path': '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/PubChem_vectors/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_Vectors_v2.pkl'\n",
    "        },    \n",
    "    ]\n",
    "\n",
    "    \n",
    "output_folder = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/CSV_examples_2'\n",
    "ranking_method = 'HSQC & COSY'\n",
    "\n",
    "main_csv_generation(data_configs, output_folder, ranking_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d7b13a-23e6-4d87-8ce8-10e954331116",
   "metadata": {},
   "source": [
    "##### Plot correct, incorrect, failed after IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdd262-36e5-48a7-9b41-c8804742676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File paths\n",
    "base_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/CSV_examples_2\"\n",
    "\n",
    "def load_and_process_data(weight_range):\n",
    "    pos_file = f\"{base_path}/PC_{weight_range}_neg_100_IC_positive.csv\"\n",
    "    neg_file = f\"{base_path}/PC_{weight_range}_neg_100_IC_negative.csv\"\n",
    "    \n",
    "    if weight_range == \"ZINC_250-350\":\n",
    "        pos_file = f\"{base_path}/ZINC_250-350_neg_100_IC_positive.csv\"\n",
    "        neg_file = f\"{base_path}/ZINC_250-350_neg_100_IC_negative.csv\"\n",
    "    \n",
    "    pos_df = pd.read_csv(pos_file)\n",
    "    neg_df = pd.read_csv(neg_file)\n",
    "    \n",
    "    total = 100  # Total molecules per set\n",
    "    correct = len(pos_df)\n",
    "    incorrect = len(neg_df)\n",
    "    failed = total - (correct + incorrect)\n",
    "    \n",
    "    return {\n",
    "        'Correct': (correct/total) * 100,\n",
    "        'Incorrect': (incorrect/total) * 100,\n",
    "        'Failed': (failed/total) * 100\n",
    "    }\n",
    "\n",
    "# Process data for each set\n",
    "data_0_250 = load_and_process_data(\"0-250\")\n",
    "data_250_350 = load_and_process_data(\"250-350\")\n",
    "data_350_500 = load_and_process_data(\"350-500\")\n",
    "data_zinc = load_and_process_data(\"ZINC_250-350\")\n",
    "\n",
    "# Prepare plotting data\n",
    "plot_data = {\n",
    "    'Correct': [data_0_250['Correct'], data_250_350['Correct'], data_350_500['Correct'], data_zinc['Correct']],\n",
    "    'Incorrect': [data_0_250['Incorrect'], data_250_350['Incorrect'], data_350_500['Incorrect'], data_zinc['Incorrect']],\n",
    "    'Failed': [data_0_250['Failed'], data_250_350['Failed'], data_350_500['Failed'], data_zinc['Failed']]\n",
    "}\n",
    "\n",
    "def create_stacked_bar_chart(data, categories, title, save_path):\n",
    "    fontsize = 22\n",
    "    colors = [\n",
    "        '#8BE5A0',  # mint green for Failed\n",
    "        '#A1C8F3',  # light blue for Correct\n",
    "        '#FFB381',  # salmon for Incorrect\n",
    "    ]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 7))\n",
    "    bottom = np.zeros(4)\n",
    "    \n",
    "    bars = []\n",
    "    for i, category in enumerate(categories):\n",
    "        values = data[category]\n",
    "        bar = ax.bar(range(4), values, bottom=bottom, label=category, color=colors[i], edgecolor='black')\n",
    "        for patch in bar:\n",
    "            patch.set_edgecolor('black')\n",
    "        bottom += values\n",
    "        bars.append(bar)\n",
    "    \n",
    "    ax.set_title(title, fontsize=fontsize, pad=20)\n",
    "    ax.set_xticks(range(4))\n",
    "    ax.set_xticklabels(['Set 1', 'Set 2', 'Set 3', 'ZINC'], fontsize=fontsize)\n",
    "    ax.set_ylabel('Percentage', fontsize=fontsize)\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    ax.tick_params(axis='y', labelsize=fontsize)\n",
    "    \n",
    "    ax.legend(loc='lower right', fontsize=fontsize)\n",
    "    \n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i, fmt='%.1f%%', label_type='center', fontsize=fontsize)\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# Create and save the plot\n",
    "save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/IC_Results.png\"\n",
    "categories = ['Correct', 'Incorrect', 'Failed']\n",
    "fig = create_stacked_bar_chart(plot_data, categories, 'Internal Coordinate Results', save_path)\n",
    "\n",
    "# Print the percentages for verification\n",
    "for i, dataset in enumerate(['Set 1 (0-250)', 'Set 2 (250-350)', 'Set 3 (350-500)', 'ZINC']):\n",
    "    print(f\"\\n{dataset}:\")\n",
    "    for category in categories:\n",
    "        print(f\"{category}: {plot_data[category][i]:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76f823-c5ad-42e0-acbc-725d2169231a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "056190af-e301-48b3-b249-037b8cda9c6e",
   "metadata": {},
   "source": [
    "##### Plot Top 1, 3, 5, 10 Accuracy of IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4d8a0-ef7a-4a16-b387-39ae7e78681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PC 0-250\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ranking_method = 'HSQC & COSY'\n",
    "pkl_folder= \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/PC_0_250_neg_2\"\n",
    "all_rankings = exp_func.process_pkl_files_baseline(pkl_folder, ranking_method)\n",
    "\n",
    "all_rankings, removed_smiles = exp_func.deduplicate_smiles_from_ranking(all_rankings)\n",
    "all_rankings, filtered_out_rankings = exp_func.filter_rankings_by_molecular_formula(all_rankings)\n",
    "accuracies = exp_func.calculate_top_k_accuracy(all_rankings)\n",
    "\n",
    "\n",
    "# Increase default font sizes\n",
    "plt.rcParams.update({'font.size': 22})  # Base font size\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.labelsize'] = 22\n",
    "plt.rcParams['xtick.labelsize'] = 22\n",
    "plt.rcParams['ytick.labelsize'] = 22\n",
    "\n",
    "# Data\n",
    "labels = ['Top 1', 'Top 3', 'Top 5', 'Top 10', 'Top 20']\n",
    "\n",
    "# Calculate molecules for each accuracy (based on 100 total molecules)\n",
    "total_molecules = 100\n",
    "molecules = [int(acc * total_molecules) for acc in accuracies]\n",
    "all_labels = labels\n",
    "\n",
    "# Different colors for each bar\n",
    "colors = ['#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "         ]\n",
    "\n",
    "# Create the bar plot\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "bars = ax.bar(range(len(molecules)), molecules, color=colors)\n",
    "\n",
    "# Set black edges for all bars\n",
    "for bar in bars:\n",
    "    bar.set_edgecolor('black')\n",
    "    \n",
    "# Customize the plot\n",
    "ax.set_xticks(range(len(all_labels)))\n",
    "ax.set_xticklabels(all_labels, fontsize=22)\n",
    "ax.set_ylabel('Number of Molecules', fontsize=22)\n",
    "ax.set_title('Prediction Accuracy of Set 1 (Molecules: 100)', fontsize=22, pad=20)\n",
    "\n",
    "# Add value labels on top and inside of each bar\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    # Percentage on top\n",
    "    percentage = accuracies[i] * 100\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{percentage:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=22)\n",
    "    # Number inside bar\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='center', fontsize=22, color='black')\n",
    "\n",
    "# Add grid for better readability\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set y-axis limit to accommodate labels\n",
    "ax.set_ylim(0, 105)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/PC_0_250_neg_IC_accuracy_plot.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Plot saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda6ec9-a45b-46bd-8960-0f198e3ed418",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PC 0-250\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ranking_method = 'HSQC & COSY'\n",
    "pkl_folder= \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/PC_250_350_neg\"\n",
    "all_rankings = exp_func.process_pkl_files_baseline(pkl_folder, ranking_method)\n",
    "\n",
    "all_rankings, removed_smiles = exp_func.deduplicate_smiles_from_ranking(all_rankings)\n",
    "all_rankings, filtered_out_rankings = exp_func.filter_rankings_by_molecular_formula(all_rankings)\n",
    "accuracies = exp_func.calculate_top_k_accuracy(all_rankings)\n",
    "\n",
    "\n",
    "# Increase default font sizes\n",
    "plt.rcParams.update({'font.size': 22})  # Base font size\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.labelsize'] = 22\n",
    "plt.rcParams['xtick.labelsize'] = 22\n",
    "plt.rcParams['ytick.labelsize'] = 22\n",
    "\n",
    "# Data\n",
    "labels = ['Top 1', 'Top 3', 'Top 5', 'Top 10', 'Top 20']\n",
    "\n",
    "# Calculate molecules for each accuracy (based on 100 total molecules)\n",
    "total_molecules = 100\n",
    "molecules = [int(acc * total_molecules) for acc in accuracies]\n",
    "all_labels = labels\n",
    "\n",
    "# Different colors for each bar\n",
    "colors = ['#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "         ]\n",
    "\n",
    "# Create the bar plot\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "bars = ax.bar(range(len(molecules)), molecules, color=colors)\n",
    "\n",
    "# Set black edges for all bars\n",
    "for bar in bars:\n",
    "    bar.set_edgecolor('black')\n",
    "    \n",
    "# Customize the plot\n",
    "ax.set_xticks(range(len(all_labels)))\n",
    "ax.set_xticklabels(all_labels, fontsize=22)\n",
    "ax.set_ylabel('Number of Molecules', fontsize=22)\n",
    "ax.set_title('Prediction Accuracy of Set 2 (Molecules: 100)', fontsize=22, pad=20)\n",
    "\n",
    "# Add value labels on top and inside of each bar\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    # Percentage on top\n",
    "    percentage = accuracies[i] * 100\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{percentage:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=22)\n",
    "    # Number inside bar\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='center', fontsize=22, color='black')\n",
    "\n",
    "# Add grid for better readability\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set y-axis limit to accommodate labels\n",
    "ax.set_ylim(0, 105)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/PC_250_350_neg_IC_accuracy_plot.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Plot saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77498f-4ed7-46c2-bffc-61196d0b43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PC 0-250\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ranking_method = 'HSQC & COSY'\n",
    "pkl_folder= \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/PC_350_500_neg\"\n",
    "all_rankings = exp_func.process_pkl_files_baseline(pkl_folder, ranking_method)\n",
    "\n",
    "all_rankings, removed_smiles = exp_func.deduplicate_smiles_from_ranking(all_rankings)\n",
    "all_rankings, filtered_out_rankings = exp_func.filter_rankings_by_molecular_formula(all_rankings)\n",
    "accuracies = exp_func.calculate_top_k_accuracy(all_rankings)\n",
    "\n",
    "\n",
    "# Increase default font sizes\n",
    "plt.rcParams.update({'font.size': 22})  # Base font size\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.labelsize'] = 22\n",
    "plt.rcParams['xtick.labelsize'] = 22\n",
    "plt.rcParams['ytick.labelsize'] = 22\n",
    "\n",
    "# Data\n",
    "labels = ['Top 1', 'Top 3', 'Top 5', 'Top 10', 'Top 20']\n",
    "\n",
    "# Calculate molecules for each accuracy (based on 100 total molecules)\n",
    "total_molecules = 100\n",
    "molecules = [int(acc * total_molecules) for acc in accuracies]\n",
    "all_labels = labels\n",
    "\n",
    "# Different colors for each bar\n",
    "colors = ['#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "         ]\n",
    "\n",
    "# Create the bar plot\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "bars = ax.bar(range(len(molecules)), molecules, color=colors)\n",
    "\n",
    "# Set black edges for all bars\n",
    "for bar in bars:\n",
    "    bar.set_edgecolor('black')\n",
    "    \n",
    "# Customize the plot\n",
    "ax.set_xticks(range(len(all_labels)))\n",
    "ax.set_xticklabels(all_labels, fontsize=22)\n",
    "ax.set_ylabel('Number of Molecules', fontsize=22)\n",
    "ax.set_title('Prediction Accuracy of Set 3 (Molecules: 100)', fontsize=22, pad=20)\n",
    "\n",
    "# Add value labels on top and inside of each bar\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    # Percentage on top\n",
    "    percentage = accuracies[i] * 100\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{percentage:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=22)\n",
    "    # Number inside bar\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='center', fontsize=22, color='black')\n",
    "\n",
    "# Add grid for better readability\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set y-axis limit to accommodate labels\n",
    "ax.set_ylim(0, 105)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/PC_350_500_neg_IC_accuracy_plot.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Plot saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98427427-4bd4-4cce-8dac-8387074eee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PC 0-250\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ranking_method = 'HSQC & COSY'\n",
    "pkl_folder= \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/IC_of_neg_examples/ZINC_250_350_neg\"\n",
    "all_rankings = exp_func.process_pkl_files_baseline(pkl_folder, ranking_method)\n",
    "\n",
    "all_rankings, removed_smiles = exp_func.deduplicate_smiles_from_ranking(all_rankings)\n",
    "all_rankings, filtered_out_rankings = exp_func.filter_rankings_by_molecular_formula(all_rankings)\n",
    "accuracies = exp_func.calculate_top_k_accuracy(all_rankings)\n",
    "\n",
    "\n",
    "# Increase default font sizes\n",
    "plt.rcParams.update({'font.size': 22})  # Base font size\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.labelsize'] = 22\n",
    "plt.rcParams['xtick.labelsize'] = 22\n",
    "plt.rcParams['ytick.labelsize'] = 22\n",
    "\n",
    "# Data\n",
    "labels = ['Top 1', 'Top 3', 'Top 5', 'Top 10', 'Top 20']\n",
    "\n",
    "# Calculate molecules for each accuracy (based on 100 total molecules)\n",
    "total_molecules = 100\n",
    "molecules = [int(acc * total_molecules) for acc in accuracies]\n",
    "all_labels = labels\n",
    "\n",
    "# Different colors for each bar\n",
    "colors = ['#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "         ]\n",
    "\n",
    "# Create the bar plot\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "bars = ax.bar(range(len(molecules)), molecules, color=colors)\n",
    "\n",
    "# Set black edges for all bars\n",
    "for bar in bars:\n",
    "    bar.set_edgecolor('black')\n",
    "    \n",
    "# Customize the plot\n",
    "ax.set_xticks(range(len(all_labels)))\n",
    "ax.set_xticklabels(all_labels, fontsize=22)\n",
    "ax.set_ylabel('Number of Molecules', fontsize=22)\n",
    "ax.set_title('Prediction Accuracy of ZINC (Molecules: 100)', fontsize=22, pad=20)\n",
    "\n",
    "# Add value labels on top and inside of each bar\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    # Percentage on top\n",
    "    percentage = accuracies[i] * 100\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{percentage:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=22)\n",
    "    # Number inside bar\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='center', fontsize=22, color='black')\n",
    "\n",
    "# Add grid for better readability\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set y-axis limit to accommodate labels\n",
    "ax.set_ylim(0, 105)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/ZINC_250_350_neg_IC_accuracy_plot.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Plot saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2cd692-54dd-4747-bc18-132dd7a4b6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4163de17-0ac4-4e37-aa1b-d5ee55dc034f",
   "metadata": {},
   "source": [
    "#### 5.7 Bar chart of ESI 7 HSQC Matching results ZINC 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe4f53-cf81-471c-a4a7-482b8431028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# V8 Raw \n",
    "#config.IR_data_folder = \"/projects/cc/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/IR_data\"\n",
    "config.csv_train_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_train_V8.csv' \n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_13C_test_10x100.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_HSQC_test_10x100.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_COSY_test_10x100.csv'  \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100_909434.pkl\"\n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"\n",
    "\n",
    "\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW2_Drop/MultimodalTransformer_time_1706856620.371885_Loss_0.202.ckpt\"\n",
    "config.multinom_runs = 10\n",
    "#config.multinom_runs = 3\n",
    "config.temperature = 1\n",
    "greedy_full = False\n",
    "MW_filter = True\n",
    "config.data_size = 100 # config.test_size # why would I do that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086fd32-2c46-4584-a840-5f05cf9690e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "config.execution_type = \"test_performance\"\n",
    "if config.execution_type == \"test_performance\":\n",
    "    print(\"\\033[1m\\033[31mThis is: test_performance\\033[0m\")\n",
    "    # config.csv_path_val = config.csv_SMI_targets  #this already got updated in simulate_syn_data\n",
    "    \n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    model_CLIP = mrtf.load_CLIP_model(config)\n",
    "    #model_BLIP = mrtf.load_BLIP_model(config)\n",
    "    #model_MMT = model_CLIP.MT_model\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "\n",
    "    \n",
    "    results_dict_bl_ZINC = mrtf.run_test_mns_performance_CLIP_3(config,  \n",
    "                                                        model_MMT,\n",
    "                                                        model_CLIP,\n",
    "                                                        val_dataloader,\n",
    "                                                        stoi, \n",
    "                                                        itos,\n",
    "                                                        MW_filter)\n",
    "    results_dict_bl_ZINC, counter = mrtf.filter_invalid_inputs(results_dict_bl_ZINC)\n",
    "    \n",
    "    avg_tani_bl_ZINC, html_plot = rbgvm.plot_hist_of_results(results_dict_bl_ZINC)\n",
    "    \n",
    "    # Slow because also just takes one at the time\n",
    "    if greedy_full == True:\n",
    "        results_dict_greedy_bl_ZINC, failed_bl_ZINC = mrtf.run_test_performance_CLIP_greedy_3(config,  \n",
    "                                                                stoi, \n",
    "                                                                stoi_MF, \n",
    "                                                                itos, \n",
    "                                                                itos_MF)\n",
    "\n",
    "        avg_tani_greedy_bl_ZINC, html_plot_greedy = rbgvm.plot_hist_of_results_greedy(results_dict_greedy_bl_ZINC)\n",
    "\n",
    "    else: \n",
    "        config, results_dict_ZINC_greedy_bl = mrtf.run_greedy_sampling(config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "        avg_tani_greedy_bl_ZINC = results_dict_ZINC_greedy_bl[\"tanimoto_mean\"]\n",
    "    \n",
    "    total_results_bl_ZINC = mrtf.run_test_performance_CLIP_3(config, \n",
    "                                                        model_MMT, \n",
    "                                                        val_dataloader,\n",
    "                                                        stoi)\n",
    "    \n",
    "    corr_sampleing_prob_bl_ZINC = total_results_bl_ZINC[\"statistics_multiplication_avg\"][0]\n",
    "    print(\"avg_tani, avg_tani_greedy, corr_sampleing_prob'\")\n",
    "    print(avg_tani_bl_ZINC, avg_tani_greedy_bl_ZINC, corr_sampleing_prob_bl_ZINC)       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa3b76-87ed-4bc1-a557-fb911f1a49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save variables to a pickle file\n",
    "variables_to_save = {\n",
    "    'avg_tani_bl_ZINC': avg_tani_bl_ZINC,\n",
    "    'results_dict_greedy_bl_ZINC': results_dict_greedy_bl_ZINC if greedy_full else None,\n",
    "    'failed_bl_ZINC': failed_bl_ZINC if greedy_full else None,\n",
    "    'avg_tani_greedy_bl_ZINC': avg_tani_greedy_bl_ZINC,\n",
    "    'results_dict_ZINC_greedy_bl': results_dict_ZINC_greedy_bl if not greedy_full else None,\n",
    "    'total_results_bl_ZINC': total_results_bl_ZINC,\n",
    "    'corr_sampleing_prob_bl_ZINC': corr_sampleing_prob_bl_ZINC,\n",
    "    'results_dict_bl_ZINC': results_dict_bl_ZINC,\n",
    "}\n",
    "\n",
    "with open('/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240522_ZINC_MNS_HSQC_matching/7.0_imp_cyc_all_100_10_after.pkl', 'wb') as f:\n",
    "    pickle.dump(variables_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0910b-6fb9-4da4-a334-88897a1481df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ffc76-aaf8-468e-975e-4778106f840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240522_ZINC_MNS_HSQC_matching/7.0_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    variables_to_save = pickle.load(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a30da5-3b58-4ba4-a6e7-c1cd18a9bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_bl_ZINC = variables_to_save[\"results_dict_bl_ZINC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c15e0-2fb6-40d5-bd5c-922d810aef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the lowest error correctly identifies the correct molecule\n",
    "def check_lowest_error_correct(results):\n",
    "    correct_identifications = 0\n",
    "    total_cases_with_correct_answer = 0\n",
    "    total_cases_without_correct_answer = 0\n",
    "    closest_identifications = 0\n",
    "    incorrect_identification_keys = []\n",
    "\n",
    "    for key, value in results.items():\n",
    "        if not isinstance(value, list) or not isinstance(value[0], list):\n",
    "            continue  # Skip non-list items\n",
    "\n",
    "        for sublist in value:\n",
    "            if not isinstance(sublist, list):\n",
    "                continue  # Skip non-list sublists\n",
    "\n",
    "            correct_error = None\n",
    "            lowest_error = float('inf')\n",
    "            highest_similarity = 0\n",
    "            closest_error = float('inf')\n",
    "\n",
    "            for item in sublist:\n",
    "                if not isinstance(item, list) or len(item) < 5:\n",
    "                    continue  # Skip invalid items\n",
    "\n",
    "                similarity = item[3]\n",
    "                error = item[4]\n",
    "\n",
    "                if isinstance(similarity, (int, float)) and similarity == 1:\n",
    "                    correct_error = float(error)\n",
    "                if isinstance(error, (int, float)) and float(error) < lowest_error:\n",
    "                    lowest_error = float(error)\n",
    "                if isinstance(similarity, (int, float)) and similarity > highest_similarity:\n",
    "                    highest_similarity = similarity\n",
    "                    closest_error = float(error)\n",
    "\n",
    "            if correct_error is not None:\n",
    "                total_cases_with_correct_answer += 1\n",
    "                if correct_error == lowest_error:\n",
    "                    correct_identifications += 1\n",
    "                else:\n",
    "                    incorrect_identification_keys.append(key)\n",
    "            else:\n",
    "                total_cases_without_correct_answer += 1\n",
    "                if closest_error == lowest_error:\n",
    "                    closest_identifications += 1\n",
    "\n",
    "    return (correct_identifications, total_cases_with_correct_answer, \n",
    "            closest_identifications, total_cases_without_correct_answer,\n",
    "            incorrect_identification_keys)\n",
    "\n",
    "# Run the function\n",
    "correct_identifications, total_cases_with_correct_answer, closest_identifications, total_cases_without_correct_answer, incorrect_identification_keys = check_lowest_error_correct(results_dict_bl_ZINC)\n",
    "\n",
    "# Calculate accuracies\n",
    "accuracy_with_correct = correct_identifications / total_cases_with_correct_answer if total_cases_with_correct_answer > 0 else 0\n",
    "accuracy_without_correct = closest_identifications / total_cases_without_correct_answer if total_cases_without_correct_answer > 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Correct identifications: {correct_identifications}\")\n",
    "print(f\"Total cases with correct answer: {total_cases_with_correct_answer}\")\n",
    "print(f\"Accuracy with correct answer: {accuracy_with_correct:.2%}\")\n",
    "\n",
    "print(f\"Closest identifications: {closest_identifications}\")\n",
    "print(f\"Total cases without correct answer: {total_cases_without_correct_answer}\")\n",
    "print(f\"Accuracy without correct answer: {accuracy_without_correct:.2%}\")\n",
    "\n",
    "# Print keys of incorrect identifications\n",
    "print(f\"Keys of incorrect identifications: {incorrect_identification_keys}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a1e5d-4b7a-4561-9eb6-210a46e74705",
   "metadata": {},
   "outputs": [],
   "source": [
    "### old with 3 bars\n",
    "\"\"\"import matplotlib.pyplot as plt\n",
    "\n",
    "tani_list = variables_to_save[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "greedy_correct = tani_list.count(1)\n",
    "total_cases_greedy = len(tani_list)\n",
    "accuracy_greedy = greedy_correct / total_cases_greedy\n",
    "\n",
    "# Bar chart for identification accuracies\n",
    "accuracies = {\n",
    "    'MNS With \\nCorrect Answer': accuracy_with_correct,\n",
    "    'MNS Without \\nCorrect Answer': accuracy_without_correct,\n",
    "    'Greedy \\nSampling': accuracy_greedy\n",
    "}\n",
    "\n",
    "# Ratios for annotation\n",
    "ratios = {\n",
    "    'With Correct Answer': f'{correct_identifications}/{total_cases_with_correct_answer}',\n",
    "    'Without Correct Answer': f'{closest_identifications}/{total_cases_without_correct_answer}',\n",
    "    'Greedy Sampling': f'{greedy_correct}/{total_cases_greedy}'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(accuracies.keys(), accuracies.values(), color=['#87CEEB', '#FFA07A', '#90EE90'])  # LightBlue, LightSalmon, LightGreen\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Identification Accuracies')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Annotate bars with accuracy percentages on top of the bar\n",
    "for bar, (label, ratio) in zip(bars, ratios.items()):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height,\n",
    "            f'{height:.2%}',\n",
    "            ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "# Annotate bars with ratios inside the bar\n",
    "for bar, (label, ratio) in zip(bars, ratios.items()):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height / 2,\n",
    "            f'{ratio}',\n",
    "            ha='center', va='center', fontsize=14, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define the file path for saving the plot\n",
    "output_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/7.0_identification_accuracies_new.png'\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d5516-5972-4a3e-8f17-b4160bbd840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tani_list = variables_to_save[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "greedy_correct = tani_list.count(1)\n",
    "total_cases_greedy = len(tani_list)\n",
    "accuracy_greedy = greedy_correct / total_cases_greedy\n",
    "\n",
    "# Bar chart for identification accuracies\n",
    "accuracies = {\n",
    "    'MNS \\nSampling': accuracy_with_correct,\n",
    "    'Greedy \\nSampling': accuracy_greedy\n",
    "}\n",
    "\n",
    "# Ratios for annotation\n",
    "ratios = {\n",
    "    'MNS': f'{correct_identifications}/{total_cases_with_correct_answer}',\n",
    "    'Greedy Sampling': f'{greedy_correct}/{total_cases_greedy}'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(accuracies.keys(), accuracies.values(), color=['#A1C8F3',  '#FFB381'])  # LightBlue, LightGreen\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Identification Accuracies')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Annotate bars with accuracy percentages on top of the bar\n",
    "for bar, (label, ratio) in zip(bars, ratios.items()):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height,\n",
    "            f'{height:.2%}',\n",
    "            ha='center', va='bottom', fontsize=22)\n",
    "\n",
    "# Annotate bars with ratios inside the bar\n",
    "for bar, (label, ratio) in zip(bars, ratios.items()):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height / 2,\n",
    "            f'{ratio}',\n",
    "            ha='center', va='center', fontsize=22, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define the file path for saving the plot\n",
    "output_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/7.0_identification_accuracies_new.png'\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dccdbfa-8096-4626-89f5-e4e90537a04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85347cc6-ea47-4027-9f6d-0f9f01f3285f",
   "metadata": {},
   "source": [
    "#### 5.8 ZINC 4000 MNS Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9224c38-dc35-48db-a0c5-d436ed2e740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_method = 'HSQC & COSY'\n",
    "pkl_folder= \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350_4000\"\n",
    "all_rankings = exp_func.process_pkl_files_baseline(pkl_folder, ranking_method)\n",
    "\n",
    "all_rankings, removed_smiles = exp_func.deduplicate_smiles_from_ranking(all_rankings)\n",
    "all_rankings, filtered_out_rankings = exp_func.filter_rankings_by_molecular_formula(all_rankings)\n",
    "accuracies = exp_func.calculate_top_k_accuracy(all_rankings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55723970-e166-4f7c-9a79-ffb4baa78d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2bef8-8b84-4b30-93c4-db633d5a80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase default font sizes\n",
    "plt.rcParams.update({'font.size': 22})  # Base font size\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.labelsize'] = 22\n",
    "plt.rcParams['xtick.labelsize'] = 22\n",
    "plt.rcParams['ytick.labelsize'] = 22\n",
    "\n",
    "# Data\n",
    "labels = ['Top 1', 'Top 3', 'Top 5', 'Top 10']\n",
    "\n",
    "# Calculate molecules for each accuracy\n",
    "total_molecules = 4000\n",
    "processed_molecules = 3991\n",
    "failed_molecules = total_molecules - processed_molecules\n",
    "molecules = [int(acc * processed_molecules) for acc in accuracies]\n",
    "all_molecules = molecules + [failed_molecules]\n",
    "all_labels = labels + ['Failed']\n",
    "\n",
    "# Different colors for each bar\n",
    "colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FF99CC']\n",
    "\n",
    "# Create the bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = ax.bar(range(len(all_molecules)), all_molecules, color=colors)\n",
    "\n",
    "# Set black edges for all bars\n",
    "for bar in bars:\n",
    "    bar.set_edgecolor('black')\n",
    "    \n",
    "# Customize the plot\n",
    "ax.set_xticks(range(len(all_labels)))\n",
    "ax.set_xticklabels(all_labels, fontsize=22)\n",
    "ax.set_ylabel('Number of Molecules', fontsize=22)\n",
    "ax.set_title('Prediction Accuracy by Top-K (Total Molecules: 4000)', fontsize=22, pad=20)\n",
    "\n",
    "# Add value labels on top and inside of each bar\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    if i < len(accuracies):  # For accuracy bars\n",
    "        percentage = accuracies[i] * 100\n",
    "        # Percentage on top\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 50,\n",
    "                f'{percentage:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=22)\n",
    "        # Number inside bar\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='center', fontsize=22, color='black')\n",
    "    else:  # For failed molecules bar\n",
    "        percentage = (height/total_molecules) * 100\n",
    "        # Percentage on top - moved higher for failed bar\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 200,\n",
    "                f'{percentage:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=22)\n",
    "        # Number inside bar - moved higher for failed bar\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 100,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='center', fontsize=22, color='black')\n",
    "        \n",
    "# Add grid for better readability\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set y-axis limit to accommodate labels\n",
    "ax.set_ylim(0, max(all_molecules) + 400)\n",
    "#ax.set_ylim(0, 4100)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.show()\n",
    "# Save the plot\n",
    "save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/ZINC4000_accuracy_plot.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Plot saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab919cf2-50b3-46a9-8e56-3fbee7d57db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26002b0e-36e2-485d-8eef-b6feda8809e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce6f86-80fc-4e5f-babc-263801d1c638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf1efa-bfad-4522-95d1-e11dcb551322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0f744fd-86a0-4496-883b-5c9a1cc9f3cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 6.0 Test Improvement cycle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f9ac2-1302-4f5a-876f-a5e889712ee2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 6.1 Fine Tune an all the molecules that I want to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd08d02-70e8-4843-9b92-47d1e2725c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.project = \"Improv_Cycle_v3\" # Name of the project for wandb monitoring\n",
    "config.csv_train_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_train_V8.csv' \n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_13C_test_10x100.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_HSQC_test_10x100.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_COSY_test_10x100.csv'  \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100_909434.pkl\"\n",
    "\n",
    "#config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "#config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_13C_V1_test_350_500_x1000.csv'    \n",
    "#config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_HSQC_V1_test_350_500_x1000.csv'    \n",
    "#config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_COSY_V1_test_350_500_x1000.csv'   \n",
    "#config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "#config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_185242.pkl\"\n",
    "\n",
    "# V8 Raw \n",
    "#config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/IR_data\"\n",
    "\n",
    "#config.IR_data_folder = \"\"\n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT/MultimodalTransformer_time_1702145565.246352_Loss_0.048.ckpt\"\n",
    "\n",
    "# V8 / 8Vi Raw MW Drop\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW2_Drop/MultimodalTransformer_time_1706856620.371885_Loss_0.202.ckpt\"\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "\n",
    "config.data_size = 100 # config.test_size # why would I do that? \n",
    "#config.data_size = 4 # config.test_size # why would I do that? \n",
    "config.execution_type = \"test_performance\"\n",
    "config.multinom_runs = 1\n",
    "#config.multinom_runs = 3\n",
    "config.temperature = 1\n",
    "greedy_full = False\n",
    "MW_filter = True\n",
    "config.MF_generations = 50\n",
    "config.MF_delta_weight = 20\n",
    "config.max_scaffold_generations = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9098965-3773-4724-9ef5-4360d125a2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "if config.execution_type == \"test_performance\":\n",
    "    print(\"\\033[1m\\033[31mThis is: test_performance\\033[0m\")\n",
    "    # config.csv_path_val = config.csv_SMI_targets  #this already got updated in simulate_syn_data\n",
    "    \n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    model_CLIP = mrtf.load_CLIP_model(config)\n",
    "    #model_BLIP = mrtf.load_BLIP_model(config)\n",
    "    #model_MMT = model_CLIP.MT_model\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "\n",
    "    \n",
    "    results_dict_bl_ZINC = mrtf.run_test_mns_performance_CLIP_3(config,  \n",
    "                                                        model_MMT,\n",
    "                                                        model_CLIP,\n",
    "                                                        val_dataloader,\n",
    "                                                        stoi, \n",
    "                                                        itos,\n",
    "                                                        MW_filter)\n",
    "    results_dict_bl_ZINC, counter = mrtf.filter_invalid_inputs(results_dict_bl_ZINC)\n",
    "    \n",
    "    avg_tani_bl_ZINC, html_plot = rbgvm.plot_hist_of_results(results_dict_bl_ZINC)\n",
    "    \n",
    "    # Slow because also just takes one at the time\n",
    "    if greedy_full == True:\n",
    "        results_dict_greedy_bl_ZINC, failed_bl_ZINC = mrtf.run_test_performance_CLIP_greedy_3(config,  \n",
    "                                                                stoi, \n",
    "                                                                stoi_MF, \n",
    "                                                                itos, \n",
    "                                                                itos_MF)\n",
    "\n",
    "        avg_tani_greedy_bl_ZINC, html_plot_greedy = rbgvm.plot_hist_of_results_greedy(results_dict_greedy_bl_ZINC)\n",
    "\n",
    "    else: \n",
    "        config, results_dict_ZINC_greedy_bl = mrtf.run_greedy_sampling(config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "        avg_tani_greedy_bl_ZINC = results_dict_ZINC_greedy_bl[\"tanimoto_mean\"]\n",
    "    \n",
    "    total_results_bl_ZINC = mrtf.run_test_performance_CLIP_3(config, \n",
    "                                                        model_MMT, \n",
    "                                                        val_dataloader,\n",
    "                                                        stoi)\n",
    "    \n",
    "    corr_sampleing_prob_bl_ZINC = total_results_bl_ZINC[\"statistics_multiplication_avg\"][0]\n",
    "    print(\"avg_tani, avg_tani_greedy, corr_sampleing_prob'\")\n",
    "    print(avg_tani_bl_ZINC, avg_tani_greedy_bl_ZINC, corr_sampleing_prob_bl_ZINC)       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd532a1-d1d0-41c5-932a-98e551102b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Select the samples that did not succeed to get right\n",
    "filtered_results = [key for key, value in results_dict_bl_ZINC.items()]\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856deab-dbdc-4d77-b470-59683b681c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"SMILES\": filtered_results,\n",
    "    \"sample-id\": [f\"SOURCE_00000{i+1}\" for i in range(len(filtered_results))]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "csv_file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/deep-molecular-optimization/data/MMP/test_selection_2.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "csv_path_val_backup = config.csv_path_val\n",
    "pickle_file_path_backup = config.pickle_file_path\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5329f7-3cb8-4d70-a540-cb90e859b9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.execution_type = \"SMI_generation_MF\"\n",
    "\n",
    "if config.execution_type == \"SMI_generation_MF\":\n",
    "    config.n_samples = config.data_size\n",
    "    #if config.execution_type == \"SMI_generation_MF\":\n",
    "    print(\"\\033[1m\\033[31mThis is: SMI_generation_MF\\033[0m\")\n",
    "    config.csv_path_val  = ex.filter_invalid_criteria(config.csv_path_val)#, config.csv_path_val)\n",
    "    config, results_dict_MF = ex.SMI_generation_MF(config, stoi, stoi_MF, itos, itos_MF)\n",
    "    #mode = \"val\"\n",
    "\n",
    "    # Iterate through the dictionary and remove 'nan' from lists\n",
    "    results_dict_MF = {key: value for key, value in results_dict_MF.items() if not hf.contains_only_nan(value)}\n",
    "    for key, value in results_dict_MF.items():\n",
    "        results_dict_MF[key] = hf.remove_nan_from_list(value)\n",
    "\n",
    "    combined_list_MF, html_TSNE, html_UMAP, html_PCA = cv.plot_cluster_MF(results_dict_MF, config)\n",
    "    max_num = 10\n",
    "    html_plot = pt.plot_molecules_from_list(combined_list_MF, max_num)\n",
    "    config.execution_type = \"combine_MMT_MF\"\n",
    "    #import IPython; IPython.embed();\n",
    "    print(config.data_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da00d0-007d-4d4a-9b47-e789a80c4bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.execution_type = \"combine_MMT_MF\"\n",
    "combined_list_MMT = []\n",
    "if config.execution_type == \"combine_MMT_MF\":\n",
    "    print(\"\\033[1m\\033[31mThis is: combine_MMT_MF\\033[0m\")\n",
    "    all_gen_smis = combined_list_MMT + combined_list_MF\n",
    "    combined_list_MF = [smiles for smiles in combined_list_MF if smiles != 'NAN']\n",
    "    all_gen_smis = [smiles for smiles in all_gen_smis if smiles != 'NAN']\n",
    "    \n",
    "    #filter out potential hits from the real test_set\n",
    "    val_data = pd.read_csv(config.csv_path_val)\n",
    "    all_gen_smis = mrtf.filter_smiles(val_data, all_gen_smis)\n",
    "    length_of_list = len(all_gen_smis)   \n",
    "    random_number_strings = [f\"GT_{str(i).zfill(7)}\" for i in range(1, length_of_list + 1)]\n",
    "    aug_mol_df = pd.DataFrame({'SMILES': all_gen_smis, 'sample-id': random_number_strings})\n",
    "    config.execution_type = \"blend_prev_train_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c2167-8cf3-4dcd-942b-b878eb25adc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.train_data_blend = 0\n",
    "config.execution_type = \"blend_prev_train_data\"\n",
    "if config.execution_type == \"blend_prev_train_data\":\n",
    "    print(\"\\033[1m\\033[31mThis is: blend_prev_train_data\\033[0m\")\n",
    "    config, final_df = ex.blend_aug_with_train_data(config, aug_mol_df)\n",
    "    config.execution_type = \"data_generation\"\n",
    "    #import IPython; IPython.embed();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d70f1-7043-4c91-8183-7fcf3eb2e6c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.execution_type = \"data_generation\"\n",
    "if config.execution_type == \"data_generation\":\n",
    "    #config.csv_SMI_targets = config.csv_1H_path_SGNN\n",
    "    print(\"\\033[1m\\033[31mThis is: data_generation\\033[0m\")\n",
    "    config = ex.gen_sim_aug_data(config, IR_config)\n",
    "    config.execution_type = \"transformer_improvement\"\n",
    "    sim_data_gen = True\n",
    "    #import IPython; IPython.embed();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c6c09-714f-447a-9709-f657da3e45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save variables to a pickle file\n",
    "variables_to_save = {\n",
    "    'avg_tani_bl_ZINC': avg_tani_bl_ZINC,\n",
    "    'results_dict_greedy_bl_ZINC': results_dict_greedy_bl_ZINC if greedy_full else None,\n",
    "    'failed_bl_ZINC': failed_bl_ZINC if greedy_full else None,\n",
    "    'avg_tani_greedy_bl_ZINC': avg_tani_greedy_bl_ZINC,\n",
    "    'results_dict_ZINC_greedy_bl': results_dict_ZINC_greedy_bl if not greedy_full else None,\n",
    "    'total_results_bl_ZINC': total_results_bl_ZINC,\n",
    "    'corr_sampleing_prob_bl_ZINC': corr_sampleing_prob_bl_ZINC,\n",
    "    'filtered_results': filtered_results,\n",
    "    'all_gen_smis': all_gen_smis,\n",
    "    'aug_mol_df': aug_mol_df,\n",
    "    'results_dict_bl_ZINC': results_dict_bl_ZINC,\n",
    "}\n",
    "\n",
    "with open('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240516_Improvment_Cycle_v2/6.2_imp_cyc_all_100_50.pkl', 'wb') as f:\n",
    "    pickle.dump(variables_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b95b91-43a3-469c-ab13-e9eb1fe14d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!#rm -r '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/24_SGNN_gen_folder_2/dump_2_64364'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e59fb6-3a08-4eae-8f16-106c991cdcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.csv_SMI_targets = config.csv_1H_path_SGNN\n",
    "# data_IR = irs.run_IR_simulation(config, IR_config, \"target\")\n",
    "# config.IR_data_folder = data_IR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea441ddf-4e66-4d0f-860e-164c3f92d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.blank_percentage = 0\n",
    "config.weight_MW = 0\n",
    "config.lr_pretraining = 1e-4\n",
    "config.tr_te_split = 0.9\n",
    "config.model_save_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/imp_cyc_all_100_50_v2\" # Folder where networks are saved\n",
    "data_size = len(pd.read_csv(config.csv_1H_path_SGNN))\n",
    "config.data_size = data_size\n",
    "config.gpu_num = 1\n",
    "config.batch_size = 64\n",
    "config.num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62b73f-d19b-4420-984b-09f0209f42fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.execution_type = \"transformer_improvement\"\n",
    "sim_data_gen = True\n",
    "\n",
    "if config.execution_type == \"transformer_improvement\" and sim_data_gen == True:\n",
    "    print(\"\\033[1m\\033[31mThis is: transformer_improvement, sim_data_gen == TRUE\\033[0m\")\n",
    "    config.training_setup = \"pretraining\"\n",
    "    mtf.run_MMT(config, stoi, stoi_MF)\n",
    "\n",
    "    # config.execution_type = \"clip_improvement\"\n",
    "    config.execution_type = \"update_model\"\n",
    "    # finish_while = True\n",
    "    #import IPython; IPython.embed();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2840db-c9ca-4e95-9e60-fb11b484dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.csv_train_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/ML_NMR_5M_XL_1H_comb_train_V8.csv' \n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_13C_test_10x100.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_HSQC_test_10x100.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_5M_XL_COSY_test_10x100.csv'  \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/val_data_all_modalities/ML_NMR_1H_combined_ZINC_test_10x100_909434.pkl\"\n",
    "\n",
    "#config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "#config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_13C_V1_test_350_500_x1000.csv'    \n",
    "#config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_HSQC_V1_test_350_500_x1000.csv'    \n",
    "#config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_COSY_V1_test_350_500_x1000.csv'   \n",
    "#config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "#config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_185242.pkl\"\n",
    "\n",
    "# V8 Raw \n",
    "#config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/IR_data\"\n",
    "\n",
    "#config.IR_data_folder = \"\"\n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/15_ZINC270M/IR_spectra_NN\"\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT/MultimodalTransformer_time_1702145565.246352_Loss_0.048.ckpt\"\n",
    "\n",
    "# V8 / 8Vi Raw MW Drop\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW2_Drop/MultimodalTransformer_time_1706856620.371885_Loss_0.202.ckpt\"\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "\n",
    "config.data_size = 100 # config.test_size # why would I do that? \n",
    "#config.data_size = 4 # config.test_size # why would I do that? \n",
    "config.execution_type = \"test_performance\"\n",
    "config.multinom_runs = 1\n",
    "#config.multinom_runs = 3\n",
    "config.temperature = 1\n",
    "greedy_full = False\n",
    "MW_filter = True\n",
    "config.MF_generations = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38184b64-77b1-427e-b240-0ca320fe3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ex.update_model_path(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752c1fd-feba-43c7-bf7c-68fa4e712700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "if config.execution_type == \"test_performance\":\n",
    "    print(\"\\033[1m\\033[31mThis is: test_performance\\033[0m\")\n",
    "    # config.csv_path_val = config.csv_SMI_targets  #this already got updated in simulate_syn_data\n",
    "    \n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    model_CLIP = mrtf.load_CLIP_model(config)\n",
    "    #model_BLIP = mrtf.load_BLIP_model(config)\n",
    "    #model_MMT = model_CLIP.MT_model\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "\n",
    "    \n",
    "    results_dict_bl_ZINC = mrtf.run_test_mns_performance_CLIP_3(config,  \n",
    "                                                        model_MMT,\n",
    "                                                        model_CLIP,\n",
    "                                                        val_dataloader,\n",
    "                                                        stoi, \n",
    "                                                        itos,\n",
    "                                                        MW_filter)\n",
    "    results_dict_bl_ZINC, counter = mrtf.filter_invalid_inputs(results_dict_bl_ZINC)\n",
    "    \n",
    "    avg_tani_bl_ZINC, html_plot = rbgvm.plot_hist_of_results(results_dict_bl_ZINC)\n",
    "    \n",
    "    # Slow because also just takes one at the time\n",
    "    if greedy_full == True:\n",
    "        results_dict_greedy_bl_ZINC, failed_bl_ZINC = mrtf.run_test_performance_CLIP_greedy_3(config,  \n",
    "                                                                stoi, \n",
    "                                                                stoi_MF, \n",
    "                                                                itos, \n",
    "                                                                itos_MF)\n",
    "\n",
    "        avg_tani_greedy_bl_ZINC, html_plot_greedy = rbgvm.plot_hist_of_results_greedy(results_dict_greedy_bl_ZINC)\n",
    "\n",
    "    else: \n",
    "        config, results_dict_ZINC_greedy_bl = mrtf.run_greedy_sampling(config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "        avg_tani_greedy_bl_ZINC = results_dict_ZINC_greedy_bl[\"tanimoto_mean\"]\n",
    "    \n",
    "    total_results_bl_ZINC = mrtf.run_test_performance_CLIP_3(config, \n",
    "                                                        model_MMT, \n",
    "                                                        val_dataloader,\n",
    "                                                        stoi)\n",
    "    \n",
    "    corr_sampleing_prob_bl_ZINC = total_results_bl_ZINC[\"statistics_multiplication_avg\"][0]\n",
    "    print(\"avg_tani, avg_tani_greedy, corr_sampleing_prob'\")\n",
    "    print(avg_tani_bl_ZINC, avg_tani_greedy_bl_ZINC, corr_sampleing_prob_bl_ZINC)       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397d27d-b111-4320-9ff0-b3baae8f6c13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Select the samples that did not succeed to get right\n",
    "filtered_results = [key for key, value in results_dict_bl_ZINC.items()]\n",
    "# filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962ccb8-703a-490a-8e0e-b2013c7c463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save variables to a pickle file\n",
    "variables_to_save = {\n",
    "    'avg_tani_bl_ZINC': avg_tani_bl_ZINC,\n",
    "    'results_dict_greedy_bl_ZINC': results_dict_greedy_bl_ZINC if greedy_full else None,\n",
    "    'failed_bl_ZINC': failed_bl_ZINC if greedy_full else None,\n",
    "    'avg_tani_greedy_bl_ZINC': avg_tani_greedy_bl_ZINC,\n",
    "    'results_dict_ZINC_greedy_bl': results_dict_ZINC_greedy_bl if not greedy_full else None,\n",
    "    'total_results_bl_ZINC': total_results_bl_ZINC,\n",
    "    'corr_sampleing_prob_bl_ZINC': corr_sampleing_prob_bl_ZINC,\n",
    "    'filtered_results': filtered_results,\n",
    "    'results_dict_bl_ZINC': results_dict_bl_ZINC,\n",
    "}\n",
    "\n",
    "with open('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240516_Improvment_Cycle_v2/6.2_imp_cyc_all_100_50_after.pkl', 'wb') as f:\n",
    "    pickle.dump(variables_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7b6f1-e2a5-4687-807e-5c62bcc578c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config.data_size = 100 # config.test_size # why would I do that? \n",
    "#config.data_size = 4 # config.test_size # why would I do that? \n",
    "config.execution_type = \"test_performance\"\n",
    "config.multinom_runs = 1\n",
    "config.multinom_runs = 3\n",
    "config.temperature = 1\n",
    "greedy_full = False\n",
    "MW_filter = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e929a-b141-492e-b741-6c41e2318834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "if config.execution_type == \"test_performance\":\n",
    "    print(\"\\033[1m\\033[31mThis is: test_performance\\033[0m\")\n",
    "    # config.csv_path_val = config.csv_SMI_targets  #this already got updated in simulate_syn_data\n",
    "    \n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    model_CLIP = mrtf.load_CLIP_model(config)\n",
    "    #model_BLIP = mrtf.load_BLIP_model(config)\n",
    "    #model_MMT = model_CLIP.MT_model\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "\n",
    "    \n",
    "    results_dict_bl_ZINC = mrtf.run_test_mns_performance_CLIP_3(config,  \n",
    "                                                        model_MMT,\n",
    "                                                        model_CLIP,\n",
    "                                                        val_dataloader,\n",
    "                                                        stoi, \n",
    "                                                        itos,\n",
    "                                                        MW_filter)\n",
    "    \n",
    "    results_dict_bl_ZINC, counter = mrtf.filter_invalid_inputs(results_dict_bl_ZINC)\n",
    "    \n",
    "    avg_tani_bl_ZINC, html_plot = rbgvm.plot_hist_of_results(results_dict_bl_ZINC)\n",
    "    \n",
    "    # Slow because also just takes one at the time\n",
    "    if greedy_full == True:\n",
    "        results_dict_greedy_bl_ZINC, failed_bl_ZINC = mrtf.run_test_performance_CLIP_greedy_3(config,  \n",
    "                                                                stoi, \n",
    "                                                                stoi_MF, \n",
    "                                                                itos, \n",
    "                                                                itos_MF)\n",
    "\n",
    "        avg_tani_greedy_bl_ZINC, html_plot_greedy = rbgvm.plot_hist_of_results_greedy(results_dict_greedy_bl_ZINC)\n",
    "\n",
    "    else: \n",
    "        config, results_dict_ZINC_greedy_bl = mrtf.run_greedy_sampling(config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "        avg_tani_greedy_bl_ZINC = results_dict_ZINC_greedy_bl[\"tanimoto_mean\"]\n",
    "    \n",
    "    total_results_bl_ZINC = mrtf.run_test_performance_CLIP_3(config, \n",
    "                                                        model_MMT, \n",
    "                                                        val_dataloader,\n",
    "                                                        stoi)\n",
    "    \n",
    "    corr_sampleing_prob_bl_ZINC = total_results_bl_ZINC[\"statistics_multiplication_avg\"][0]\n",
    "    print(\"avg_tani, avg_tani_greedy, corr_sampleing_prob'\")\n",
    "    print(avg_tani_bl_ZINC, avg_tani_greedy_bl_ZINC, corr_sampleing_prob_bl_ZINC)       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5cf341-c4b6-47f6-9001-ebe0968c7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the samples that did not succeed to get right\n",
    "filtered_results = [key for key, value in results_dict_bl_ZINC.items() if value[0][0][-2] != 1]\n",
    "#filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e4bde-cd68-4955-96fb-a42b94bc52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save variables to a pickle file\n",
    "variables_to_save = {\n",
    "    'avg_tani_bl_ZINC': avg_tani_bl_ZINC,\n",
    "    'results_dict_greedy_bl_ZINC': results_dict_greedy_bl_ZINC if greedy_full else None,\n",
    "    'failed_bl_ZINC': failed_bl_ZINC if greedy_full else None,\n",
    "    'avg_tani_greedy_bl_ZINC': avg_tani_greedy_bl_ZINC,\n",
    "    'results_dict_ZINC_greedy_bl': results_dict_ZINC_greedy_bl if not greedy_full else None,\n",
    "    'total_results_bl_ZINC': total_results_bl_ZINC,\n",
    "    'corr_sampleing_prob_bl_ZINC': corr_sampleing_prob_bl_ZINC,\n",
    "    'filtered_results': filtered_results,\n",
    "    'results_dict_bl_ZINC': results_dict_bl_ZINC,\n",
    "}\n",
    "\n",
    "with open('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240516_Improvment_Cycle_v2/6.2_imp_cyc_all_100_50_after_MNS_3.pkl', 'wb') as f:\n",
    "    pickle.dump(variables_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d1684-77dd-4486-9211-11fa6e340d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3c771-ee7e-4f85-9aa1-b54e52eca854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "#config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_13C_V1_test_350_500_x1000.csv'    \n",
    "#config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_HSQC_V1_test_350_500_x1000.csv'    \n",
    "#config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_COSY_V1_test_350_500_x1000.csv'   \n",
    "#config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000.csv'\n",
    "#config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_350_500_x1000/ML_NMR_2M_XL_1H_V1_test_f_350_500_x1000_185242.pkl\"\n",
    "\n",
    "#config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000.csv'\n",
    "#config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_13C_V1_test_0_250_x1000.csv'\n",
    "#config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_HSQC_V1_test_0_250_x1000.csv'    \n",
    "#config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_COSY_V1_test_0_250_x1000.csv'   \n",
    "#config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000.csv'\n",
    "#config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_0_250_x1000/ML_NMR_2M_XL_1H_V1_test_f_0_250_x1000_933335.pkl\"\n",
    "\n",
    "\n",
    "config.csv_1H_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000.csv'\n",
    "config.csv_13C_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_13C_V1_test_250_350_x1000.csv'    \n",
    "config.csv_HSQC_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_HSQC_V1_test_250_350_x1000.csv'    \n",
    "config.csv_COSY_path_SGNN = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_COSY_V1_test_250_350_x1000.csv'   \n",
    "config.csv_path_val = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000.csv'\n",
    "config.pickle_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/val_data_250_350_x1000/ML_NMR_2M_XL_1H_V1_test_f_250_350_x1000_285005.pkl\"\n",
    "\n",
    "# V8 Raw \n",
    "config.IR_data_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/26_PubChem_dataset/IR_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154571ff-6ac1-474f-801a-364a111529ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config.data_size = 100 # config.test_size # why would I do that? \n",
    "#config.data_size = 4 # config.test_size # why would I do that? \n",
    "config.execution_type = \"test_performance\"\n",
    "config.multinom_runs = 1\n",
    "config.multinom_runs = 1\n",
    "config.temperature = 1\n",
    "greedy_full = False\n",
    "MW_filter = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c21f31-0315-4aef-b3be-b1f6c33fed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "if config.execution_type == \"test_performance\":\n",
    "    print(\"\\033[1m\\033[31mThis is: test_performance\\033[0m\")\n",
    "    # config.csv_path_val = config.csv_SMI_targets  #this already got updated in simulate_syn_data\n",
    "    \n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    model_CLIP = mrtf.load_CLIP_model(config)\n",
    "    #model_BLIP = mrtf.load_BLIP_model(config)\n",
    "    #model_MMT = model_CLIP.MT_model\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "\n",
    "    \n",
    "    results_dict_bl_ZINC = mrtf.run_test_mns_performance_CLIP_3(config,  \n",
    "                                                        model_MMT,\n",
    "                                                        model_CLIP,\n",
    "                                                        val_dataloader,\n",
    "                                                        stoi, \n",
    "                                                        itos,\n",
    "                                                        MW_filter)\n",
    "    results_dict_bl_ZINC, counter = mrtf.filter_invalid_inputs(results_dict_bl_ZINC)\n",
    "    \n",
    "    avg_tani_bl_ZINC, html_plot = rbgvm.plot_hist_of_results(results_dict_bl_ZINC)\n",
    "    \n",
    "    # Slow because also just takes one at the time\n",
    "    if greedy_full == True:\n",
    "        results_dict_greedy_bl_ZINC, failed_bl_ZINC = mrtf.run_test_performance_CLIP_greedy_3(config,  \n",
    "                                                                stoi, \n",
    "                                                                stoi_MF, \n",
    "                                                                itos, \n",
    "                                                                itos_MF)\n",
    "\n",
    "        avg_tani_greedy_bl_ZINC, html_plot_greedy = rbgvm.plot_hist_of_results_greedy(results_dict_greedy_bl_ZINC)\n",
    "\n",
    "    else: \n",
    "        config, results_dict_ZINC_greedy_bl = mrtf.run_greedy_sampling(config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "        avg_tani_greedy_bl_ZINC = results_dict_ZINC_greedy_bl[\"tanimoto_mean\"]\n",
    "    \n",
    "    total_results_bl_ZINC = mrtf.run_test_performance_CLIP_3(config, \n",
    "                                                        model_MMT, \n",
    "                                                        val_dataloader,\n",
    "                                                        stoi)\n",
    "    \n",
    "    corr_sampleing_prob_bl_ZINC = total_results_bl_ZINC[\"statistics_multiplication_avg\"][0]\n",
    "    print(\"avg_tani, avg_tani_greedy, corr_sampleing_prob'\")\n",
    "    print(avg_tani_bl_ZINC, avg_tani_greedy_bl_ZINC, corr_sampleing_prob_bl_ZINC)       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c367f0-0ce9-4221-830b-4b22c48d1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save variables to a pickle file\n",
    "variables_to_save = {\n",
    "    'avg_tani_bl_ZINC': avg_tani_bl_ZINC,\n",
    "    'results_dict_greedy_bl_ZINC': results_dict_greedy_bl_ZINC if greedy_full else None,\n",
    "    'failed_bl_ZINC': failed_bl_ZINC if greedy_full else None,\n",
    "    'avg_tani_greedy_bl_ZINC': avg_tani_greedy_bl_ZINC,\n",
    "    'results_dict_ZINC_greedy_bl': results_dict_ZINC_greedy_bl if not greedy_full else None,\n",
    "    'total_results_bl_ZINC': total_results_bl_ZINC,\n",
    "    'corr_sampleing_prob_bl_ZINC': corr_sampleing_prob_bl_ZINC,\n",
    "    'filtered_results': filtered_results,\n",
    "    'results_dict_bl_ZINC': results_dict_bl_ZINC,\n",
    "}\n",
    "\n",
    "with open('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_v2/6.2_PC_FT_Model_0_250.pkl', 'wb') as f:\n",
    "    pickle.dump(variables_to_save, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f2684c-a96a-4e34-95d6-806c12d29f8a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00edbf55-e435-4b2b-8f0b-f9db293f8ce9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6.2 Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e3cfe-390a-4796-ace1-76c1e1e625cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mns_tani_extraction(data):\n",
    "    \"\"\"\n",
    "    Extracts the 4th item of the first sublist of the value for each key in the dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    data (dict): The input dictionary.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing the 4th item of the first sublist for each key.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the results\n",
    "    result_list = []\n",
    "\n",
    "    # Iterate over the dictionary items\n",
    "    for key, value in data.items():\n",
    "        # Check if the value is not None and has at least one sublist\n",
    "        if value and value[0]:\n",
    "            # Get the 4th item of the first sublist\n",
    "            item = value[0][0][3]\n",
    "            # Append the item to the result list\n",
    "            result_list.append(item)\n",
    "\n",
    "    # Return the result list\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d0c40-ca5e-45ff-aeb0-285481e6025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 100_10\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_10.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_10_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_mns = pickle.load(file)\n",
    "\n",
    "\n",
    "# 100_30\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_30.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_30_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_30_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after_mns = pickle.load(file) \n",
    "        \n",
    "    \n",
    "# 100_50\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_50.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_50_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_50_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after_mns = pickle.load(file) \n",
    "    \n",
    "# 100_100\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_100.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_100_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.1_imp_cyc_100_100_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after_mns = pickle.load(file)     \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a0520-d9ab-4a34-a09d-cfb0435dbda6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Load ZINC data experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13211d2a-19d5-485e-9b08-ade070489b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100_10\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_10.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_10_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_mns = pickle.load(file)\n",
    "\n",
    "\n",
    "# 100_30\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_30.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_30_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_30_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after_mns = pickle.load(file) \n",
    "        \n",
    "    \n",
    "# 100_50\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_50.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_50_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_50_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after_mns = pickle.load(file) \n",
    "    \n",
    "# 100_100\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_100_v2.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_100_after_MNS_3_v2.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_v3/6.2_imp_cyc_all_100_100_after_MNS_3_v2.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after_mns = pickle.load(file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd74bf-11d7-42bd-90a1-6a00e0c4d3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tani_before_all_100_10 = imp_cyc_all_100_10_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10 = imp_cyc_all_100_10_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10_mns = mns_tani_extraction(imp_cyc_all_100_10_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_30 = imp_cyc_all_100_30_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30 = imp_cyc_all_100_30_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30_mns = mns_tani_extraction(imp_cyc_all_100_30_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_50 = imp_cyc_all_100_50_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50 = imp_cyc_all_100_50_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50_mns = mns_tani_extraction(imp_cyc_all_100_50_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_100 = imp_cyc_all_100_100_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100 = imp_cyc_all_100_100_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100_mns = mns_tani_extraction(imp_cyc_all_100_100_after_mns[\"results_dict_bl_ZINC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab991ee-5366-4edf-8e8c-22f3917b69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cyc_all_100_10_before[\"results_dict_ZINC_greedy_bl\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62424e7-f873-4fc3-851a-f4bd20bd52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fontsize = 26\n",
    "tani_data = [\n",
    "    (tani_before_all_100_10, 'Greedy Tanomoto Before FT10'), (tani_after_all_100_10, 'Greedy Tanomoto After FT10'), (tani_after_all_100_10_mns, '3 Multinomial Sampling After FT10'),\n",
    "    (tani_before_all_100_30, 'Greedy Tanomoto Before FT30'), (tani_after_all_100_30, 'Greedy Tanomoto After FT30'), (tani_after_all_100_30_mns, '3 Multinomial Sampling After FT30'),\n",
    "    (tani_before_all_100_50, 'Greedy Tanomoto Before FT50'), (tani_after_all_100_50, 'Greedy Tanomoto After FT50'), (tani_after_all_100_50_mns, '3 Multinomial Sampling After FT50'), \n",
    "    (tani_before_all_100_50, 'Greedy Tanomoto Before FT100'), (tani_after_all_100_100, 'Greedy Tanomoto After FT50'), (tani_after_all_100_100_mns, '3 Multinomial Sampling After FT100')\n",
    "]\n",
    "\n",
    "# Extract numerical data (count of perfect matches)\n",
    "numerical_data = [np.sum(np.array(data) == 1.0) for data, _ in tani_data]\n",
    "\n",
    "# Labels for each group\n",
    "group_labels = ['MMST IC-10', 'MMST IC-30', 'MMST IC-50', 'MMST IC-100']\n",
    "condition_labels = ['Before IC', 'After IC', 'MNS: 3']\n",
    "\n",
    "# Colors for the bars\n",
    "colors = ['#A1C8F3', '#FFB381', '#8BE5A0']  # Red, Blue, Green\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "\n",
    "# Set the width of each bar and the spacing between groups\n",
    "bar_width = 0.25\n",
    "group_spacing = 0.05\n",
    "\n",
    "# Calculate positions for each bar\n",
    "num_groups = len(group_labels)\n",
    "indices = np.arange(num_groups)\n",
    "positions = [indices + i * (bar_width + group_spacing) for i in range(3)]\n",
    "\n",
    "# Create grouped bar plot\n",
    "for i in range(3):  # Three conditions: Before, After, MNS\n",
    "    ax.bar(positions[i], numerical_data[i::3], \n",
    "           width=bar_width, color=colors[i], edgecolor='black', \n",
    "           label=condition_labels[i])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Number of Perfect Matches (Tanimoto = 1)', fontsize=fontsize)\n",
    "ax.set_title('Tanimoto Matches Across Different Conditions: ZINC 250-350 Da', fontsize=fontsize)\n",
    "ax.set_xlabel('Number of Molecule Analogues for Improvement Cycle', fontsize=fontsize)\n",
    "\n",
    "# Set x-ticks in the middle of each group\n",
    "group_centers = indices + bar_width\n",
    "ax.set_xticks(group_centers)\n",
    "ax.set_xticklabels(group_labels, fontsize=fontsize)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(numerical_data):\n",
    "    ax.text(positions[i % 3][i // 3], v, str(v), ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=fontsize, loc='upper left')\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "ax.set_ylim(0, max(numerical_data) * 1.1)  # Set y-axis limit to 110% of max value\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "\n",
    "# Specify the path and file name where you want to save the figure.\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.1.2_ZINC_Bar_Chart_Greedy_MNS_Tanimoto_v4.png'\n",
    "plt.savefig(save_path, format='png', dpi=300)  # Save as PNG with 300 dpi\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77a155-753a-4450-b56b-1f2b4c425001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the variables\n",
    "\n",
    "corr_sampleing_prob_bl_ZINC = imp_cyc_all_100_10_before['corr_sampleing_prob_bl_ZINC']\n",
    "results_dict_ZINC_greedy_bl = imp_cyc_all_100_10_before['results_dict_ZINC_greedy_bl']\n",
    "results_dict_greedy_bl_ZINC = imp_cyc_all_100_10_before['results_dict_greedy_bl_ZINC']\n",
    "\n",
    "\n",
    "#avg_tani_bl_ZINC = imp_cyc_all_100_10_before['avg_tani_bl_ZINC']\n",
    "#failed_bl_ZINC = imp_cyc_all_100_10_before['failed_bl_ZINC']\n",
    "#avg_tani_greedy_bl_ZINC = imp_cyc_all_100_10_before['avg_tani_greedy_bl_ZINC']\n",
    "#total_results_bl_ZINC = imp_cyc_all_100_10_before['total_results_bl_ZINC']\n",
    "#filtered_results = imp_cyc_all_100_10_before['filtered_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1468fe-1738-4111-a162-655a94244e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cyc_all_100_10_before.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05dcbd-2cde-474e-a601-7137fc31c256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_sp_before_all_100_10 = imp_cyc_all_100_10_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_10 = imp_cyc_all_100_10_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_30 = imp_cyc_all_100_30_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_30 = imp_cyc_all_100_30_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_50 = imp_cyc_all_100_50_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_50 = imp_cyc_all_100_50_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_100 = imp_cyc_all_100_100_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_100 = imp_cyc_all_100_100_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0bf86-ae98-41ea-b99f-9fa28f412516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for the bar chart\n",
    "values = [\n",
    "    corr_sp_before_all_100_10,  # Before (same for all)\n",
    "    corr_sp_after_all_100_10,   # After FT10\n",
    "    corr_sp_after_all_100_30,   # After FT30\n",
    "    corr_sp_after_all_100_50,   # After FT50\n",
    "    corr_sp_after_all_100_100   # After FT100\n",
    "]\n",
    "\n",
    "# Labels for the bars\n",
    "labels = [\n",
    "    'MMST Model', \n",
    "    'IC-10', \n",
    "    'IC-30', \n",
    "    'IC-50', \n",
    "    'IC-100'\n",
    "]\n",
    "\n",
    "# Colors for the bars (based on provided image)\n",
    "colors = [\n",
    "        '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "      ]\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "bars = ax.bar(labels, values, color=colors, edgecolor='black')\n",
    "\n",
    "# Add numbers inside the bars\n",
    "for bar, value in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, f'{value:.2f}', ha='center', va='center', fontsize=fontsize, color='black')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Averaged Correct Sample Probability: ZINC 250-350 Da', fontsize=fontsize)\n",
    "plt.ylabel('Averaged Correct Sample Probability', fontsize=fontsize)\n",
    "ax.set_xlabel('Number of Molecule Analogues for Improvment Cycle', fontsize=fontsize)\n",
    "\n",
    "#plt.xlabel('Stages', fontsize=16)\n",
    "\n",
    "# Increase the size of the labels on the x-axis\n",
    "ax.set_xticklabels(labels, fontsize=fontsize, rotation=0)\n",
    "\n",
    "# Increase the size of the ticks on the y-axis\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_ZINC_correct_sample_prob_comparison_v3.png\"\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73728564-de4c-4eeb-ab47-b32c26fff416",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Chemical spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdae4f7-64ac-4b89-8b16-76ffcfd0f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tani_before_all_100_10 = imp_cyc_all_100_10_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10 = imp_cyc_all_100_10_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10_mns = mns_tani_extraction(imp_cyc_all_100_10_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_30 = imp_cyc_all_100_30_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30 = imp_cyc_all_100_30_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30_mns = mns_tani_extraction(imp_cyc_all_100_30_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_50 = imp_cyc_all_100_50_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50 = imp_cyc_all_100_50_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50_mns = mns_tani_extraction(imp_cyc_all_100_50_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_100 = imp_cyc_all_100_100_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100 = imp_cyc_all_100_100_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100_mns = mns_tani_extraction(imp_cyc_all_100_100_after_mns[\"results_dict_bl_ZINC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d596c-adef-466e-9ed4-c4d58ec2fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_bl_ZINC_before = imp_cyc_all_100_10_before[\"results_dict_bl_ZINC\"]\n",
    "filtered_results_false_before = [key for key, value in results_dict_bl_ZINC_before.items() if value[0][0][-2] == 1]\n",
    "len(filtered_results_false_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341a108-50b4-49f4-919d-6955944e457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_bl_ZINC_after = imp_cyc_all_100_10_after[\"results_dict_bl_ZINC\"]\n",
    "filtered_results_false_after = [key for key, value in results_dict_bl_ZINC_after.items() if value[0][0][-2] == 1]\n",
    "len(filtered_results_false_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdc08a-fa1c-4c34-bd62-eedbdae97de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gen_smis = imp_cyc_all_100_10_before[\"all_gen_smis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c63ca-63b6-46c9-a731-12ab34b891f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert SMILES to fingerprints\n",
    "def smiles_to_fps(smiles_list):\n",
    "    fps = []\n",
    "    for smiles in tqdm(smiles_list):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512)\n",
    "            fps.append(fp)\n",
    "    return np.array(fps)\n",
    "\n",
    "fps1 = smiles_to_fps(filtered_results_false_before)\n",
    "fps2 = smiles_to_fps(all_gen_smis)\n",
    "fps3 = smiles_to_fps(filtered_results_false_after)\n",
    "\n",
    "# Concatenate the two fingerprint arrays\n",
    "all_fps = np.vstack([fps1, fps2, fps3])\n",
    "\n",
    "# Dimensionality Reduction: t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_tsne = tsne.fit_transform(all_fps)\n",
    "\n",
    "# Dimensionality Reduction: UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2)\n",
    "X_umap = umap_model.fit_transform(all_fps)\n",
    "\n",
    "# Dimensionality Reduction: PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(all_fps)\n",
    "\n",
    "\n",
    "# Plotting function with the legend below the graph\n",
    "def plot_2D(X, title, label1='Molecules Correct before', label2='Generated molecules', label3='Molecules Correct after'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(X[len(fps1):len(fps1)+len(fps2), 0], X[len(fps1):len(fps1)+len(fps2), 1], c='g', marker='^', label=label2, alpha=0.1)\n",
    "    plt.scatter(X[:len(fps1), 0], X[:len(fps1), 1], c='b', marker='o', label=label1, alpha=1, s=50)\n",
    "    plt.scatter(X[len(fps1)+len(fps2):, 0], X[len(fps1)+len(fps2):, 1], c='r', marker='s', label=label3, alpha=1, s=10)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=3, fontsize=14)  \n",
    "    output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/nmr_project/1_Dataexploration/2_paper_code/Experiments_SLURM/20.0_SLURM_MasterTransformer/Figures_Paper_2/6.1.2_t-SNE_FT10_v1.png\"\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot t-SNE\n",
    "plot_2D(X_tsne, 't-SNE Plot: FT10')\n",
    "\n",
    "# Plot UMAP\n",
    "#plot_2D(X_umap, 'UMAP Plot')\n",
    "\n",
    "# Plot PCA\n",
    "#plot_2D(X_pca, 'PCA Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f1035-cdc3-4765-8334-f4c88eab59de",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PubChem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f41285-6269-4e10-8c64-43742d224b20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Load PubChem 0-250 v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fac727-75f2-4180-b3e1-9228d57fb516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 100_10\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_10.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_10_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_mns = pickle.load(file)\n",
    "\n",
    "\n",
    "# 100_30\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_30.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_30_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_30_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after_mns = pickle.load(file) \n",
    "        \n",
    "    \n",
    "# 100_50\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_50.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_50_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_50_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after_mns = pickle.load(file) \n",
    "    \n",
    "# 100_100\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_100.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_100_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_100_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after_mns = pickle.load(file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a7e3f-a0e8-4682-9748-c931f0f81d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_v2/6.2_PC_FT_Model_0_250.pkl'\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_PC_FT_Model_0_250.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    PC_0_250_FT = pickle.load(file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17d84f-8c8d-4e57-a821-99de817908c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tani_before_all_100_10 = imp_cyc_all_100_10_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10 = imp_cyc_all_100_10_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10_mns = mns_tani_extraction(imp_cyc_all_100_10_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_30 = imp_cyc_all_100_30_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30 = imp_cyc_all_100_30_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30_mns = mns_tani_extraction(imp_cyc_all_100_30_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_50 = imp_cyc_all_100_50_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50 = imp_cyc_all_100_50_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50_mns = mns_tani_extraction(imp_cyc_all_100_50_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_100 = imp_cyc_all_100_100_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100 = imp_cyc_all_100_100_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100_mns = mns_tani_extraction(imp_cyc_all_100_100_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_PC_0_250_FT = PC_0_250_FT[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b56695d-9c58-4fa3-87cf-184297b6fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data and labels\n",
    "tani_data = [\n",
    "    (tani_before_all_100_10, 'FT10 Before'), (tani_after_all_100_10, 'FT10 After'), (tani_after_all_100_10_mns, 'FT10 MNS'),\n",
    "    (tani_before_all_100_30, 'FT30 Before'), (tani_after_all_100_30, 'FT30 After'), (tani_after_all_100_30_mns, 'FT30 MNS'),\n",
    "    (tani_before_all_100_50, 'FT50 Before'), (tani_after_all_100_50, 'FT50 After'), (tani_after_all_100_50_mns, 'FT50 MNS'), \n",
    "    (tani_before_all_100_100, 'FT100 Before'), (tani_after_all_100_100, 'FT100 After'), (tani_after_all_100_100_mns, 'FT100 MNS')\n",
    "]\n",
    "\n",
    "# Add the PubChem Fine-Tuned data\n",
    "tani_PC_0_250_FT_list = [tani_PC_0_250_FT for _ in range(4)]  # Repeat the data for each group\n",
    "\n",
    "# Count perfect matches (Tanimoto = 1) for each condition\n",
    "perfect_matches = [np.sum(np.array(data) == 1) for data, _ in tani_data]\n",
    "perfect_matches_pc = [np.sum(np.array(data) == 1) for data in tani_PC_0_250_FT_list]\n",
    "\n",
    "# Combine all perfect matches\n",
    "all_perfect_matches = []\n",
    "for i in range(4):  # For each FT group (10, 30, 50, 100)\n",
    "    all_perfect_matches.extend([perfect_matches_pc[i]] + perfect_matches[i*3:(i+1)*3])\n",
    "\n",
    "# Colors for the bars\n",
    "colors = [\n",
    "    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "]\n",
    "\n",
    "# Labels\n",
    "group_labels = ['MMST IC-10', 'MMST IC-30', 'MMST IC-50', 'MMST IC-100']\n",
    "condition_labels = ['PubChem FT', 'Before IC', 'After IC', 'MNS: 3']\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "\n",
    "# Set the width of each bar and the spacing between groups\n",
    "bar_width = 0.2\n",
    "group_spacing = 0.03\n",
    "\n",
    "# Calculate positions for each bar\n",
    "num_groups = len(group_labels)\n",
    "indices = np.arange(num_groups)\n",
    "positions = [indices + i * (bar_width + group_spacing) for i in range(4)]\n",
    "\n",
    "# Create grouped bar plot\n",
    "for i in range(4):  # Four conditions: PubChem FT, Before, After, MNS\n",
    "    ax.bar(positions[i], all_perfect_matches[i::4], \n",
    "           width=bar_width, color=colors[i], edgecolor='black', \n",
    "           label=condition_labels[i])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Number of Perfect Matches (Tanimoto = 1)', fontsize=fontsize)\n",
    "ax.set_title('Tanimoto Matches Across Different Conditions: PubChem 0-250 Da', fontsize=fontsize)\n",
    "ax.set_xlabel('Number of Molecule Analogues for Improvment Cycle', fontsize=fontsize)\n",
    "\n",
    "# Set x-ticks in the middle of each group\n",
    "group_centers = indices + 1.5 * bar_width + 0.5 * group_spacing\n",
    "ax.set_xticks(group_centers)\n",
    "ax.set_xticklabels(group_labels, fontsize=fontsize)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(all_perfect_matches):\n",
    "    ax.text(positions[i % 4][i // 4], v, str(v), ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=fontsize, loc='upper left')\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "#ax.set_ylim(0, 105)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "save_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_Bar_Chart_Greedy_MNS_Tanimoto_0_250_v4.png'  # Update this path as needed\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(save_path, format='png', dpi=300)  # Save as PNG with 300 dpi\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Uncomment to save the plot\n",
    "# plt.savefig(\"/path/to/save/grouped_perfect_matches_bar_plot.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbc77f-4759-40fe-8b41-5e8d5636f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sp_before_all_100_10 = imp_cyc_all_100_10_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_10 = imp_cyc_all_100_10_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_30 = imp_cyc_all_100_30_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_30 = imp_cyc_all_100_30_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_50 = imp_cyc_all_100_50_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_50 = imp_cyc_all_100_50_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_100 = imp_cyc_all_100_100_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_100 = imp_cyc_all_100_100_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_PC_0_250_FT = PC_0_250_FT[\"corr_sampleing_prob_bl_ZINC\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc00cc-2c83-4483-a8e7-4fadf04eac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for the bar chart\n",
    "values = [\n",
    "    corr_sp_before_all_100_10,  # Before (same for all)\n",
    "    corr_PC_0_250_FT,         # PC FT\n",
    "    corr_sp_after_all_100_10,   # After FT10\n",
    "    corr_sp_after_all_100_30,   # After FT30\n",
    "    corr_sp_after_all_100_50,   # After FT50\n",
    "    corr_sp_after_all_100_100   # After FT100\n",
    "]\n",
    "\n",
    "# Labels for the bars\n",
    "labels = [\n",
    "    'MMST Model', \n",
    "    'PC FT', \n",
    "    'IC-10', \n",
    "    'IC-30', \n",
    "    'IC-50', \n",
    "    'IC-100'\n",
    "]\n",
    "\n",
    "# Colors for the bars (based on provided image)\n",
    "colors = [\n",
    "    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "]\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "bars = ax.bar(labels, values, color=colors, edgecolor='black')\n",
    "\n",
    "# Add numbers inside the bars\n",
    "for bar, value in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, f'{value:.2f}', ha='center', va='center', fontsize=fontsize, color='black')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Averaged Correct Sample Probability: PubChem 0-250 Da', fontsize=fontsize)\n",
    "plt.ylabel('Averaged Correct Sample Probability', fontsize=fontsize)\n",
    "ax.set_xlabel('Number of Molecule Analogues for Improvment Cycle', fontsize=fontsize)\n",
    "\n",
    "# Increase the size of the labels on the x-axis\n",
    "ax.set_xticklabels(labels, fontsize=fontsize, rotation=0)\n",
    "\n",
    "# Increase the size of the ticks on the y-axis\n",
    "ax.tick_params(axis='y', labelsize=21)\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_correct_sample_prob_comparison_0_250_v3.png\"\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575c64e-237b-48bc-b6a8-540f7a17ea1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a985cbdd-f6bd-4bb6-bc7f-fc67a322aa65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Load PubChem 250-350 v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d02fe-1fc3-4dc3-960f-1554ddbc73bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100_10\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_10.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_10_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_mns = pickle.load(file)\n",
    "\n",
    "\n",
    "# 100_30\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_30.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_30_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_30_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after_mns = pickle.load(file) \n",
    "        \n",
    "    \n",
    "# 100_50\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_50.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_50_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_50_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after_mns = pickle.load(file) \n",
    "    \n",
    "# 100_100\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_100.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_100_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_100_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after_mns = pickle.load(file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396576a7-cd98-4b61-9aa3-799fe95083ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_PC_FT_Model_250_350.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    PC_250_350_FT = pickle.load(file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec75c90a-1a6d-4e95-93ae-b91b96f24eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tani_before_all_100_10 = imp_cyc_all_100_10_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10 = imp_cyc_all_100_10_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10_mns = mns_tani_extraction(imp_cyc_all_100_10_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_30 = imp_cyc_all_100_30_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30 = imp_cyc_all_100_30_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30_mns = mns_tani_extraction(imp_cyc_all_100_30_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_50 = imp_cyc_all_100_50_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50 = imp_cyc_all_100_50_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50_mns = mns_tani_extraction(imp_cyc_all_100_50_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_100 = imp_cyc_all_100_100_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100 = imp_cyc_all_100_100_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100_mns = mns_tani_extraction(imp_cyc_all_100_100_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_PC_250_350_FT = PC_250_350_FT[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94502e-d285-4501-91c0-321f3664c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fontsize = 26\n",
    "# Data and labels\n",
    "tani_data = [\n",
    "    (tani_before_all_100_10, 'FT10 Before'), (tani_after_all_100_10, 'FT10 After'), (tani_after_all_100_10_mns, 'FT10 MNS'),\n",
    "    (tani_before_all_100_30, 'FT30 Before'), (tani_after_all_100_30, 'FT30 After'), (tani_after_all_100_30_mns, 'FT30 MNS'),\n",
    "    (tani_before_all_100_50, 'FT50 Before'), (tani_after_all_100_50, 'FT50 After'), (tani_after_all_100_50_mns, 'FT50 MNS'), \n",
    "    (tani_before_all_100_100, 'FT100 Before'), (tani_after_all_100_100, 'FT100 After'), (tani_after_all_100_100_mns, 'FT100 MNS')\n",
    "]\n",
    "\n",
    "# Add the PubChem Fine-Tuned data\n",
    "tani_PC_250_350_FT_list = [tani_PC_250_350_FT for _ in range(4)]  # Repeat the data for each group\n",
    "\n",
    "# Count perfect matches (Tanimoto = 1) for each condition\n",
    "perfect_matches = [np.sum(np.array(data) == 1) for data, _ in tani_data]\n",
    "perfect_matches_pc = [np.sum(np.array(data) == 1) for data in tani_PC_250_350_FT_list]\n",
    "\n",
    "# Combine all perfect matches\n",
    "all_perfect_matches = []\n",
    "for i in range(4):  # For each FT group (10, 30, 50, 100)\n",
    "    all_perfect_matches.extend([perfect_matches_pc[i]] + perfect_matches[i*3:(i+1)*3])\n",
    "\n",
    "# Colors for the bars\n",
    "condition_labels = ['PubChem FT', 'Before IC', 'After IC', 'MNS: 3']\n",
    "\n",
    "# Labels\n",
    "group_labels = ['MMST IC-10', 'MMST IC-30', 'MMST IC-50', 'MMST IC-100']\n",
    "colors = [ '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "\n",
    "# Set the width of each bar and the spacing between groups\n",
    "bar_width = 0.2\n",
    "group_spacing = 0.03\n",
    "\n",
    "# Calculate positions for each bar\n",
    "num_groups = len(group_labels)\n",
    "indices = np.arange(num_groups)\n",
    "positions = [indices + i * (bar_width + group_spacing) for i in range(4)]\n",
    "\n",
    "# Create grouped bar plot\n",
    "for i in range(4):  # Four conditions: PubChem FT, Before, After, MNS\n",
    "    ax.bar(positions[i], all_perfect_matches[i::4], \n",
    "           width=bar_width, color=colors[i], edgecolor='black', \n",
    "           label=condition_labels[i])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Number of Perfect Matches (Tanimoto = 1)', fontsize=fontsize)\n",
    "ax.set_xlabel('Number of Molecule Analogues for Improvement Cycle', fontsize=fontsize)\n",
    "ax.set_title('Tanimoto Matches Across Different Conditions: PubChem 250-350 Da', fontsize=fontsize)\n",
    "\n",
    "# Set x-ticks in the middle of each group\n",
    "group_centers = indices + 1.5 * bar_width + 0.5 * group_spacing\n",
    "ax.set_xticks(group_centers)\n",
    "ax.set_xticklabels(group_labels, fontsize=fontsize)\n",
    "\n",
    "# Set y-axis tick label font size\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(all_perfect_matches):\n",
    "    ax.text(positions[i % 4][i // 4], v, str(v), ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=22, loc='upper left')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_Bar_Chart_Greedy_MNS_Tanimoto_250_350_v3.png\"\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2e609-9716-4fe2-80cb-c54a98f5df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sp_before_all_100_10 = imp_cyc_all_100_10_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_10 = imp_cyc_all_100_10_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_30 = imp_cyc_all_100_30_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_30 = imp_cyc_all_100_30_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_50 = imp_cyc_all_100_50_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_50 = imp_cyc_all_100_50_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_100 = imp_cyc_all_100_100_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_100 = imp_cyc_all_100_100_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_PC_250_350_FT = PC_250_350_FT[\"corr_sampleing_prob_bl_ZINC\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b6f14-62d2-43a8-a307-4d77c4f3512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for the bar chart\n",
    "values = [\n",
    "    corr_sp_before_all_100_10,  # Before (same for all)\n",
    "    corr_PC_250_350_FT,         # PC FT\n",
    "    corr_sp_after_all_100_10,   # After FT10\n",
    "    corr_sp_after_all_100_30,   # After FT30\n",
    "    corr_sp_after_all_100_50,   # After FT50\n",
    "    corr_sp_after_all_100_100   # After FT100\n",
    "]\n",
    "\n",
    "# Labels for the bars\n",
    "labels = [\n",
    "    'MMST Model', \n",
    "    'PC FT', \n",
    "    'IC-10', \n",
    "    'IC-30', \n",
    "    'IC-50', \n",
    "    'IC-100'\n",
    "]\n",
    "\n",
    "# Colors for the bars (based on provided image)\n",
    "colors = [\n",
    "    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "]\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "bars = ax.bar(labels, values, color=colors, edgecolor='black')\n",
    "\n",
    "# Add numbers inside the bars\n",
    "for bar, value in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, f'{value:.2f}', ha='center', va='center', fontsize=fontsize, color='black')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Averaged Correct Sample Probability: PubChem 250-350 Da', fontsize=fontsize)\n",
    "plt.ylabel('Averaged Correct Sample Probability', fontsize=fontsize)\n",
    "ax.set_xlabel('Number of Molecule Analogues for Improvment Cycle', fontsize=fontsize)\n",
    "\n",
    "# Increase the size of the labels on the x-axis\n",
    "ax.set_xticklabels(labels, fontsize=fontsize, rotation=0)\n",
    "\n",
    "# Increase the size of the ticks on the y-axis\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_correct_sample_prob_comparison_250_350_v3.png\"\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b833cb-36bf-4186-b30e-92517e915a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec67695-753c-431b-976f-f23b2acaa7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17109478-7283-41b0-ad1a-059f70bf7a7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Load PubChem 350-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f8ba3-d557-437c-a159-2ddc8ba5b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100_10\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_10.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_30_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_mns = pickle.load(file)\n",
    "\n",
    "\n",
    "# 100_30\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_30.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_30_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_30_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_30_after_mns = pickle.load(file) \n",
    "        \n",
    "    \n",
    "# 100_50\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_50.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_50_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_50_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_50_after_mns = pickle.load(file) \n",
    "    \n",
    "# 100_100\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_100.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_before = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_100_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_100_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_100_after_mns = pickle.load(file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b2886-ff58-405d-8d83-5b5ce0c19eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_PC_FT_Model_350_500.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    PC_350_500_FT = pickle.load(file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e674a5b-d123-4394-a47e-44f91ade79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100_10 second fine-tuning step\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240522_PC_Imp_Cycle_2_from_350_500/6.2_imp_cyc_all_100_10_after_epoch41.pkl'\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240522_PC_Imp_Cycle_2_from_350_500/6.2_imp_cyc_all_100_10_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_2 = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240522_PC_Imp_Cycle_2_from_350_500/6.2_imp_cyc_all_100_10_after_epoch41.pkl'\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240522_PC_Imp_Cycle_2_from_350_500/6.2_imp_cyc_all_100_10_after_MNS_3.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_mns_2 = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea8ef1-3f13-4593-896c-35286261f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "tani_before_all_100_10 = imp_cyc_all_100_10_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10 = imp_cyc_all_100_10_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10_mns = mns_tani_extraction(imp_cyc_all_100_10_after_mns[\"results_dict_bl_ZINC\"])\n",
    "\n",
    "tani_after_all_100_10_2 = imp_cyc_all_100_10_after_2[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_10_mns_2 = mns_tani_extraction(imp_cyc_all_100_10_after_mns_2[\"results_dict_bl_ZINC\"])\n",
    "\n",
    "\n",
    "tani_before_all_100_30 = imp_cyc_all_100_30_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30 = imp_cyc_all_100_30_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_30_mns = mns_tani_extraction(imp_cyc_all_100_30_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_50 = imp_cyc_all_100_50_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50 = imp_cyc_all_100_50_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_50_mns = mns_tani_extraction(imp_cyc_all_100_50_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_before_all_100_100 = imp_cyc_all_100_100_before[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100 = imp_cyc_all_100_100_after[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_all_100_100_mns = mns_tani_extraction(imp_cyc_all_100_100_after_mns[\"results_dict_bl_ZINC\"])\n",
    "tani_PC_350_500_FT = PC_350_500_FT[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95daff4a-7a52-4d3c-9e95-3037a0d2952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data and labels\n",
    "tani_data = [\n",
    "    (tani_before_all_100_10, 'FT10 Before'), (tani_after_all_100_10, 'FT10 After'), (tani_after_all_100_10_mns, 'FT10 MNS'),\n",
    "    #(tani_before_all_100_10, 'FT10 2x Before'), (tani_after_all_100_10_2, 'FT10 2x After'), (tani_after_all_100_10_mns_2, 'FT10 2x MNS'),\n",
    "    (tani_before_all_100_30, 'FT30 Before'), (tani_after_all_100_30, 'FT30 After'), (tani_after_all_100_30_mns, 'FT30 MNS'),\n",
    "    (tani_before_all_100_50, 'FT50 Before'), (tani_after_all_100_50, 'FT50 After'), (tani_after_all_100_50_mns, 'FT50 MNS'), \n",
    "    (tani_before_all_100_100, 'FT100 Before'), (tani_after_all_100_100, 'FT100 After'), (tani_after_all_100_100_mns, 'FT100 MNS')\n",
    "]\n",
    "\n",
    "# Add the PubChem Fine-Tuned data\n",
    "tani_PC_350_500_FT_list = [tani_PC_350_500_FT for _ in range(5)]  # Repeat the data for each group\n",
    "\n",
    "# Count perfect matches (Tanimoto = 1) for each condition\n",
    "perfect_matches = [np.sum(np.array(data) == 1) for data, _ in tani_data]\n",
    "perfect_matches_pc = [np.sum(np.array(data) == 1) for data in tani_PC_350_500_FT_list]\n",
    "\n",
    "# Combine all perfect matches\n",
    "all_perfect_matches = []\n",
    "for i in range(4):  # For each FT group (10, 10 2x, 30, 50, 100)\n",
    "    all_perfect_matches.extend([perfect_matches_pc[i]] + perfect_matches[i*3:(i+1)*3])\n",
    "\n",
    "# Colors for the bars\n",
    "colors = [    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    ]\n",
    "\n",
    "# Labels\n",
    "group_labels = ['MMST IC-10',  'MMST IC-30', 'MMST IC-50', 'MMST IC-100'] #'FT10 2x',\n",
    "condition_labels = ['PubChem FT', 'Before IC', 'After IC', 'MNS: 3']\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "\n",
    "# Set the width of each bar and the spacing between groups\n",
    "bar_width = 0.2\n",
    "group_spacing = 0.03\n",
    "\n",
    "# Calculate positions for each bar\n",
    "num_groups = len(group_labels)\n",
    "indices = np.arange(num_groups)\n",
    "positions = [indices + i * (bar_width + group_spacing) for i in range(4)]\n",
    "\n",
    "# Create grouped bar plot\n",
    "for i in range(4):  # Four conditions: PubChem FT, Before, After, MNS\n",
    "    ax.bar(positions[i], all_perfect_matches[i::4], \n",
    "           width=bar_width, color=colors[i], edgecolor='black', \n",
    "           label=condition_labels[i])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Number of Perfect Matches (Tanimoto = 1)', fontsize=fontsize)\n",
    "ax.set_xlabel('Number of Molecule Analogues for Improvement Cycle', fontsize=fontsize)\n",
    "ax.set_title('Tanimoto Matches Across Different Conditions: PubChem 350-500 Da', fontsize=fontsize)\n",
    "\n",
    "# Set x-ticks in the middle of each group\n",
    "group_centers = indices + 1.5 * bar_width + 0.5 * group_spacing\n",
    "ax.set_xticks(group_centers)\n",
    "ax.set_xticklabels(group_labels, fontsize=fontsize)\n",
    "\n",
    "# Set y-axis tick label font size\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(all_perfect_matches):\n",
    "    ax.text(positions[i % 4][i // 4], v, str(v), ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=fontsize, loc='upper left')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_Bar_Chart_Greedy_MNS_Tanimoto_350_500_v3.png\"\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ece7a-bcc5-45ca-b08f-361d7556ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the variables\n",
    "\"\"\"\n",
    "corr_sampleing_prob_bl_ZINC = imp_cyc_all_100_10_before['corr_sampleing_prob_bl_ZINC']\n",
    "results_dict_ZINC_greedy_bl = imp_cyc_all_100_10_before['results_dict_ZINC_greedy_bl']\n",
    "results_dict_greedy_bl_ZINC = imp_cyc_all_100_10_before['results_dict_greedy_bl_ZINC']\n",
    "tani_PC_350_500_FT = PC_350_500_FT[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "\"\"\"\n",
    "\n",
    "#avg_tani_bl_ZINC = imp_cyc_all_100_10_before['avg_tani_bl_ZINC']\n",
    "#failed_bl_ZINC = imp_cyc_all_100_10_before['failed_bl_ZINC']\n",
    "#avg_tani_greedy_bl_ZINC = imp_cyc_all_100_10_before['avg_tani_greedy_bl_ZINC']\n",
    "#total_results_bl_ZINC = imp_cyc_all_100_10_before['total_results_bl_ZINC']\n",
    "#filtered_results = imp_cyc_all_100_10_before['filtered_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b1557-c460-43d9-aad6-34aafd26e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sp_before_all_100_10 = imp_cyc_all_100_10_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_10 = imp_cyc_all_100_10_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_10_2 = imp_cyc_all_100_10_after_2[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_30 = imp_cyc_all_100_30_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_30 = imp_cyc_all_100_30_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_50 = imp_cyc_all_100_50_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_50 = imp_cyc_all_100_50_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_all_100_100 = imp_cyc_all_100_100_before[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_all_100_100 = imp_cyc_all_100_100_after[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_PC_350_500_FT = PC_350_500_FT[\"corr_sampleing_prob_bl_ZINC\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4d090-2bbf-4a3e-ba62-729f428c59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for the bar chart\n",
    "values = [\n",
    "    corr_sp_before_all_100_10,  # Before (same for all)\n",
    "    corr_PC_350_500_FT,         # PC FT\n",
    "    corr_sp_after_all_100_10,   # After FT10\n",
    "  #  corr_sp_after_all_100_10_2,  # After 2x FT10\n",
    "    corr_sp_after_all_100_30,   # After FT30\n",
    "    corr_sp_after_all_100_50,   # After FT50\n",
    "    corr_sp_after_all_100_100   # After FT100\n",
    "]\n",
    "\n",
    "# Labels for the bars\n",
    "labels = [\n",
    "    'MMST Model', \n",
    "    'PC FT', \n",
    "    'IC-10', \n",
    "    #'MMTi Imp-Cycle: 2x FT10', \n",
    "    'IC-30', \n",
    "    'IC-50', \n",
    "    'IC-100'\n",
    "]\n",
    "\n",
    "# Colors for the bars (based on provided image)\n",
    "colors = [\n",
    "    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "]\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "bars = ax.bar(labels, values, color=colors, edgecolor='black')\n",
    "\n",
    "# Add numbers inside the bars\n",
    "for bar, value in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, f'{value:.2f}', ha='center', va='center', fontsize=fontsize, color='black')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Averaged Correct Sample Probability: PubChem 350-500 Da', fontsize=fontsize)\n",
    "plt.ylabel('Averaged Correct Sample Probability', fontsize=21)\n",
    "ax.set_xlabel('Number of Molecule Analogues for Improvment Cycle', fontsize=fontsize)\n",
    "\n",
    "# Increase the size of the labels on the x-axis\n",
    "ax.set_xticklabels(labels, fontsize=fontsize, rotation=0)\n",
    "\n",
    "# Increase the size of the ticks on the y-axis\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.2f}'))\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_correct_sample_prob_comparison_350_500_v3.png\"\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac957c8-c076-42cc-a812-116b11e9164b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PubChem Second round training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff240f-6fb4-4191-a15b-e7d9eb1c2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100_10 0_250\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_10.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_before_0_250 = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_0_250/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_0_250 = pickle.load(file)\n",
    "\n",
    "#maybe need to take the first one    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240523_PC_Imp_Cycle_2_from_250_350/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_2_0_250 = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c9c6f-6b06-4108-8cd9-9b0cfa7e37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100_10 250_350\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_10.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_before_250_350 = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240520_Improvment_Cycle_PC_250_350/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_250_350 = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240523_PC_Imp_Cycle_2_from_250_350/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_2_250_350 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d1cba-64d1-434d-bbac-3f0cf5a7430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100_10 350_500\n",
    "import pickle\n",
    "\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_10.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_before_350_500 = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240517_Improvment_Cycle_PC_350_500/6.2_imp_cyc_all_100_10_after.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_350_500 = pickle.load(file)\n",
    "    \n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240522_PC_Imp_Cycle_2_from_350_500/6.2_imp_cyc_all_100_10_after_v3_second_round.pkl'\n",
    "# Loading results_list_b\n",
    "with open(file_path, 'rb') as file:\n",
    "    imp_cyc_all_100_10_after_2_350_500 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18be48-7bb2-4867-826d-682e62381d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tani_before_0_250 = imp_cyc_all_100_10_before_0_250[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_0_250 = imp_cyc_all_100_10_after_0_250[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_2_0_250 = imp_cyc_all_100_10_after_2_0_250[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_before_250_350 = imp_cyc_all_100_10_before_250_350[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_250_350 = imp_cyc_all_100_10_after_250_350[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_2_250_350 = imp_cyc_all_100_10_after_2_250_350[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_before_350_500 = imp_cyc_all_100_10_before_350_500[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_350_500 = imp_cyc_all_100_10_after_350_500[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n",
    "tani_after_2_350_500 = imp_cyc_all_100_10_after_2_350_500[\"results_dict_ZINC_greedy_bl\"][\"tanimoto_sim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab297e5-6f5c-498f-ae03-823ceaf28f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data and labels\n",
    "tani_data = [\n",
    "    (tani_before_0_250, 'FT0-250 Before'), (tani_after_0_250, 'FT0-250 After'), (tani_after_2_0_250, 'FT0-250 2nd Round'),\n",
    "    (tani_before_250_350, 'FT250-350 Before'), (tani_after_250_350, 'FT250-350 After'), (tani_after_2_250_350, 'FT250-350 2nd Round'),\n",
    "    (tani_before_350_500, 'FT350-500 Before'), (tani_after_350_500, 'FT350-500 After'), (tani_after_2_350_500, 'FT350-500 2nd Round')\n",
    "]\n",
    "\n",
    "# Count perfect matches (Tanimoto = 1) for each condition\n",
    "perfect_matches = [np.sum(np.array(data) == 1) for data, _ in tani_data]\n",
    "\n",
    "# Colors for the bars\n",
    "colors = [    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "        ]\n",
    "\n",
    "# Labels\n",
    "group_labels = ['PubChem: 0-250', 'PubChem: 250-350', 'PubChem: 350-500']\n",
    "condition_labels = ['Before IC', 'After IC', 'After 2x IC']\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "\n",
    "# Set the width of each bar and the spacing between groups\n",
    "bar_width = 0.25\n",
    "group_spacing = 0.05\n",
    "\n",
    "# Calculate positions for each bar\n",
    "num_groups = len(group_labels)\n",
    "indices = np.arange(num_groups)\n",
    "positions = [indices + i * (bar_width + group_spacing) for i in range(3)]\n",
    "\n",
    "# Create grouped bar plot\n",
    "for i in range(3):  # Three conditions: Before, After, 2nd Round\n",
    "    ax.bar(positions[i], perfect_matches[i::3], \n",
    "           width=bar_width, color=colors[i], edgecolor='black', \n",
    "           label=condition_labels[i])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Number of Perfect Matches (Tanimoto = 1)', fontsize=fontsize)\n",
    "ax.set_xlabel('Molecular Weight Ranges', fontsize=fontsize)\n",
    "ax.set_title('Tanimoto Matches Across Different Conditions: PubChem Data', fontsize=fontsize)\n",
    "\n",
    "# Set x-ticks in the middle of each group\n",
    "group_centers = indices + bar_width\n",
    "ax.set_xticks(group_centers)\n",
    "ax.set_xticklabels(group_labels, fontsize=fontsize)\n",
    "\n",
    "# Set y-axis tick label font size\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(perfect_matches):\n",
    "    ax.text(positions[i % 3][i // 3], v, str(v), ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "# Add legend to the upper right corner\n",
    "ax.legend(fontsize=fontsize, loc='upper left')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_Bar_Chart_Greedy_second_round_v3.png\"\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf657d-936d-4cc9-a802-b242bf0d47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_sp_before_0_250 = imp_cyc_all_100_10_before_0_250[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_0_250 = imp_cyc_all_100_10_after_0_250[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_2_0_250 = imp_cyc_all_100_10_after_2_0_250[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_250_350 = imp_cyc_all_100_10_before_250_350[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_250_350 = imp_cyc_all_100_10_after_250_350[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_2_250_350 = imp_cyc_all_100_10_after_2_250_350[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_before_350_500 = imp_cyc_all_100_10_before_350_500[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_350_500 = imp_cyc_all_100_10_after_350_500[\"corr_sampleing_prob_bl_ZINC\"]\n",
    "corr_sp_after_2_350_500 = imp_cyc_all_100_10_after_2_350_500[\"corr_sampleing_prob_bl_ZINC\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5df604-8bb5-407e-b8e0-d555170b9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for the bar chart\n",
    "values = [\n",
    "    np.mean(corr_sp_before_0_250), np.mean(corr_sp_after_0_250), np.mean(corr_sp_after_2_0_250),\n",
    "    np.mean(corr_sp_before_250_350), np.mean(corr_sp_after_250_350), np.mean(corr_sp_after_2_250_350),\n",
    "    np.mean(corr_sp_before_350_500), np.mean(corr_sp_after_350_500), np.mean(corr_sp_after_2_350_500)\n",
    "]\n",
    "\n",
    "# Colors for the bars\n",
    "colors = ['#E57373', '#A2A37E', '#64B689']\n",
    "colors = [    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',]  # coral pink]  # Red, Blue, Orange, Green\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "\n",
    "# Set the width of each bar and the spacing between groups\n",
    "bar_width = 0.25\n",
    "group_spacing = 0.05\n",
    "\n",
    "# Calculate positions for each bar\n",
    "indices = np.arange(3)\n",
    "positions = [indices + i * (bar_width + group_spacing) for i in range(3)]\n",
    "\n",
    "# Create grouped bar plot\n",
    "for i in range(3):  # Three conditions: Before, After, 2nd Round\n",
    "    bars = ax.bar(positions[i], values[i::3], \n",
    "                  width=bar_width, color=colors[i], edgecolor='black', \n",
    "                  label=['Before IC', 'After IC', 'After 2x IC'][i])\n",
    "    \n",
    "    # Add numbers inside the bars\n",
    "    for bar, value in zip(bars, values[i::3]):\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, \n",
    "                f'{value:.2f}', ha='center', va='center', fontsize=fontsize, color='black')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Averaged Correct Sample Probability', fontsize=fontsize)\n",
    "ax.set_title('Averaged Correct Sample Probability: PubChem Data', fontsize=fontsize)\n",
    "ax.set_xlabel('Molecular Weight Ranges', fontsize=fontsize)\n",
    "\n",
    "# Set x-ticks in the middle of each group\n",
    "group_centers = indices + bar_width\n",
    "ax.set_xticks(group_centers)\n",
    "ax.set_xticklabels(['PubChem 0-250', 'PubChem 250-350', 'PubChem 350-500'], fontsize=fontsize)\n",
    "\n",
    "# Set y-axis to display two decimal places\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.2f}'))\n",
    "\n",
    "# Increase the size of the ticks on the y-axis\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=fontsize, loc='upper left')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_correct_sample_prob_comparison_second_ro_v3.png\"\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d334a4-a107-4504-9ef4-599fba872b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for the bar chart\n",
    "values = [\n",
    "    np.mean(corr_sp_before_0_250),  # Before (0-250)\n",
    "    np.mean(corr_sp_after_0_250),   # After 0-250\n",
    "    np.mean(corr_sp_after_2_0_250), # 2nd Round After 0-250\n",
    "    np.mean(corr_sp_before_250_350),  # Before (250-350)\n",
    "    np.mean(corr_sp_after_250_350),   # After 250-350\n",
    "    np.mean(corr_sp_after_2_250_350), # 2nd Round After 250-350\n",
    "    np.mean(corr_sp_before_350_500),  # Before (350-500)\n",
    "    np.mean(corr_sp_after_350_500),   # After 350-500\n",
    "    np.mean(corr_sp_after_2_350_500)  # 2nd Round After 350-500\n",
    "]\n",
    "\n",
    "# Labels for the bars\n",
    "labels = [\n",
    "    'Before IC 0-250', \n",
    "    'After IC 0-250', \n",
    "    'After 2x IC 0-250',\n",
    "    'Before IC 250-350', \n",
    "    'After IC 250-350', \n",
    "    'After 2x IC 250-350',\n",
    "    'Before IC 350-500', \n",
    "    'After IC 350-500', \n",
    "    'After 2x IC 350-500'\n",
    "]\n",
    "\n",
    "# Colors for the bars (based on provided image)\n",
    "colors = [\n",
    "    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    '#FF9D9A',  # coral pink\n",
    "    '#D1B9FE',  # lavender\n",
    "    '#DEBA9A',  # beige/tan\n",
    "    '#FCAEE3',  # pink\n",
    "    '#CFCECE',  # light gray\n",
    "    '#FEFDA2',  # pale yellow\n",
    "    '#B8F1EF',  # light cyan/aqua\n",
    "]\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "bars = ax.bar(labels, values, color=colors, edgecolor='black')\n",
    "\n",
    "# Add numbers inside the bars\n",
    "for bar, value in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, f'{value:.2f}', ha='center', va='center', fontsize=fontsize, color='black')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Averaged Correct Sample Probability', fontsize=fontsize)\n",
    "plt.ylabel('Averaged Correct Sample Probability', fontsize=fontsize)\n",
    "#plt.xlabel('Stages', fontsize=16)\n",
    "\n",
    "# Increase the size of the labels on the x-axis\n",
    "ax.set_xticklabels(labels, fontsize=fontsize, rotation=45, ha='right')\n",
    "\n",
    "# Increase the size of the ticks on the y-axis\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "# Save the plot to a specified location\n",
    "output_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/6.2.2_PC_correct_sample_prob_comparison_second_ro_v3.png\"\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24533d29-65bd-4b90-86c3-cf0d7f179ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49635dd8-826c-4051-b3e7-eeb788b31148",
   "metadata": {},
   "source": [
    "### 7.0 Experimental vs Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff6c5f-6630-47a2-9d95-26bf9e87c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_comparison_bars(data_dict, colors, figsize=(12, 6), save_path=None):\n",
    "    \"\"\"\n",
    "    Create a bar plot comparing different metrics across all categories.\n",
    "    Shows accuracy as percentages and adds rotated value labels above bars.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary with categories and their accuracy values (0-1 scale)\n",
    "    colors : list\n",
    "        List of colors for the bars\n",
    "    figsize : tuple\n",
    "        Figure size as (width, height)\n",
    "    save_path : str, optional\n",
    "        Full path where to save the figure\n",
    "    \"\"\"\n",
    "    # Check if data_dict is empty and use dummy data if it is\n",
    "    if not data_dict:\n",
    "        data_dict = {\n",
    "            'Simulated': [0.18, 0.20, 0.22],\n",
    "            'IC on Simulated target': [0.32, 0.33, 0.34],\n",
    "            'IC on Simulated (analogue)': [0.28, 0.30, 0.32],\n",
    "            'Experimental': [0.02, 0.03, 0.04],\n",
    "            'IC on Experimental (target)': [0.12, 0.22, 0.25],\n",
    "            'IC on Experimental (analogue)': [0.10, 0.20, 0.25],\n",
    "        }\n",
    "    \n",
    "    # Create the figure with specified figsize\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Calculate positions for bars\n",
    "    categories = list(data_dict.keys())\n",
    "    n_categories = len(categories)\n",
    "    n_metrics = len(list(data_dict.values())[0])\n",
    "    \n",
    "    # Set width of bars and positions of the bars\n",
    "    total_width = 0.8\n",
    "    width = total_width / n_metrics\n",
    "    x = np.arange(n_categories)\n",
    "    \n",
    "    # Create bars for each metric\n",
    "    metric_names = ['top-1', 'top-3', 'top-10']\n",
    "    \n",
    "    # Set y-axis limit first to properly position labels\n",
    "    ax.set_ylim(0, 1.1)  # Set y-axis limit from 0 to 110%\n",
    "    \n",
    "    for i in range(n_metrics):\n",
    "        values = [data_dict[cat][i] for cat in categories]\n",
    "        offset = width * i - (total_width/2) + (width/2)\n",
    "        bars = ax.bar(x + offset, values, width, label=metric_names[i], color=colors[i], edgecolor='black')\n",
    "        \n",
    "        # Add value labels above bars with more spacing\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, \n",
    "                   height + 0.03,  # Add more space between bar and label\n",
    "                   f'{height*100:.0f}%',\n",
    "                   ha='center', \n",
    "                   va='bottom',\n",
    "                   rotation=90,\n",
    "                   fontsize=10)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=14)\n",
    "    ax.set_title('Comparison Across Categories', fontsize=16, pad=20)\n",
    "    \n",
    "    # Set x-ticks\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories, rotation=45, ha='right', fontsize=12)\n",
    "    \n",
    "    # Set y-ticks and convert to percentages\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    y_ticks = np.arange(0, 1.2, 0.2)  # Create ticks at 0%, 20%, 40%, 60%, 80%, 100%\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels([f'{x*100:.0f}%' for x in y_ticks])\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    colors = [\n",
    "        '#A1C8F3',  # light blue/periwinkle\n",
    "        '#B8F1EF',  # light cyan/aqua\n",
    "        '#FFB381',  # salmon/peach\n",
    "        #'#8BE5A0',  # mint green\n",
    "        #'#D1B9FE',  # lavender\n",
    "    ]\n",
    "    \n",
    "    # Example save path\n",
    "    save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/7.0_IC_comparison_exp_sim_aug_plot.png\"\n",
    "    \n",
    "    # Call with dummy data\n",
    "    #plot_comparison_bars({}, colors, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7b5bc-9d33-4923-8b3b-6b7d9154b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_comparison_bars(data_dict, colors, figsize=(12, 6), save_path=None):\n",
    "    \"\"\"\n",
    "    Create a bar plot comparing different metrics across all categories.\n",
    "    Shows accuracy as percentages with labels inside bars (except for BL Experimental).\n",
    "    X-axis labels are split into two rows.\n",
    "    Axis labels: font size 18\n",
    "    All other text: font size 20\n",
    "    \"\"\"\n",
    "    # Check if data_dict is empty and use dummy data if it is\n",
    "    if not data_dict:\n",
    "        data_dict = {\n",
    "            'BL Simulated (target)': [0.576, 0.576, 0.606],\n",
    "            'IC Simulated (target)': [0.971, 1.0, 1.0],\n",
    "            'IC Simulated (analogue)': [0.529, 0.559, 0.706],\n",
    "            'BL Experimental (target)': [0.0, 0.0, 0.029],\n",
    "            'IC Experimental (target)': [0.312, 0.562, 0.812],\n",
    "            'IC Experimental (analogue)': [0.118, 0.382, 0.441]\n",
    "        }\n",
    "    \n",
    "    # Create the figure with specified figsize\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Calculate positions for bars\n",
    "    categories = list(data_dict.keys())\n",
    "    n_categories = len(categories)\n",
    "    n_metrics = len(list(data_dict.values())[0])\n",
    "    \n",
    "    # Set width of bars and positions of the bars\n",
    "    total_width = 0.8\n",
    "    width = total_width / n_metrics\n",
    "    x = np.arange(n_categories)\n",
    "    \n",
    "    # Create bars for each metric\n",
    "    metric_names = ['top-1', 'top-3', 'top-10']\n",
    "    \n",
    "    # Set y-axis limit first to properly position labels\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    \n",
    "    for i in range(n_metrics):\n",
    "        values = [data_dict[cat][i] for cat in categories]\n",
    "        offset = width * i - (total_width/2) + (width/2)\n",
    "        bars = ax.bar(x + offset, values, width, label=metric_names[i], color=colors[i], edgecolor='black')\n",
    "        \n",
    "        # Add value labels\n",
    "        for j, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            \n",
    "            # Special case for BL Experimental (target) where height is very small\n",
    "            if categories[j] == 'BL Experimental (target)' and height < 0.1:\n",
    "                # Place label above the bar\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, \n",
    "                       height + 0.03,\n",
    "                       f'{height*100:.0f}%',\n",
    "                       ha='center', \n",
    "                       va='bottom',\n",
    "                       rotation=90,\n",
    "                       fontsize=20)\n",
    "            else:\n",
    "                # Place label inside the bar\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, \n",
    "                       height/2,  # Center vertically inside bar\n",
    "                       f'{height*100:.0f}%',\n",
    "                       ha='center', \n",
    "                       va='center',\n",
    "                       rotation=90,\n",
    "                       fontsize=20)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=18)  # Changed to 18\n",
    "    ax.set_title('Comparison Across Categories', fontsize=20, pad=20)\n",
    "    \n",
    "    # Create two-line labels\n",
    "    def split_category(category):\n",
    "        if '(target)' in category or '(analogue)' in category:\n",
    "            main_part = category.split(' (')[0]\n",
    "            suffix = f'({category.split(\"(\")[1]}'\n",
    "            return f'{main_part}\\n{suffix}'\n",
    "        return category\n",
    "    \n",
    "    # Set x-ticks\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([split_category(cat) for cat in categories], \n",
    "                       ha='center',  # Center align\n",
    "                       fontsize=18)  # Changed to 18\n",
    "    \n",
    "    # Set y-ticks and convert to percentages\n",
    "    ax.tick_params(axis='y', labelsize=18)  # Changed to 18\n",
    "    y_ticks = np.arange(0, 1.2, 0.2)\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels([f'{x*100:.0f}%' for x in y_ticks])\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add legend inside the plot in the upper right corner\n",
    "    ax.legend(fontsize=20, loc='upper right')\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    colors = [\n",
    "        '#A1C8F3',  # light blue/periwinkle\n",
    "        '#B8F1EF',  # light cyan/aqua\n",
    "        '#FFB381',  # salmon/peach\n",
    "    ]\n",
    "    \n",
    "    # Example save path\n",
    "    save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/7.0_IC_comparison_exp_sim_aug_plot.png\"\n",
    "    \n",
    "    # Call with dummy data\n",
    "    #plot_comparison_bars({}, colors, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b721c3c-aca1-471e-adf1-e5bce23d8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa4b70-8efd-445e-a40f-a67e40715e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e36851-f193-44e9-a156-c0ed29e0a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a16e422-0275-4746-b6e0-d108ef98e60f",
   "metadata": {},
   "source": [
    "#### Extracting the data for the plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f708c1-0211-479f-9221-6664f3faac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "\n",
    "def process_pkl_files_new(folder_path, file_type, ranking_method):\n",
    "    pkl_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) \n",
    "                 if f.endswith('.pkl') and file_type in f]\n",
    "    all_rankings = defaultdict(list)\n",
    "    for file_path in pkl_files:\n",
    "        file_data = load_data(file_path)\n",
    "        \n",
    "        for trg_smi, value_list in file_data.items():\n",
    "            for sublist in value_list[0]:\n",
    "                \n",
    "                gen_smi = sublist[0]\n",
    "                tanimoto = sublist[4]\n",
    "                errors = sublist[5]\n",
    "                if errors == 9:  # Check if both errors are 9\n",
    "                    errors = [9, 9]  # Keep it as is\n",
    "                try:\n",
    "                    all_rankings[trg_smi].append((trg_smi, gen_smi, tanimoto, 0, errors[0], errors[1]))\n",
    "                except:\n",
    "                    import IPython; IPython.embed();           \n",
    "    all_rankings = rank_all_molecules(all_rankings, ranking_method)\n",
    "    \n",
    "    return all_rankings\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def rank_all_molecules(all_rankings, ranking_method):\n",
    "    new_rankings = defaultdict(list)\n",
    "    \n",
    "    for trg_smi, molecule_list in all_rankings.items():\n",
    "        molecule_data = []\n",
    "        seen_gen_smiles = set()\n",
    "        \n",
    "        for molecule in molecule_list:\n",
    "            gen_smi = molecule[1]\n",
    "            if gen_smi in seen_gen_smiles:\n",
    "                continue\n",
    "            seen_gen_smiles.add(gen_smi)\n",
    "            \n",
    "            tanimoto = molecule[2]\n",
    "            errors = molecule[4:6]\n",
    "            if errors == (9, 9):  # Check if both errors are 9\n",
    "                errors = [9, 9]  # Keep it as is\n",
    "            molecule_data.append((gen_smi, errors[0], errors[1], tanimoto))\n",
    "        \n",
    "        if not molecule_data:\n",
    "            continue\n",
    "        \n",
    "        molecule_array = np.array(molecule_data, dtype=[('gen_smi', 'U100'), \n",
    "                                                        ('error1', float), ('error2', float), \n",
    "                                                        ('tanimoto', float)])\n",
    "        \n",
    "        if ranking_method == 'HSQC & COSY':\n",
    "            rank1 = molecule_array.argsort(order='error1')\n",
    "            rank2 = molecule_array.argsort(order='error2')\n",
    "            average_ranks = (np.arange(len(rank1))[np.argsort(rank1)] + \n",
    "                             np.arange(len(rank2))[np.argsort(rank2)]) / 2\n",
    "            sorted_indices = average_ranks.argsort()\n",
    "            \n",
    "        elif ranking_method == 'HSQC':\n",
    "            sorted_indices = molecule_array.argsort(order='error1')\n",
    "        elif ranking_method == 'COSY':\n",
    "            sorted_indices = molecule_array.argsort(order='error2')\n",
    "        else:\n",
    "            raise ValueError(\"Invalid ranking method. Choose 'HSQC & COSY', 'HSQC', or 'COSY'.\")\n",
    "        \n",
    "        for new_rank, i in enumerate(sorted_indices):\n",
    "            gen_smi = molecule_array['gen_smi'][i]\n",
    "            tanimoto = molecule_array['tanimoto'][i]\n",
    "            error1 = molecule_array['error1'][i]\n",
    "            error2 = molecule_array['error2'][i]\n",
    "            \n",
    "            new_rankings[trg_smi].append((trg_smi, gen_smi, tanimoto, new_rank, error1, error2))\n",
    "    \n",
    "    return new_rankings\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data[\"results_dict_bl_ZINC\"]\n",
    "\n",
    "def process_experimental_data(base_folder_path, ic_folder_path, analogue_folder_path):\n",
    "    \"\"\"\n",
    "    Process experimental data from different sources and prepare it for plotting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_folder_path : str\n",
    "        Path to the folder containing base experiment data (without IC)\n",
    "    ic_folder_path : str\n",
    "        Path to the folder containing IC experiment data\n",
    "    analogue_folder_path : str\n",
    "        Path to the folder containing analogue experiment data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with processed data ready for plotting\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    ranking_method = \"HSQC\"\n",
    "    file_types = [\"exp_sim_data\", \"sim_sim_data\"]\n",
    "    \n",
    "    plot_data = {}\n",
    "    \n",
    "    # Process IC experiments\n",
    "    for file_type in file_types:\n",
    "        IC_rankings = process_pkl_files_new(ic_folder_path, file_type, ranking_method)\n",
    "        IC_rankings, _ = exp_func.deduplicate_smiles_from_ranking(IC_rankings)\n",
    "        IC_rankings, _ = exp_func.filter_rankings_by_molecular_formula(IC_rankings)\n",
    "        accuracies = exp_func.calculate_top_k_accuracy(IC_rankings, k_range=[1, 3, 10])\n",
    "        accuracies = [round(acc, 3) for acc in accuracies][:3]\n",
    "\n",
    "        if file_type == \"exp_sim_data\":\n",
    "            plot_data['IC Experimental (target)'] = accuracies\n",
    "        else:\n",
    "            plot_data['IC Simulated (target)'] = accuracies\n",
    "            \n",
    "    # Process base experiments (without IC)\n",
    "    for file_type in file_types:\n",
    "        if file_type == \"exp_sim_data\":\n",
    "            input_dict = {\"exp_sim_data\" : base_pkl_dicts[\"exp_sim_data\"]}\n",
    "            rankings = exp_func.process_pkl_files_BL(input_dict, ranking_method)\n",
    "            accuracies = exp_func.calculate_top_k_accuracy_BL(rankings[\"exp_sim_data\"],k_range=[1, 3, 10])\n",
    "            accuracies = [round(acc, 3) for acc in accuracies][:3]\n",
    "            plot_data['BL Experimental (target)'] = accuracies\n",
    "\n",
    "        elif file_type == \"sim_sim_data\":\n",
    "            input_dict = {\"sim_sim_data\" : base_pkl_dicts[\"sim_sim_data\"]}\n",
    "            rankings = exp_func.process_pkl_files_BL(input_dict, ranking_method)\n",
    "            accuracies = exp_func.calculate_top_k_accuracy_BL(rankings[\"sim_sim_data\"],k_range=[1, 3, 10])       \n",
    "            accuracies = [round(acc, 3) for acc in accuracies][:3]\n",
    "            plot_data['BL Simulated (target)'] = accuracies\n",
    "\n",
    "            \n",
    "    # Process analogue experiments\n",
    "    for file_type in file_types:\n",
    "        analogue_rankings = process_pkl_files_new(analogue_folder_path, file_type, ranking_method)\n",
    "        analogue_rankings, _ = exp_func.deduplicate_smiles_from_ranking(analogue_rankings)\n",
    "        analogue_rankings, _ = exp_func.filter_rankings_by_molecular_formula(analogue_rankings)\n",
    "        accuracies = exp_func.calculate_top_k_accuracy(analogue_rankings, k_range=[1, 3, 10])\n",
    "        accuracies = [round(acc, 3) for acc in accuracies][:3]\n",
    "        \n",
    "        if file_type == \"exp_sim_data\":\n",
    "            plot_data['IC Experimental (analogue)'] = accuracies\n",
    "        else:\n",
    "            plot_data['IC Simulated (analogue)'] = accuracies\n",
    "            \n",
    "    return plot_data\n",
    "\n",
    "def reorder_data_dict(data_dict):\n",
    "    \"\"\"\n",
    "    Reorders the data dictionary to group simulated and experimental results together.\n",
    "    \"\"\"\n",
    "    # Define the desired order\n",
    "    desired_order = [\n",
    "        'BL Simulated (target)',\n",
    "        'IC Simulated (target)',\n",
    "        'IC Simulated (analogue)',\n",
    "        'BL Experimental (target)',\n",
    "        'IC Experimental (target)',\n",
    "        'IC Experimental (analogue)'\n",
    "    ]\n",
    "    \n",
    "    # Create new ordered dictionary\n",
    "    ordered_dict = {key: data_dict[key] for key in desired_order if key in data_dict}\n",
    "    \n",
    "    return ordered_dict\n",
    "\n",
    "# Helper functions remain the same as in previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d3733-0b35-4756-b6f5-a5ee31af1a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your folder paths\n",
    "base_folder = \"\"\n",
    "ic_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1/\"\n",
    "base_pkl_dicts = {\n",
    "        \"sim_sim_data\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1_baseline/8.0_sim_real_data_before_FT_MMTi_v0.pkl\",\n",
    "        \"exp_sim_data\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1_baseline/8.3_real_data_before_FT_MMTi_v0.pkl\"\n",
    "        }    \n",
    "analogue_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/test_on_aug_data_34_v3/\"\n",
    "\n",
    "# Process the data\n",
    "data = process_experimental_data(base_pkl_dicts, ic_folder, analogue_folder)\n",
    "data = reorder_data_dict(data)\n",
    "# Plot with your color scheme\n",
    "colors = [\n",
    "    '#A1C8F3',  # light blue/periwinkle\n",
    "    '#FFB381',  # salmon/peach\n",
    "    '#8BE5A0',  # mint green\n",
    "    #'#FF9D9A',  # coral pink\n",
    "    #'#D1B9FE',  # lavender\n",
    "    #'#DEBA9A',  # beige/tan\n",
    "]\n",
    "save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/7.0_IC_comparison_exp_sim_aug_plot.png\"\n",
    "\n",
    "plot_comparison_bars( data_dict=data,     colors=colors,     save_path=save_path,    figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d67100-1274-430a-a653-eb60bd8cad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb0bc4-afa2-4bca-a60a-33571715c111",
   "metadata": {},
   "source": [
    "#### Extract Top 1 and top 3 correct Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2624622-cfea-48fd-b917-f8a2116441a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_correct_smiles_analogues(analogue_folder_path, file_type=\"exp_sim_data\", ranking_method=\"HSQC\"):\n",
    "    \"\"\"\n",
    "    Extract SMILES of molecules that are correct matches in top 1 and top 3 rankings\n",
    "    for experimental analogues.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    analogue_folder_path : str\n",
    "        Path to the folder containing analogue experiment data\n",
    "    file_type : str\n",
    "        Type of file to process ('exp_sim_data' or 'sim_sim_data')\n",
    "    ranking_method : str\n",
    "        Method used for ranking ('HSQC', 'COSY', or 'HSQC & COSY')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (correct_top1_pairs, correct_top3_pairs) where each is a list of tuples containing\n",
    "        (target_smiles, generated_smiles, rank) where rank indicates which position (1,2,3)\n",
    "        had the correct match\n",
    "    \"\"\"\n",
    "    # Process the rankings\n",
    "    analogue_rankings = process_pkl_files_new(analogue_folder_path, file_type, ranking_method)\n",
    "    \n",
    "    # Deduplicate and filter rankings\n",
    "    analogue_rankings, _ = exp_func.deduplicate_smiles_from_ranking(analogue_rankings)\n",
    "    analogue_rankings, _ = exp_func.filter_rankings_by_molecular_formula(analogue_rankings)\n",
    "    \n",
    "    correct_top1_pairs = []\n",
    "    correct_top3_pairs = []\n",
    "    \n",
    "    # For each target molecule\n",
    "    for target_smi, rankings in analogue_rankings.items():\n",
    "        # Sort rankings by rank\n",
    "        sorted_rankings = sorted(rankings, key=lambda x: x[3])  # x[3] is the rank\n",
    "        \n",
    "        # Check top 1 match\n",
    "        if sorted_rankings:\n",
    "            top1_gen_smi = sorted_rankings[0][1]  # x[1] is generated SMILES\n",
    "            if top1_gen_smi == target_smi:  # Only append if it's a correct match\n",
    "                correct_top1_pairs.append((target_smi, top1_gen_smi, 1))\n",
    "        \n",
    "        # Check each of the top 3 matches individually\n",
    "        for idx, ranking in enumerate(sorted_rankings[:3], 1):  # idx will be 1, 2, or 3\n",
    "            gen_smi = ranking[1]\n",
    "            if gen_smi == target_smi:  # If we find a match at any position\n",
    "                correct_top3_pairs.append((target_smi, gen_smi, idx))\n",
    "    \n",
    "    return correct_top1_pairs, correct_top3_pairs\n",
    "\n",
    "def save_correct_smiles_to_file(smiles_pairs, output_path, include_rank=False):\n",
    "    \"\"\"\n",
    "    Save correct SMILES pairs to a text file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    smiles_pairs : list\n",
    "        List of (target_smiles, generated_smiles, rank) tuples that are correct matches\n",
    "    output_path : str\n",
    "        Path where to save the file\n",
    "    include_rank : bool\n",
    "        If True, includes which position (1,2,3) had the correct match\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        if include_rank:\n",
    "            f.write(\"SMILES\\tRank\\n\")\n",
    "            for target_smi, _, rank in smiles_pairs:  # We can use either SMILES since they're identical\n",
    "                f.write(f\"{target_smi}\\t{rank}\\n\")\n",
    "        else:\n",
    "            f.write(\"SMILES\\n\")\n",
    "            for target_smi, _, _ in smiles_pairs:\n",
    "                f.write(f\"{target_smi}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d65058-a9f3-4483-87c0-8c1ce6bb2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### with Analogues\n",
    "# Example usage:\n",
    "\n",
    "analogue_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/test_on_aug_data_34_v3/\"\n",
    "\n",
    "# Extract only correct SMILES matches\n",
    "correct_top1_pairs, correct_top3_pairs = extract_correct_smiles_analogues(\n",
    "    analogue_folder,\n",
    "    file_type=\"exp_sim_data\",\n",
    "    ranking_method=\"HSQC\"\n",
    ")\n",
    "\n",
    "# Save to files (only correct matches)\n",
    "# For top 1, we don't need the rank\n",
    "save_correct_smiles_to_file(correct_top1_pairs, \"correct_top1_experimental_analogues.txt\", include_rank=False)\n",
    "# For top 3, we might want to know which position had the match\n",
    "save_correct_smiles_to_file(correct_top3_pairs, \"correct_top3_experimental_analogues.txt\", include_rank=True)\n",
    "\n",
    "# Optional: Print some statistics\n",
    "print(f\"Number of correct top 1 matches: {len(correct_top1_pairs)}\")\n",
    "print(f\"Number of correct top 3 matches: {len(correct_top3_pairs)}\")\n",
    "print(\"\\nBreakdown of top 3 matches by position:\")\n",
    "for rank in [1, 2, 3]:\n",
    "    count = sum(1 for _, _, r in correct_top3_pairs if r == rank)\n",
    "    print(f\"Position {rank}: {count} matches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33a64a-a93c-41be-9e3b-d0d10e0f62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc6c99-31fe-44b1-a1a4-c034a44e01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "\n",
    "analogue_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1/\"\n",
    "\n",
    "# Extract only correct SMILES matches\n",
    "correct_top1_pairs, correct_top3_pairs = extract_correct_smiles_analogues(\n",
    "    analogue_folder,\n",
    "    file_type=\"exp_sim_data\",\n",
    "    ranking_method=\"HSQC\"\n",
    ")\n",
    "\n",
    "# Save to files (only correct matches)\n",
    "# For top 1, we don't need the rank\n",
    "save_correct_smiles_to_file(correct_top1_pairs, \"correct_top1_experimental_analogues.txt\", include_rank=False)\n",
    "# For top 3, we might want to know which position had the match\n",
    "save_correct_smiles_to_file(correct_top3_pairs, \"correct_top3_experimental_analogues.txt\", include_rank=True)\n",
    "\n",
    "\n",
    "# Optional: Print some statistics\n",
    "print(f\"Number of correct top 1 matches: {len(correct_top1_pairs)}\")\n",
    "print(f\"Number of correct top 3 matches: {len(correct_top3_pairs)}\")\n",
    "print(\"\\nBreakdown of top 3 matches by position:\")\n",
    "for rank in [1, 2, 3]:\n",
    "    count = sum(1 for _, _, r in correct_top3_pairs if r == rank)\n",
    "    print(f\"Position {rank}: {count} matches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bd4f5-2bf5-4af1-bf10-c72c6571dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOCC1)CC2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f71bbf-56bb-4661-be51-3c2d11ca63c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6369ef9-2c44-4627-a651-89efba55a9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf1697-af20-434f-b01d-42a898650bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4ce6f-1edf-433c-b25b-d6ff0248ea96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd755da1-b045-46b2-a4fe-a821b8774fd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7.0 Simulated, ACD, Experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06920df-75a6-44bd-be5f-48ef5f6c8222",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5aeb4-343f-4476-ae10-1fd59659fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "\n",
    "colors = [\n",
    "    '#E57373', '#A2A37E', '#64B689', '#4DA6A9', '#5C95CC', '#9574D0', '#EB6CC2'\n",
    "]\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data[\"results_dict_bl_ZINC\"]\n",
    "\n",
    "\n",
    "def process_pkl_files_new(folder_path, file_type, ranking_method):\n",
    "    pkl_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) \n",
    "                 if f.endswith('.pkl') and file_type in f]\n",
    "    all_rankings = defaultdict(list)\n",
    "    for file_path in pkl_files:\n",
    "        file_data = load_data(file_path)\n",
    "        \n",
    "        for trg_smi, value_list in file_data.items():\n",
    "            for sublist in value_list[0]:\n",
    "                \n",
    "                gen_smi = sublist[0]\n",
    "                tanimoto = sublist[4]\n",
    "                errors = sublist[5]\n",
    "                if errors == 9:  # Check if both errors are 9\n",
    "                    errors = [9, 9]  # Keep it as is\n",
    "                try:\n",
    "                    all_rankings[trg_smi].append((trg_smi, gen_smi, tanimoto, 0, errors[0], errors[1]))\n",
    "                except:\n",
    "                    import IPython; IPython.embed();           \n",
    "    all_rankings = rank_all_molecules(all_rankings, ranking_method)\n",
    "    \n",
    "    return all_rankings\n",
    "\n",
    "\n",
    "def calculate_top_k_accuracy(all_rankings, k_range=[1, 3, 5, 10, 20]):\n",
    "    accuracies = []\n",
    "    total_molecules = len(all_rankings)\n",
    "    for k in k_range:\n",
    "        correct_count = sum(\n",
    "            any(molecule[2] == 1 for molecule in rankings[:k])\n",
    "            for rankings in all_rankings.values()\n",
    "        )\n",
    "        accuracy = correct_count / total_molecules\n",
    "        accuracies.append(accuracy)\n",
    "    correct_count = sum(\n",
    "        any(molecule[2] == 1 for molecule in rankings[:])\n",
    "        for rankings in all_rankings.values()\n",
    "    )\n",
    "    accuracy = correct_count / total_molecules\n",
    "    accuracies.append(accuracy)    \n",
    "    return accuracies\n",
    "\"\"\"\n",
    "def count_molecules_with_sim_rank_one(all_rankings):\n",
    "    count = sum(\n",
    "        any(molecule[2] == 1.0 for molecule in rankings)\n",
    "        for rankings in all_rankings.values()\n",
    "    )\n",
    "    return count\"\"\"\n",
    "\n",
    "def plot_top_k_accuracy(accuracies, data_type, model_type, ranking_method, sim_rank_one_count, save_path=None, total_samples=34):\n",
    "    fontsize = 30\n",
    "    k_values = [1, 3, 5, 10, 20]\n",
    "    labels = [f'Top {k}' for k in k_values] + ['Total']\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))  # Slightly wider to accommodate longer labels\n",
    "    bars = plt.bar(range(len(labels)), accuracies, color=colors[:len(labels)])\n",
    "    \n",
    "    plt.ylabel('Accuracy', fontsize=fontsize)\n",
    "    plt.title(f'{data_type} Data and {ranking_method} Ranking', fontsize=fontsize+4)\n",
    "    \n",
    "    plt.xticks(range(len(labels)), labels, fontsize=fontsize, rotation=0, ha='center')\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.ylim(0, 1.1)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        correct_samples = int(height * total_samples)\n",
    "        \n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.2f}',\n",
    "                 ha='center', va='bottom', fontsize=fontsize)\n",
    "        \n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "                 f'{correct_samples}',\n",
    "                 ha='center', va='center', fontsize=fontsize, color='black')\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def get_molecular_formula(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return Chem.rdMolDescriptors.CalcMolFormula(mol)\n",
    "\n",
    "def filter_rankings_by_molecular_formula(all_rankings):\n",
    "    filtered_rankings = defaultdict(list)\n",
    "    filtered_out_rankings = defaultdict(list)\n",
    "\n",
    "    for key, rankings in all_rankings.items():\n",
    "        filtered_rankings_for_key = []\n",
    "        filtered_out_rankings_for_key = []\n",
    "        \n",
    "        for ranking in rankings:\n",
    "            if len(ranking) >= 2:\n",
    "                smiles1 = ranking[0]\n",
    "                smiles2 = ranking[1]\n",
    "                formula1 = get_molecular_formula(smiles1)\n",
    "                formula2 = get_molecular_formula(smiles2)\n",
    "                \n",
    "                if formula1 is not None and formula2 is not None and formula1 == formula2:\n",
    "                    filtered_rankings_for_key.append(ranking)\n",
    "                else:\n",
    "                    filtered_out_rankings_for_key.append(ranking)\n",
    "        \n",
    "        if filtered_rankings_for_key:\n",
    "            filtered_rankings[key] = filtered_rankings_for_key\n",
    "        \n",
    "        if filtered_out_rankings_for_key:\n",
    "            filtered_out_rankings[key] = filtered_out_rankings_for_key\n",
    "\n",
    "    return filtered_rankings, filtered_out_rankings\n",
    "\n",
    "\n",
    "def deduplicate_smiles_from_ranking(all_rankings):\n",
    "    def canonicalize(smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return Chem.MolToSmiles(mol) if mol else smiles\n",
    "        #return Chem.MolToSmiles(mol, isomericSmiles=False, canonical=True) if mol else smiles\n",
    "\n",
    "    deduplicated_rankings = {}\n",
    "    removed_smiles = {}\n",
    "\n",
    "    for key, rankings in all_rankings.items():\n",
    "        seen_canonical = set()\n",
    "        deduplicated_rankings[key] = []\n",
    "        removed_smiles[key] = []\n",
    "\n",
    "        for ranking in rankings:\n",
    "            canonical_smiles = canonicalize(ranking[1])\n",
    "            if canonical_smiles not in seen_canonical:\n",
    "                seen_canonical.add(canonical_smiles)\n",
    "                deduplicated_rankings[key].append(ranking)\n",
    "            else:\n",
    "                removed_smiles[key].append(ranking[1])\n",
    "\n",
    "    return deduplicated_rankings, removed_smiles\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def main_normal():\n",
    "    folder_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1/\"\n",
    "    #folder_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/test_on_aug_data_34_v5/\"\n",
    "    model_type = \"MMT\"\n",
    "    #ranking_methods = [\"COSY\", \"HSQC\", \"HSQC & COSY\"]\n",
    "    ranking_methods = [ \"HSQC\"]\n",
    "    #file_types = [\"exp_sim_data\", \"sim_sim_data\", \"ACD_sim_data\", ]\n",
    "    file_types = [\"exp_sim_data\", \"sim_sim_data\"]\n",
    "\n",
    "    data_type_map = {\n",
    "        \"exp_sim_data\": \"Experimental\",\n",
    "        \"sim_sim_data\": \"Our Simulated\",\n",
    "     #   \"ACD_sim_data\": \"ACD Simulated\",\n",
    "    }\n",
    "    filtered_out = []\n",
    "    all_rankings_list = []\n",
    "    for ranking_method in ranking_methods:\n",
    "        for file_type in file_types:\n",
    "            all_rankings = process_pkl_files_new(folder_path, file_type, ranking_method)\n",
    "            #import IPython; IPython.embed();\n",
    "            all_rankings, removed_smiles = exp_func.deduplicate_smiles_from_ranking(all_rankings)\n",
    "            all_rankings, filtered_out_rankings = filter_rankings_by_molecular_formula(all_rankings)\n",
    "            #filtered_out.append(filtered_out_rankings)\n",
    "            all_rankings_list.append(all_rankings)\n",
    "            print(\"second_breakout\")\n",
    "            #import IPython; IPython.embed();\n",
    "\n",
    "            accuracies = calculate_top_k_accuracy(all_rankings)\n",
    "            sim_rank_one_count = count_molecules_with_sim_rank_one(all_rankings)\n",
    "\n",
    "            data_type = data_type_map[file_type]\n",
    "            save_path = f\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/top_k_accuracy_MMTi_{file_type}_{ranking_method}_va_FINAL.png\"\n",
    "            #save_path = f\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/top_k_accuracy_MMT_{file_type}_{ranking_method}_v10.png\"\n",
    "\n",
    "            plot_top_k_accuracy(accuracies, data_type, model_type, ranking_method, sim_rank_one_count, save_path, total_samples=len(all_rankings.keys()))\n",
    "\n",
    "            print(f\"Completed plot for {ranking_method} - {data_type}\")\n",
    "    return all_rankings_list, filtered_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e4a2d-56d9-4b4c-8841-d7e64ced0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors\n",
    "from IPython.display import display, SVG\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data[\"results_dict_bl_ZINC\"]\n",
    "\n",
    "\n",
    "def rank_molecules_in_file(file_data, ranking_method):\n",
    "    molecule_data = []\n",
    "    for trg_smi, value_list in file_data.items():\n",
    "        for sublist in value_list[0]:\n",
    "            gen_smi = sublist[0]\n",
    "            tanimoto = sublist[4]\n",
    "            errors = sublist[5]\n",
    "            if errors == 9:\n",
    "                errors = [9,9] ### Necessary if it doesn't manage to calculate HSQC or COSY to calculate the errors\n",
    "                                ## Basically put it last then\n",
    "            molecule_data.append((trg_smi, gen_smi, errors[0], errors[1], tanimoto))\n",
    "\n",
    "    if not molecule_data:\n",
    "        return []\n",
    "\n",
    "    molecule_array = np.array(molecule_data, dtype=[('trg_smi', 'U100'), ('gen_smi', 'U100'), \n",
    "                                                    ('error1', float), ('error2', float), \n",
    "                                                    ('tanimoto', float)])\n",
    "    \n",
    "    if ranking_method == 'HSQC & COSY':\n",
    "        rank1 = molecule_array.argsort(order='error1')\n",
    "        rank2 = molecule_array.argsort(order='error2')\n",
    "        average_ranks = (np.arange(len(rank1))[np.argsort(rank1)] + \n",
    "                         np.arange(len(rank2))[np.argsort(rank2)]) / 2\n",
    "        sorted_indices = average_ranks.argsort()\n",
    "        \n",
    "    elif ranking_method == 'HSQC':\n",
    "        sorted_indices = molecule_array.argsort(order='error1')\n",
    "    elif ranking_method == 'COSY':\n",
    "        sorted_indices = molecule_array.argsort(order='error2')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid ranking method. Choose 'HSQC & COSY', 'HSQC', or 'COSY'.\")\n",
    "\n",
    "    sorted_molecules = [(molecule_array['trg_smi'][i], \n",
    "                         molecule_array['gen_smi'][i],\n",
    "                         molecule_array[\"tanimoto\"][i],\n",
    "                         new_rank,  # Use index as rank\n",
    "                         molecule_array['error1'][i], \n",
    "                         molecule_array['error2'][i]) \n",
    "                        for new_rank, i  in enumerate(sorted_indices)]\n",
    "    return sorted_molecules\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def rank_all_molecules(all_rankings, ranking_method):\n",
    "    new_rankings = defaultdict(list)\n",
    "    \n",
    "    for trg_smi, molecule_list in all_rankings.items():\n",
    "        molecule_data = []\n",
    "        seen_gen_smiles = set()\n",
    "        \n",
    "        for molecule in molecule_list:\n",
    "            gen_smi = molecule[1]\n",
    "            if gen_smi in seen_gen_smiles:\n",
    "                continue\n",
    "            seen_gen_smiles.add(gen_smi)\n",
    "            \n",
    "            tanimoto = molecule[2]\n",
    "            errors = molecule[4:6]\n",
    "            if errors == (9, 9):  # Check if both errors are 9\n",
    "                errors = [9, 9]  # Keep it as is\n",
    "            molecule_data.append((gen_smi, errors[0], errors[1], tanimoto))\n",
    "        \n",
    "        if not molecule_data:\n",
    "            continue\n",
    "        \n",
    "        molecule_array = np.array(molecule_data, dtype=[('gen_smi', 'U100'), \n",
    "                                                        ('error1', float), ('error2', float), \n",
    "                                                        ('tanimoto', float)])\n",
    "        \n",
    "        if ranking_method == 'HSQC & COSY':\n",
    "            rank1 = molecule_array.argsort(order='error1')\n",
    "            rank2 = molecule_array.argsort(order='error2')\n",
    "            average_ranks = (np.arange(len(rank1))[np.argsort(rank1)] + \n",
    "                             np.arange(len(rank2))[np.argsort(rank2)]) / 2\n",
    "            sorted_indices = average_ranks.argsort()\n",
    "            \n",
    "        elif ranking_method == 'HSQC':\n",
    "            sorted_indices = molecule_array.argsort(order='error1')\n",
    "        elif ranking_method == 'COSY':\n",
    "            sorted_indices = molecule_array.argsort(order='error2')\n",
    "        else:\n",
    "            raise ValueError(\"Invalid ranking method. Choose 'HSQC & COSY', 'HSQC', or 'COSY'.\")\n",
    "        \n",
    "        for new_rank, i in enumerate(sorted_indices):\n",
    "            gen_smi = molecule_array['gen_smi'][i]\n",
    "            tanimoto = molecule_array['tanimoto'][i]\n",
    "            error1 = molecule_array['error1'][i]\n",
    "            error2 = molecule_array['error2'][i]\n",
    "            \n",
    "            new_rankings[trg_smi].append((trg_smi, gen_smi, tanimoto, new_rank, error1, error2))\n",
    "    \n",
    "    return new_rankings\n",
    "\n",
    "\n",
    "def prepare_mol(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    AllChem.Compute2DCoords(mol)\n",
    "    return mol\n",
    "\n",
    "def get_mol_weight(mol):\n",
    "    return round(Descriptors.ExactMolWt(mol), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683f864-cede-4344-862f-c2f26f2e632a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_rankings_list, filtered_out = main_normal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6aef7-1b17-41fe-939b-ed57cee2f6fb",
   "metadata": {},
   "source": [
    "#### Plot baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e1edd-148c-40f9-ba1f-b30cd3c6b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "colors = [\n",
    "    '#E57373', '#A2A37E', '#64B689', '#4DA6A9', '#5C95CC', '#9574D0', '#EB6CC2'\n",
    "]\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data[\"results_dict_bl_ZINC\"]\n",
    "\n",
    "def rank_molecules(file_data, ranking_method):\n",
    "    all_rankings = {}\n",
    "    for trg_smi, value_list in file_data.items():\n",
    "        molecule_data = []\n",
    "        for sublist in value_list[0]:\n",
    "            try:\n",
    "                gen_smi = sublist[0]\n",
    "                tanimoto = sublist[4]\n",
    "                errors = sublist[5]\n",
    "                molecule_data.append((gen_smi, errors[0], errors[1], tanimoto))\n",
    "            except:\n",
    "                print(f\"Error processing sublist for {trg_smi}: {sublist}\")\n",
    "                continue\n",
    "\n",
    "        if not molecule_data:\n",
    "            continue\n",
    "\n",
    "        molecule_array = np.array(molecule_data, dtype=[('gen_smi', 'U100'), \n",
    "                                                        ('error1', float), ('error2', float), \n",
    "                                                        ('tanimoto', float)])\n",
    "        \n",
    "        if ranking_method == 'HSQC & COSY':\n",
    "            rank1 = molecule_array.argsort(order='error1')\n",
    "            rank2 = molecule_array.argsort(order='error2')\n",
    "            average_ranks = (np.arange(len(rank1))[np.argsort(rank1)] + \n",
    "                             np.arange(len(rank2))[np.argsort(rank2)]) / 2\n",
    "            sorted_indices = average_ranks.argsort()\n",
    "        elif ranking_method == 'HSQC':\n",
    "            sorted_indices = molecule_array.argsort(order='error1')\n",
    "        elif ranking_method == 'COSY':\n",
    "            sorted_indices = molecule_array.argsort(order='error2')\n",
    "        else:\n",
    "            raise ValueError(\"Invalid ranking method. Choose 'HSQC & COSY', 'HSQC', or 'COSY'.\")\n",
    "\n",
    "        sorted_molecules = [(trg_smi,\n",
    "                             molecule_array['gen_smi'][i],\n",
    "                             molecule_array[\"tanimoto\"][i],\n",
    "                             new_rank,  # Use index as rank\n",
    "                             molecule_array['error1'][i], \n",
    "                             molecule_array['error2'][i]) \n",
    "                            for  new_rank, i in enumerate(sorted_indices)]\n",
    "        \n",
    "        all_rankings[trg_smi] = sorted_molecules\n",
    "    \n",
    "    return all_rankings\n",
    "\"\"\"\n",
    "def process_pkl_files(file_paths_dict, ranking_method):\n",
    "    all_rankings = {}\n",
    "    \n",
    "    for data_type, file_path in file_paths_dict.items():\n",
    "        file_data = load_data(file_path)\n",
    "        ranked_molecules = rank_molecules_in_file(file_data, ranking_method)\n",
    "        all_rankings[data_type] = defaultdict(list)\n",
    "        for molecule in ranked_molecules:\n",
    "            trg_smi = molecule[0]\n",
    "            all_rankings[data_type][trg_smi].append(molecule)\n",
    "    \n",
    "        # Sort rankings for each target SMILES\n",
    "        for trg_smi in all_rankings[data_type]:\n",
    "            all_rankings[data_type][trg_smi].sort(key=lambda x: x[3])  # Sort by rank\n",
    "    \n",
    "    return all_rankings\n",
    "    \n",
    "def calculate_top_k_accuracy(all_rankings, k_range=[1, 3, 5, 10, 20]):\n",
    "    accuracies = []\n",
    "    total_molecules = len(all_rankings)\n",
    "    for k in k_range:\n",
    "        correct_count = sum(\n",
    "            any(molecule[2] == 1.0 for molecule in rankings[:k])\n",
    "            for rankings in all_rankings.values()\n",
    "        )\n",
    "        accuracy = correct_count / total_molecules\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "    \n",
    "def process_pkl_files_BL(file_paths_dict, ranking_method):\n",
    "    all_rankings = {}\n",
    "    for data_type, file_path in file_paths_dict.items():\n",
    "        file_data = load_data_results(file_path)\n",
    "        all_rankings[data_type] = rank_molecules(file_data, ranking_method)\n",
    "        \n",
    "    return all_rankings\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def plot_top_k_accuracy(accuracies, data_type, model_type, ranking_method, sim_rank_one_count, save_path=None, total_samples=34):\n",
    "    fontsize = 30\n",
    "    k_values = [1, 3, 5, 10, 20]\n",
    "    labels = [f'Top {k}' for k in k_values] + ['Total']\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))  # Slightly wider to accommodate longer labels\n",
    "    bars = plt.bar(range(len(labels)), accuracies + [sim_rank_one_count / total_samples], color=colors[:len(labels)])\n",
    "    \n",
    "    plt.ylabel('Accuracy', fontsize=fontsize)\n",
    "    plt.title(f'{data_type} Data and {ranking_method} Ranking', fontsize=fontsize+4)\n",
    "    \n",
    "    plt.xticks(range(len(labels)), labels, fontsize=fontsize, rotation=0, ha='center')\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.ylim(0, 1.1)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        correct_samples = int(height * total_samples)\n",
    "        \n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.2f}',\n",
    "                 ha='center', va='bottom', fontsize=fontsize)\n",
    "        \n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "                 f'{correct_samples}',\n",
    "                 ha='center', va='center', fontsize=fontsize, color='black')\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "def main_BL():\n",
    "    #folder_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1_baseline/\"\n",
    "    model_type = \"MMT\"\n",
    "    ranking_methods = [\"COSY\", \"HSQC\", \"HSQC & COSY\"]\n",
    "    file_types = [\"sim_sim_data\", \"ACD_sim_data\", \"exp_sim_data\"]\n",
    "    \n",
    "    \n",
    "    file_paths_dict = {\n",
    "        \"sim_sim_data\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1_baseline/8.0_sim_real_data_before_FT_MMTi_v0.pkl\",\n",
    "        \"ACD_sim_data\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1_baseline/8.2_simACD_real_data_before_FT_MMTi_v0.pkl\",\n",
    "        \"exp_sim_data\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_a1_baseline/8.3_real_data_before_FT_MMTi_v0.pkl\"\n",
    "    }    \n",
    "    \n",
    "    #file_paths_dict = {\n",
    "    #    \"sim_sim_data\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_d1_baseline/8.0_sim_real_data_before_FT_MMT_v0.pkl\",\n",
    "    #    \"ACD_sim_data\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_d1_baseline/8.2_simACD_real_data_before_FT_MMT_v0.pkl\",\n",
    "    #    \"exp_sim_data\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_d1_baseline/8.3_real_data_before_FT_MMT_v0.pkl\"\n",
    "    #}    \n",
    "    \n",
    "    data_type_map = {\n",
    "        \"sim_sim_data\": \"Our Simulated\",\n",
    "        \"ACD_sim_data\": \"ACD Simulated\",\n",
    "        \"exp_sim_data\": \"Experimental\"\n",
    "    }\n",
    "    for ranking_method in ranking_methods:\n",
    "        all_rankings = process_pkl_files_BL(file_paths_dict, ranking_method)\n",
    "        \n",
    "        for data_type, rankings in all_rankings.items():\n",
    "            #import IPython; IPython.embed();\n",
    "            accuracies = calculate_top_k_accuracy(rankings)\n",
    "            sim_rank_one_count = count_molecules_with_sim_rank_one(rankings)\n",
    "            \n",
    "            save_path = f\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/top_k_accuracy_MMTi_baseline_{data_type}_{ranking_method}_FINAL.png\"\n",
    "            #save_path = f\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/top_k_accuracy_MMT_baseline_{data_type}_{ranking_method}_v8.png\"\n",
    "            \n",
    "            plot_top_k_accuracy(accuracies, data_type_map[data_type], model_type, ranking_method, sim_rank_one_count, save_path, total_samples=len(rankings))\n",
    "\n",
    "            print(f\"Completed plot for {ranking_method} - {data_type_map[data_type]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf52332-3542-408b-b464-24838ebacbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_BL()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab303930-3786-4bf6-82ab-c63460fca465",
   "metadata": {},
   "source": [
    "#### Plot all molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64be2b0-04b6-4e0c-8fdd-e59bbf37021e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import Descriptors\n",
    "from math import ceil\n",
    "import os\n",
    "from IPython.display import display, SVG\n",
    "\n",
    "def plot_molecules_from_df(df, smiles_col, id_col, mols_per_row=5, output_folder='molecule_images'):\n",
    "    \"\"\"\n",
    "    Plot molecules from a DataFrame with SMILES and sample ID columns and save images to a folder.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing SMILES and sample ID columns\n",
    "    smiles_col (str): Name of the column containing SMILES strings\n",
    "    id_col (str): Name of the column containing sample IDs\n",
    "    mols_per_row (int): Number of molecules to display per row (default: 5)\n",
    "    output_folder (str): Name of the folder to save images (default: 'molecule_images')\n",
    "    \"\"\"\n",
    "    mols = []\n",
    "    legends = []\n",
    "    \n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        mol = Chem.MolFromSmiles(row[smiles_col])\n",
    "        if mol is not None:\n",
    "            mols.append(mol)\n",
    "            mol_weight = Descriptors.ExactMolWt(mol)\n",
    "            legend = f\"{row[id_col]} | MW: {mol_weight:.2f}\"\n",
    "            legends.append(legend)\n",
    "    \n",
    "    n_rows = ceil(len(mols) / mols_per_row)\n",
    "    \n",
    "    for i in range(n_rows):\n",
    "        start_idx = i * mols_per_row\n",
    "        end_idx = min((i + 1) * mols_per_row, len(mols))\n",
    "        \n",
    "        img = Draw.MolsToGridImage(\n",
    "            mols[start_idx:end_idx],\n",
    "            molsPerRow=mols_per_row,\n",
    "            subImgSize=(300, 300),\n",
    "            legends=[legends[j] for j in range(start_idx, end_idx)],\n",
    "            useSVG=True\n",
    "        )\n",
    "        \n",
    "        # Save the SVG image\n",
    "        filename = f'molecules_row_aug_{i+1}.svg'\n",
    "        filepath = os.path.join(output_folder, filename)\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(img.data)\n",
    "        \n",
    "        print(f\"Saved {filename}\")\n",
    "        \n",
    "        # Display the image (optional, comment out if not needed)\n",
    "        display(SVG(img.data))\n",
    "\n",
    "# Example usage:\n",
    "#df = pd.DataFrame({\n",
    "#     'SMILES': ['CCO', 'CC(=O)O', 'c1ccccc1', 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C', 'CCN(CC)CC'],\n",
    "#     'Sample_ID': ['S1', 'S2', 'S3', 'S4', 'S5']\n",
    "# })\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.drawOptions.addAtomIndices = False \n",
    "\n",
    "#df = pd.read_csv(\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/ACD_1H_with_SN_filtered_v3.csv\")\n",
    "df = pd.read_csv(\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/ACD_1H_with_SN_filtered_v3_regio_aug.csv\")\n",
    "\n",
    "output_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/experimental_mol_34\"\n",
    "\n",
    "plot_molecules_from_df(df, 'SMILES_regio_isomers', 'sample-id', output_folder=output_folder)\n",
    "#plot_molecules_from_df(df, 'SMILES', 'sample-id', output_folder=output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635466b9-6064-4031-aeb5-5746cdee7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "def find_duplicate_smiles(df, smiles_col, id_col):\n",
    "    \"\"\"\n",
    "    Find duplicate SMILES in a DataFrame after canonicalization.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing SMILES and sample ID columns\n",
    "    smiles_col (str): Name of the column containing SMILES strings\n",
    "    id_col (str): Name of the column containing sample IDs\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing duplicate SMILES, their IDs, and count\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store canonical SMILES and their corresponding IDs\n",
    "    canonical_smiles_dict = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        smiles = row[smiles_col]\n",
    "        mol_id = row[id_col]\n",
    "        \n",
    "        # Generate canonical SMILES\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            canonical_smiles = Chem.MolToSmiles(mol, canonical=True)\n",
    "            \n",
    "            # Add to dictionary\n",
    "            if canonical_smiles in canonical_smiles_dict:\n",
    "                canonical_smiles_dict[canonical_smiles].append((mol_id, smiles))\n",
    "            else:\n",
    "                canonical_smiles_dict[canonical_smiles] = [(mol_id, smiles)]\n",
    "    \n",
    "    # Filter for duplicates and create a list of results\n",
    "    duplicates = []\n",
    "    for canonical_smiles, id_smiles_list in canonical_smiles_dict.items():\n",
    "        if len(id_smiles_list) > 1:\n",
    "            for mol_id, original_smiles in id_smiles_list:\n",
    "                duplicates.append({\n",
    "                    'Canonical_SMILES': canonical_smiles,\n",
    "                    'Original_SMILES': original_smiles,\n",
    "                    'ID': mol_id,\n",
    "                    'Duplicate_Count': len(id_smiles_list)\n",
    "                })\n",
    "    \n",
    "    # Create a DataFrame from the list of duplicates\n",
    "    duplicates_df = pd.DataFrame(duplicates)\n",
    "    \n",
    "    # Sort by Duplicate_Count (descending) and Canonical_SMILES\n",
    "    duplicates_df = duplicates_df.sort_values(['Duplicate_Count', 'Canonical_SMILES'], ascending=[False, True])\n",
    "    \n",
    "    return duplicates_df\n",
    "\n",
    "# Example usage:\n",
    "df = pd.read_csv(\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/ACD_1H_with_SN_filtered_v3.csv\")\n",
    "duplicate_smiles = find_duplicate_smiles(df, 'SMILES', 'sample-id')\n",
    "print(duplicate_smiles)\n",
    "print(f\"Total number of duplicate entries: {len(duplicate_smiles)}\")\n",
    "print(f\"Number of unique molecules with duplicates: {duplicate_smiles['Canonical_SMILES'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1cfefc-a444-40de-b9f7-30a6b4e5250b",
   "metadata": {},
   "source": [
    "### 7.0 Improvement Cycle on Similar Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a67bb-9603-4ad4-8424-41032380cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Union, Tuple\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def split_dataset(config, chunk_size: int) -> List[pd.DataFrame]:\n",
    "    df = pd.read_csv(config.SGNN_csv_gen_smi)\n",
    "    return [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "\n",
    "def create_chunk_folder(config, idx: int) -> str:\n",
    "    base_dir = config.model_save_dir\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    chunk_folder_name = f\"chunk_{idx:03d}_{current_datetime}\"\n",
    "    chunk_folder_path = os.path.join(base_dir, chunk_folder_name)\n",
    "    \n",
    "    os.makedirs(chunk_folder_path, exist_ok=True)\n",
    "    print(f\"Created folder for chunk {idx}: {chunk_folder_path}\")\n",
    "    \n",
    "    return chunk_folder_path\n",
    "\n",
    "def test_pretrained_model_on_sim_data_before(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, idx):\n",
    "    MW_filter, greedy_full = True, False\n",
    "    \n",
    "    print(\"prepare_data\")\n",
    "    config = prepare_data(config, chunk)\n",
    "    print(\"generate_simulated_data\")\n",
    "    config = generate_simulated_data(config, IR_config)\n",
    "\n",
    "    print(\"load_model_and_data\")\n",
    "    model_MMT, val_dataloader, val_dataloader_multi = load_model_and_data(config, stoi, stoi_MF)\n",
    "\n",
    "    print(\"run_model_analysis\")\n",
    "    prob_dict_results_1c_, results_dict_1c_ = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "    results = test_model_performance(config, model_MMT, val_dataloader, val_dataloader_multi, stoi, itos, stoi_MF, itos_MF)\n",
    "\n",
    "    save_results_before(results, config, idx)\n",
    "\n",
    "    return config\n",
    "\n",
    "def prepare_data(config: Any, chunk: pd.DataFrame) -> Any:\n",
    "    chunk_csv_path = os.path.join(config.pkl_save_folder, \"SGNN_csv_gen_smi.csv\")\n",
    "    chunk.to_csv(chunk_csv_path)\n",
    "    config.SGNN_csv_gen_smi = chunk_csv_path \n",
    "    config.data_size = len(chunk)\n",
    "    return config\n",
    "\n",
    "def generate_simulated_data(config: Any, IR_config: Any) -> Any:\n",
    "    config.execution_type = \"data_generation\"\n",
    "    if config.execution_type == \"data_generation\":\n",
    "        print(\"\\033[1m\\033[31mThis is: data_generation\\033[0m\")\n",
    "        #import IPython; IPython.embed();\n",
    "\n",
    "        config = ex.gen_sim_aug_data(config, IR_config)\n",
    "        backup_config_paths(config)\n",
    "    return config\n",
    "\n",
    "def backup_config_paths(config: Any) -> None:\n",
    "    config.csv_1H_path_SGNN_backup = copy.deepcopy(config.csv_1H_path_SGNN)\n",
    "    config.csv_13C_path_SGNN_backup = copy.deepcopy(config.csv_13C_path_SGNN)\n",
    "    config.csv_HSQC_path_SGNN_backup = copy.deepcopy(config.csv_HSQC_path_SGNN)\n",
    "    config.csv_COSY_path_SGNN_backup = copy.deepcopy(config.csv_COSY_path_SGNN)\n",
    "    config.IR_data_folder_backup = copy.deepcopy(config.IR_data_folder)\n",
    "\n",
    "def save_results_before(results: Dict[str, Any], config: Any, idx: int) -> None:\n",
    "    variables_to_save = {\n",
    "        'avg_tani_bl_ZINC': results['avg_tani_bl_ZINC_'],\n",
    "        'results_dict_greedy_bl_ZINC': results.get('results_dict_greedy_bl_ZINC_'),\n",
    "        'failed_bl_ZINC': results.get('failed_bl_ZINC_'),\n",
    "        'avg_tani_greedy_bl_ZINC': results['avg_tani_greedy_bl_ZINC_'],\n",
    "        'results_dict_ZINC_greedy_bl': results.get('results_dict_ZINC_greedy_bl_'),\n",
    "        'total_results_bl_ZINC': results['total_results_bl_ZINC_'],\n",
    "        'corr_sampleing_prob_bl_ZINC': results['corr_sampleing_prob_bl_ZINC_'],\n",
    "        'results_dict_bl_ZINC': results['results_dict_bl_ZINC_'],\n",
    "    }\n",
    "    save_data_with_datetime_index(variables_to_save, config.pkl_save_folder, \"before_sim_data\", idx)\n",
    "\n",
    "def create_run_folder(chunk_folder, idx):\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_folder_name = f\"run_{idx}_{current_datetime}\"\n",
    "    run_folder_path = os.path.join(chunk_folder, run_folder_name)\n",
    "    \n",
    "    os.makedirs(run_folder_path, exist_ok=True)\n",
    "    print(f\"Created folder for run {idx}: {run_folder_path}\")\n",
    "    \n",
    "    return run_folder_path\n",
    "\n",
    "def fine_tune_model_aug_mol(config, stoi, stoi_MF, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "    config, all_gen_smis, aug_mol_df = generate_augmented_molecules_from_aug_mol(config, chunk, idx)\n",
    "    \n",
    "    config.parent_model_save_dir = config.model_save_dir\n",
    "    config.model_save_dir = config.current_run_folder \n",
    "    \n",
    "    if config.execution_type == \"transformer_improvement\":\n",
    "        print(\"\\033[1m\\033[31mThis is: transformer_improvement, sim_data_gen == TRUE\\033[0m\")\n",
    "        config.training_setup = \"pretraining\"\n",
    "        mtf.run_MMT(config, stoi, stoi_MF)\n",
    "    \n",
    "    config.model_save_dir = config.parent_model_save_dir\n",
    "    #config = ex.update_model_path(config)\n",
    "\n",
    "    return config, aug_mol_df, all_gen_smis\n",
    "\n",
    "\n",
    "def generate_augmented_molecules_from_aug_mol(config, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    ############# THis is just relevant for the augmented molecules #############\n",
    "    chunk.rename(columns={'SMILES': 'SMILES_orig', 'SMILES_regio_isomers': 'SMILES'}, inplace=True)\n",
    "    #############################################################################\n",
    "    \n",
    "    script_dir = os.getcwd()\n",
    "    \n",
    "    base_path = os.path.abspath(os.path.join(script_dir, 'deep-molecular-optimization'))\n",
    "\n",
    "    csv_file_path = f'{base_path}/data/MMP/test_selection_2.csv'\n",
    "    chunk.to_csv(csv_file_path, index=False)\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "    config.data_size = len(chunk)\n",
    "    config.n_samples = config.data_size\n",
    "\n",
    "    config, results_dict_MF = generate_smiles_mf(config)\n",
    "\n",
    "    combined_list_MF = process_generated_smiles(results_dict_MF, config)\n",
    "\n",
    "    all_gen_smis = filter_and_combine_smiles(combined_list_MF)\n",
    "\n",
    "    aug_mol_df = create_augmented_dataframe(all_gen_smis)\n",
    "\n",
    "    config, final_df = ex.blend_aug_with_train_data(config, aug_mol_df)\n",
    "\n",
    "    config = ex.gen_sim_aug_data(config, IR_config)\n",
    "    config.execution_type = \"transformer_improvement\"\n",
    "\n",
    "    return config, all_gen_smis, aug_mol_df\n",
    "\n",
    "\n",
    "def fine_tune_model(config, stoi, stoi_MF, chunk, idx):\n",
    "    \"\"\"\n",
    "    Fine-tune the model on a chunk of data.\n",
    "    \"\"\"\n",
    "    config, aug_mol_df, all_gen_smis = generate_augmented_molecules(config, chunk, idx)\n",
    "    \n",
    "    config.parent_model_save_dir = config.model_save_dir\n",
    "    new_model_save_dir = create_model_save_dir(config.parent_model_save_dir, idx)\n",
    "    config.model_save_dir = new_model_save_dir\n",
    "    \n",
    "    # Fine-tune the model\n",
    "    if config.execution_type == \"transformer_improvement\":\n",
    "        print(\"\\033[1m\\033[31mThis is: transformer_improvement, sim_data_gen == TRUE\\033[0m\")\n",
    "        config.training_setup = \"pretraining\"\n",
    "        mtf.run_MMT(config, stoi, stoi_MF)\n",
    "        \n",
    "    #config = ex.update_model_path(config)\n",
    "    config.model_save_dir = config.parent_model_save_dir\n",
    "    \n",
    "    return config, aug_mol_df, all_gen_smis\n",
    "\n",
    "def generate_augmented_molecules(config, chunk, idx):\n",
    "    #import IPython; IPython.embed();\n",
    "    script_dir = os.getcwd()\n",
    "    \n",
    "    base_path = os.path.abspath(os.path.join(script_dir, 'deep-molecular-optimization'))\n",
    "\n",
    "    csv_file_path = f'{base_path}/data/MMP/test_selection_2.csv'\n",
    "    chunk.to_csv(csv_file_path, index=False)\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "    config.data_size = len(chunk)\n",
    "    config.n_samples = config.data_size\n",
    "\n",
    "    config, results_dict_MF = generate_smiles_mf(config)\n",
    "\n",
    "    combined_list_MF = process_generated_smiles(results_dict_MF, config)\n",
    "\n",
    "    all_gen_smis = filter_and_combine_smiles(combined_list_MF)\n",
    "\n",
    "    aug_mol_df = create_augmented_dataframe(all_gen_smis)\n",
    "\n",
    "    config, final_df = ex.blend_aug_with_train_data(config, aug_mol_df)\n",
    "\n",
    "    config = ex.gen_sim_aug_data(config, IR_config)\n",
    "    config.execution_type = \"transformer_improvement\"\n",
    "\n",
    "    return config, all_gen_smis, aug_mol_df\n",
    "\n",
    "\n",
    "def generate_smiles_mf(config):\n",
    "    print(\"\\033[1m\\033[31mThis is: SMI_generation_MF\\033[0m\")\n",
    "    return ex.SMI_generation_MF(config, stoi, stoi_MF, itos, itos_MF)\n",
    "\n",
    "def process_generated_smiles(results_dict_MF, config):\n",
    "    results_dict_MF = {key: value for key, value in results_dict_MF.items() if not hf.contains_only_nan(value)}\n",
    "    for key, value in results_dict_MF.items():\n",
    "        results_dict_MF[key] = hf.remove_nan_from_list(value)\n",
    "\n",
    "    combined_list_MF, _, _, _ = cv.plot_cluster_MF(results_dict_MF, config)\n",
    "    return combined_list_MF\n",
    "\n",
    "def filter_and_combine_smiles(combined_list_MF):\n",
    "    print(\"\\033[1m\\033[31mThis is: combine_MMT_MF\\033[0m\")\n",
    "    all_gen_smis = combined_list_MF\n",
    "    all_gen_smis = [smiles for smiles in all_gen_smis if smiles != 'NAN']\n",
    "\n",
    "    val_data = pd.read_csv(config.csv_path_val)\n",
    "    all_gen_smis = mrtf.filter_smiles(val_data, all_gen_smis)\n",
    "    return all_gen_smis\n",
    "\n",
    "def create_augmented_dataframe(all_gen_smis):\n",
    "    length_of_list = len(all_gen_smis)\n",
    "    random_number_strings = [f\"GT_{str(i).zfill(7)}\" for i in range(1, length_of_list + 1)]\n",
    "    return pd.DataFrame({'SMILES': all_gen_smis, 'sample-id': random_number_strings})\n",
    "\n",
    "def setup_data_paths(config):\n",
    "    base_path_acd = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/\"\n",
    "    config.csv_1H_path_ACD = f\"{base_path_acd}ACD_1H_with_SN_filtered_v3.csv\"\n",
    "    config.csv_13C_path_ACD = f\"{base_path_acd}ACD_13C_with_SN_filtered_v3.csv\"\n",
    "    config.csv_HSQC_path_ACD = f\"{base_path_acd}ACD_HSQC_with_SN_filtered_v3.csv\"\n",
    "    config.csv_COSY_path_ACD = f\"{base_path_acd}ACD_COSY_with_SN_filtered_v3.csv\"\n",
    "    config.IR_data_folder_ACD = f\"{base_path_acd}IR_spectra\"\n",
    "    \n",
    "    base_path_exp = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/36_Richard_43_dataset/experimenal_data/\"\n",
    "    config.csv_1H_path_exp = f\"{base_path_exp}real_1H_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_13C_path_exp = f\"{base_path_exp}real_13C_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_HSQC_path_exp = f\"{base_path_exp}real_HSQC_with_AZ_SMILES_v3.csv\"\n",
    "    config.csv_COSY_path_exp = f\"{base_path_exp}real_COSY_with_AZ_SMILES_v3.csv\"\n",
    "    config.IR_data_folder_exp = f\"{base_path_exp}IR_data\"\n",
    "    return config\n",
    "\n",
    "def test_model_on_datasets(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, aug_mol_df, all_gen_smis):\n",
    "    checkpoint_path_backup = config.checkpoint_path    \n",
    "    for data_type in ['exp', 'sim', 'ACD', ]:\n",
    "        print(f\"Testing on {data_type} data\")\n",
    "        config.pickle_file_path = \"\"\n",
    "        config.training_mode = \"1H_13C_HSQC_COSY_IR_MF_MW\"\n",
    "        config = test_on_data(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, data_type, aug_mol_df, all_gen_smis)\n",
    "    config.checkpoint_path = checkpoint_path_backup\n",
    "    return config\n",
    "\n",
    "def test_on_data(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, composite_idx, data_type, aug_mol_df, all_gen_smis):\n",
    "    if data_type == 'sim':\n",
    "        restore_backup_configs(config)\n",
    "    else:\n",
    "        sample_ids = chunk['sample-id'].tolist()\n",
    "        process_spectrum_data(config, sample_ids, data_type)\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    update_config_settings(config)\n",
    "    last_checkpoint = get_last_checkpoint(config.current_run_folder)\n",
    "    config.checkpoint_path = last_checkpoint\n",
    "    \n",
    "    model_MMT, val_dataloader, val_dataloader_multi = load_model_and_data(config, stoi, stoi_MF)\n",
    "    \n",
    "    prob_dict_results_1c_, results_dict_1c_ = mrtf.run_model_analysis(config, model_MMT, val_dataloader_multi, stoi, itos)\n",
    "\n",
    "    results = test_model_performance(config, model_MMT, val_dataloader, val_dataloader_multi,\n",
    "                                     stoi, itos, stoi_MF, itos_MF)\n",
    "    \n",
    "    if data_type == 'sim':\n",
    "        results['aug_mol_df'] = aug_mol_df\n",
    "        results['all_gen_smis'] = all_gen_smis\n",
    "    \n",
    "    save_results_acd_exp(results, config, data_type, composite_idx)\n",
    "    return config\n",
    "\n",
    "def restore_backup_configs(config):\n",
    "    config.csv_1H_path_SGNN = config.csv_1H_path_SGNN_backup\n",
    "    config.csv_13C_path_SGNN = config.csv_13C_path_SGNN_backup\n",
    "    config.csv_HSQC_path_SGNN = config.csv_HSQC_path_SGNN_backup\n",
    "    config.csv_COSY_path_SGNN = config.csv_COSY_path_SGNN_backup\n",
    "    config.IR_data_folder = config.IR_data_folder_backup \n",
    "    config.csv_path_val = config.csv_1H_path_SGNN_backup\n",
    "    config.pickle_file_path = \"\"\n",
    "\n",
    "def process_spectrum_data(config: Any, sample_ids: List[str], data_type: str) -> None:\n",
    "    spectrum_types = ['1H', '13C', 'HSQC', 'COSY']\n",
    "    for spectrum in spectrum_types:\n",
    "        csv_path = getattr(config, f'csv_{spectrum}_path_{data_type}')\n",
    "        df_data = pd.read_csv(csv_path)\n",
    "        df_data['sample-id'] = df_data['AZ_Number']\n",
    "        data = select_relevant_samples(df_data, sample_ids)\n",
    "        dummy_path, config = save_and_update_config(config, data_type, spectrum, data)\n",
    "        print(f\"Saved {spectrum} data to: {dummy_path}\")\n",
    "    if data_type == \"ACD\" or data_type == \"sim\":\n",
    "        config.IR_data_folder = config.IR_data_folder_backup \n",
    "    elif  data_type == \"exp\":\n",
    "        config.IR_data_folder = config.IR_data_folder_exp \n",
    "\n",
    "    \n",
    "    \n",
    "def select_relevant_samples(df: pd.DataFrame, sample_ids: List[str]) -> pd.DataFrame:\n",
    "    return df[df['sample-id'].isin(sample_ids)]\n",
    "\n",
    "def save_and_update_config(config, data_type: str, spectrum_type: str, data: pd.DataFrame) -> Tuple[str, Any]:\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    dummy_path = os.path.join(temp_dir, f\"{data_type}_{spectrum_type}_selected_samples.csv\")\n",
    "    \n",
    "    data.to_csv(dummy_path, index=False)\n",
    "    \n",
    "    config_key = f'csv_{spectrum_type}_path_SGNN'\n",
    "    setattr(config, config_key, dummy_path)\n",
    "    \n",
    "    return dummy_path, config\n",
    "\n",
    "def update_config_settings(config: Any) -> None:\n",
    "    config.csv_path_val = config.csv_1H_path_SGNN\n",
    "    config.pickle_file_path = \"\"\n",
    "\n",
    "def get_last_checkpoint(model_folder: str) -> str:\n",
    "    checkpoints = [f for f in os.listdir(model_folder) if f.endswith('.ckpt')]\n",
    "    if not checkpoints:\n",
    "        raise ValueError(f\"No checkpoints found in {model_folder}\")\n",
    "    \n",
    "    last_checkpoint = max(checkpoints, key=lambda x: os.path.getmtime(os.path.join(model_folder, x)))\n",
    "    return os.path.join(model_folder, last_checkpoint)\n",
    "\n",
    "def load_model_and_data(config: Any, stoi: Dict, stoi_MF: Dict) -> Tuple[Any, Any, Any]:\n",
    "    #import IPython; IPython.embed();\n",
    "\n",
    "    val_dataloader = mrtf.load_data(config, stoi, stoi_MF, single=True, mode=\"val\")\n",
    "    val_dataloader_multi = mrtf.load_data(config, stoi, stoi_MF, single=False, mode=\"val\")\n",
    "    model_MMT = mrtf.load_MMT_model(config)\n",
    "    return model_MMT, val_dataloader, val_dataloader_multi\n",
    "\n",
    "def test_model_performance(config: Any, model_MMT: Any, val_dataloader: Any, val_dataloader_multi: Any, \n",
    "                           stoi: Dict, itos: Dict, stoi_MF: Dict, itos_MF: Dict) -> Dict[str, Any]:\n",
    "    print(\"\\033[1m\\033[31mThis is: test_performance\\033[0m\")\n",
    "    \n",
    "    MW_filter = True\n",
    "    greedy_full = False\n",
    "    \n",
    "    model_CLIP = mrtf.load_CLIP_model(config)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['results_dict_bl_ZINC_'] = mrtf.run_test_mns_performance_CLIP_3(\n",
    "        config, model_MMT, model_CLIP, val_dataloader, stoi, itos, MW_filter)\n",
    "    results['results_dict_bl_ZINC_'], counter = mrtf.filter_invalid_inputs(results['results_dict_bl_ZINC_'])\n",
    "\n",
    "    results['avg_tani_bl_ZINC_'], html_plot = rbgvm.plot_hist_of_results(results['results_dict_bl_ZINC_'])\n",
    "\n",
    "    if greedy_full:\n",
    "        results['results_dict_greedy_bl_ZINC_'], results['failed_bl_ZINC_'] = mrtf.run_test_performance_CLIP_greedy_3(\n",
    "            config, stoi, stoi_MF, itos, itos_MF)\n",
    "        results['avg_tani_greedy_bl_ZINC_'], html_plot_greedy = rbgvm.plot_hist_of_results_greedy(\n",
    "            results['results_dict_greedy_bl_ZINC_'])\n",
    "    else:\n",
    "        config, results['results_dict_ZINC_greedy_bl_'] = mrtf.run_greedy_sampling(\n",
    "            config, model_MMT, val_dataloader_multi, itos, stoi)\n",
    "        results['avg_tani_greedy_bl_ZINC_'] = results['results_dict_ZINC_greedy_bl_'][\"tanimoto_mean\"]\n",
    "\n",
    "    results['total_results_bl_ZINC_'] = mrtf.run_test_performance_CLIP_3(\n",
    "        config, model_MMT, val_dataloader, stoi)\n",
    "    results['corr_sampleing_prob_bl_ZINC_'] = results['total_results_bl_ZINC_'][\"statistics_multiplication_avg\"][0]\n",
    "\n",
    "    print(\"avg_tani, avg_tani_greedy, corr_sampleing_prob'\")\n",
    "    print(results['avg_tani_bl_ZINC_'], results['avg_tani_greedy_bl_ZINC_'], results['corr_sampleing_prob_bl_ZINC_'])\n",
    "    print(\"Greedy tanimoto results\")\n",
    "    rbgvm.plot_hist_of_results_greedy_new(results['results_dict_ZINC_greedy_bl_'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_results_acd_exp(results: Dict[str, Any], config: Any, data_type: str, composite_idx: str) -> None:\n",
    "    variables_to_save = {\n",
    "        'avg_tani_bl_ZINC': results['avg_tani_bl_ZINC_'],\n",
    "        'results_dict_greedy_bl_ZINC': results.get('results_dict_greedy_bl_ZINC_'),\n",
    "        'failed_bl_ZINC': results.get('failed_bl_ZINC_'),\n",
    "        'avg_tani_greedy_bl_ZINC': results['avg_tani_greedy_bl_ZINC_'],\n",
    "        'results_dict_ZINC_greedy_bl': results.get('results_dict_ZINC_greedy_bl_'),\n",
    "        'total_results_bl_ZINC': results['total_results_bl_ZINC_'],\n",
    "        'corr_sampleing_prob_bl_ZINC': results['corr_sampleing_prob_bl_ZINC_'],\n",
    "        'results_dict_bl_ZINC': results['results_dict_bl_ZINC_'],\n",
    "        'checkpoint_path': config.checkpoint_path,\n",
    "    }\n",
    "    \n",
    "    if data_type == 'sim':\n",
    "        variables_to_save['aug_mol_df'] = results.get('aug_mol_df')\n",
    "        variables_to_save['all_gen_smis'] = results.get('all_gen_smis')\n",
    "    \n",
    "    save_data_with_datetime_index(\n",
    "        variables_to_save, \n",
    "        config.pkl_save_folder, \n",
    "        f\"{data_type}_sim_data\", \n",
    "        composite_idx\n",
    "    )\n",
    "\n",
    "def save_data_with_datetime_index(data: Any, base_folder: str, name: str, idx: Union[int, str]) -> None:\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{current_datetime}_{name}_{idx}.pkl\"\n",
    "    os.makedirs(base_folder, exist_ok=True)\n",
    "    file_path = os.path.join(base_folder, filename)\n",
    "\n",
    "    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    \n",
    "    print(f\"Data saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf02d25-b9cf-4370-b876-240b3c51621d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af05a4-1550-4fc4-8fb1-4109120e3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main_IC(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF, num_training_runs=3):\n",
    "    chunks = split_dataset(config, chunk_size)\n",
    "    config.model_save_dir = config.pkl_save_folder\n",
    "    model_save_dir_backup = config.model_save_dir\n",
    "    original_checkpoint_path = config.checkpoint_path  # Store the original checkpoint path\n",
    "\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {chunk_idx+1} of {len(chunks)}\")\n",
    "        \n",
    "        chunk_folder = create_chunk_folder(config, chunk_idx)\n",
    "        config.current_chunk_folder = chunk_folder\n",
    "            \n",
    "        config.blank_percentage = 0\n",
    "        config = test_pretrained_model_on_sim_data_before(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, f\"{chunk_idx}_{0}\")\n",
    "        print(config.csv_1H_path_SGNN)\n",
    "        for run_idx in range(num_training_runs):\n",
    "            print(f\"Starting training run {run_idx+1} of {num_training_runs}\")\n",
    "            \n",
    "            run_folder = create_run_folder(config.current_chunk_folder, f\"{chunk_idx}_{run_idx}\")\n",
    "            config.current_run_folder = run_folder\n",
    "            config.model_save_dir = run_folder\n",
    "\n",
    "            config.blank_percentage = 50\n",
    "            config, aug_mol_df, all_gen_smis = fine_tune_model_aug_mol(config, stoi, stoi_MF, chunk, f\"{chunk_idx}_{run_idx}\")\n",
    "            #import IPython; IPython.embed();\n",
    "\n",
    "            ### Retrun the labelling of the smiles to test it on the correct one\n",
    "            #chunk.rename(columns={'SMILES': 'SMILES_regio_isomers', 'SMILES_orig': 'SMILES'}, inplace=True)\n",
    "\n",
    "            config.blank_percentage = 0\n",
    "            config = setup_data_paths(config)\n",
    "            config = test_model_on_datasets(config, IR_config, stoi, itos, stoi_MF, itos_MF, chunk, f\"{chunk_idx}_{run_idx}\", aug_mol_df, all_gen_smis)\n",
    "\n",
    "            config.checkpoint_path = original_checkpoint_path\n",
    "        \n",
    "        print(f\"Chunk {chunk_idx+1} completed. All training runs finished.\")\n",
    "        config.model_save_dir = model_save_dir_backup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d514ebe-d184-4046-a478-f4184773b807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### RUN a1\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW2_Drop/MultimodalTransformer_time_1706856620.371885_Loss_0.202.ckpt\"\n",
    "\n",
    "config.pkl_save_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/test_on_aug_data_34_v3\"\n",
    "#config.model_save_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/small_8_3\" # Folder where networks are saved\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/ACD_1H_with_SN_filtered_v3_regio_aug.csv\"\n",
    "#config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/ACD_1H_with_SN_filtered_v3.csv\"\n",
    "\n",
    "config.MF_generations = 30#50\n",
    "config.MF_delta_weight = 100\n",
    "config.max_scaffold_generations = 300\n",
    "config.blank_percentage = 50\n",
    "config.weight_MW = 100\n",
    "config.lr_pretraining = 3e-4\n",
    "config.tr_te_split = 0.9\n",
    "config.batch_size = 64\n",
    "config.num_epochs = 30#30\n",
    "config.temperature = 1\n",
    "config.multinom_runs = 20 #20\n",
    "config.train_data_blend = 0\n",
    "\n",
    "chunk_size = 1\n",
    "\n",
    "main_IC(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0eb647-bea3-4c0e-b17d-a8406442e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN a1\n",
    "config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8i_MMT_Drop4/MultimodalTransformer_time_1710027004.1571195_Loss_0.112.ckpt\"\n",
    "#config.checkpoint_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/V8_MMT_MW2_Drop/MultimodalTransformer_time_1706856620.371885_Loss_0.202.ckpt\"\n",
    "\n",
    "config.pkl_save_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/test_on_aug_data_34_v4\"\n",
    "#config.model_save_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/1_old_models/models_v2/small_8_3\" # Folder where networks are saved\n",
    "config.SGNN_csv_gen_smi = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/ACD_1H_with_SN_filtered_v3_regio_aug.csv\"\n",
    "#config.SGNN_csv_gen_smi = \"/projects len(df) len(df) len(df)/cc/knlr326/1_NMR_project/1_NMR_data_AZ/37_Richard_ACD_sim_data/ACD_1H_with_SN_filtered_v3.csv\"\n",
    "\n",
    "config.MF_generations = 300#50\n",
    "config.MF_delta_weight = 100\n",
    "config.max_scaffold_generations = 300\n",
    "config.blank_percentage = 50\n",
    "config.weight_MW = 100\n",
    "config.lr_pretraining = 3e-4\n",
    "config.tr_te_split = 0.9\n",
    "config.batch_size = 64\n",
    "config.num_epochs = 10#30\n",
    "config.temperature = 1\n",
    "config.multinom_runs = 20 #20\n",
    "config.train_data_blend = 0\n",
    "\n",
    "chunk_size = 1\n",
    "\n",
    "main_IC(chunk_size, config, IR_config, stoi, itos, stoi_MF, itos_MF, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21777ba0-fc36-45bf-b27b-3aed0db6d240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc716758-9b34-455e-8efb-12dd3e6600f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad07129-5848-4f03-a47e-eb77b9cc6b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_aug():\n",
    "    folder_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/test_on_aug_data_34_v3/\"\n",
    "    #folder_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/precomputed_raw_data/20240724_IC_batched_MMT_d1/\"\n",
    "    model_type = \"MMT\"\n",
    "    ranking_methods = [\"COSY\", \"HSQC\", \"HSQC & COSY\"]\n",
    "    file_types = [\"sim_sim_data\", \"ACD_sim_data\", \"exp_sim_data\"]\n",
    "\n",
    "    data_type_map = {\n",
    "        \"sim_sim_data\": \"Our Simulated\",\n",
    "        \"ACD_sim_data\": \"ACD Simulated\",\n",
    "        \"exp_sim_data\": \"Experimental\"\n",
    "    }\n",
    "    filtered_out = []\n",
    "    all_rankings_list = []\n",
    "    for ranking_method in ranking_methods:\n",
    "        for file_type in file_types:\n",
    "            all_rankings = process_pkl_files_new(folder_path, file_type, ranking_method)\n",
    "            #import IPython; IPython.embed();\n",
    "            all_rankings, removed_smiles = exp_func.deduplicate_smiles_from_ranking(all_rankings)\n",
    "            all_rankings, filtered_out_rankings = filter_rankings_by_molecular_formula(all_rankings)\n",
    "            filtered_out.append(filtered_out_rankings)\n",
    "            all_rankings_list.append(all_rankings)\n",
    "            \n",
    "            accuracies = calculate_top_k_accuracy(all_rankings)\n",
    "            sim_rank_one_count = count_molecules_with_sim_rank_one(all_rankings)\n",
    "\n",
    "            data_type = data_type_map[file_type]\n",
    "            save_path = f\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/similar_starting_top_k_accuracy_MMT_{file_type}_{ranking_method}_FINAL.png\"\n",
    "            #save_path = f\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/top_k_accuracy_MMT_{file_type}_{ranking_method}_v10.png\"\n",
    "\n",
    "            plot_top_k_accuracy(accuracies, data_type, model_type, ranking_method, sim_rank_one_count, save_path, total_samples=len(all_rankings.keys()))\n",
    "\n",
    "            print(f\"Completed plot for {ranking_method} - {data_type}\")\n",
    "    return all_rankings_list, filtered_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbd0a6-0254-4321-9722-352db11bfe53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_rankings_list, filtered_out = main_aug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810764d3-5322-44e5-a45f-c3d7ac74692e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from IPython.display import display\n",
    "\n",
    "# Helper function to calculate molecular weight\n",
    "def calculate_weight(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return Chem.Descriptors.ExactMolWt(mol)\n",
    "\n",
    "def plot_smiles_from_df(data_sorted, column_name):\n",
    "    list_smiles = []\n",
    "    sample_id_list = []\n",
    "    for idx, smiles in enumerate(data_sorted[column_name]):\n",
    "        weight = calculate_weight(smiles)\n",
    "        string = f\"{column_name}_{idx}_{weight:.2f}\"\n",
    "        sample_id_list.append(string)\n",
    "        list_smiles.append(Chem.MolFromSmiles(smiles))\n",
    "        if len(list_smiles) == 9 or idx == len(data_sorted) - 1:\n",
    "            pic = Draw.MolsToGridImage(list_smiles, subImgSize=(250, 250), legends=sample_id_list)\n",
    "            display(pic)\n",
    "            list_smiles = []\n",
    "            sample_id_list = []\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/ACD_1H_with_SN_filtered_v3_regio_aug.csv\")\n",
    "\n",
    "# Plot SMILES from both columns\n",
    "print(\"Original SMILES:\")\n",
    "plot_smiles_from_df(df, 'SMILES')\n",
    "\n",
    "print(\"\\nRegio Isomer SMILES:\")\n",
    "plot_smiles_from_df(df, 'SMILES_regio_isomers')\n",
    "\n",
    "# Plotting both columns side by side\n",
    "def plot_smiles_side_by_side(data_sorted, column1, column2):\n",
    "    list_smiles1 = []\n",
    "    list_smiles2 = []\n",
    "    sample_id_list1 = []\n",
    "    sample_id_list2 = []\n",
    "    for idx, (smiles1, smiles2) in enumerate(zip(data_sorted[column1], data_sorted[column2])):\n",
    "        weight1 = calculate_weight(smiles1)\n",
    "        weight2 = calculate_weight(smiles2)\n",
    "        string1 = f\"{column1}_{idx}_{weight1:.2f}\"\n",
    "        string2 = f\"{column2}_{idx}_{weight2:.2f}\"\n",
    "        sample_id_list1.append(string1)\n",
    "        sample_id_list2.append(string2)\n",
    "        list_smiles1.append(Chem.MolFromSmiles(smiles1))\n",
    "        list_smiles2.append(Chem.MolFromSmiles(smiles2))\n",
    "        if len(list_smiles1) == 4 or idx == len(data_sorted) - 1:\n",
    "            combined_smiles = [mol for pair in zip(list_smiles1, list_smiles2) for mol in pair]\n",
    "            combined_legends = [legend for pair in zip(sample_id_list1, sample_id_list2) for legend in pair]\n",
    "            pic = Draw.MolsToGridImage(combined_smiles, molsPerRow=2, subImgSize=(250, 250), legends=combined_legends)\n",
    "            display(pic)\n",
    "            list_smiles1 = []\n",
    "            list_smiles2 = []\n",
    "            sample_id_list1 = []\n",
    "            sample_id_list2 = []\n",
    "\n",
    "print(\"\\nSide-by-side comparison:\")\n",
    "plot_smiles_side_by_side(df, 'SMILES', 'SMILES_regio_isomers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e49e9-97a6-4a68-bb53-07ff9b735613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(results_dict_bl_ZINC.values())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9cfec-6073-46b7-b36e-9169cb03f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_bl_ZINC = df['results_dict_bl_ZINC']\n",
    "smiles_list = [value[0] for value in list(results_dict_bl_ZINC.values())[0][0]]\n",
    "smiles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb11c20-8c6d-4c39-9a72-77cc4215dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/test_on_aug_data_34_v1/20240925_144233_sim_sim_data_0_0.pkl\"\n",
    "df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ac03f-2cbe-4a7c-9813-44f3ee17dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles('COc1ccc(CC(C)NCC(O)c2ccc(O)c(NC=O)c2)cc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df689b-777b-411a-9f9e-6f6c20030b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_smiles_grid(smiles_list, molsPerRow=5, subImgSize=(200, 200)):\n",
    "    \"\"\"\n",
    "    Plot a list of SMILES as a grid with a specified number of molecules per row.\n",
    "    \n",
    "    :param smiles_list: List of SMILES strings to plot\n",
    "    :param molsPerRow: Number of molecules per row in the grid (default: 5)\n",
    "    :param subImgSize: Size of each molecule image (default: (200, 200))\n",
    "    \"\"\"\n",
    "    mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
    "    \n",
    "    # Generate labels (you can customize this if needed)\n",
    "    legends = [f\"Mol {i+1}\" for i in range(len(mols))]\n",
    "    \n",
    "    # Create the grid image\n",
    "    img = Draw.MolsToGridImage(mols, molsPerRow=molsPerRow, subImgSize=subImgSize, legends=legends)\n",
    "    \n",
    "    # Display the image\n",
    "    display(img)\n",
    "\n",
    "# Read the pickle file\n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/test_on_aug_data_34_v1/20240925_144730_exp_sim_data_0_0.pkl\"\n",
    "df = pd.read_pickle(file_path)\n",
    "\n",
    "# Extract the SMILES list\n",
    "results_dict_bl_ZINC = df['results_dict_bl_ZINC']\n",
    "smiles_list = [value[0] for value in list(results_dict_bl_ZINC.values())[0][0]]\n",
    "\n",
    "# Print the number of SMILES\n",
    "print(f\"Number of SMILES: {len(smiles_list)}\")\n",
    "\n",
    "# Print the first few SMILES for verification\n",
    "print(\"\\nFirst few SMILES:\")\n",
    "for smiles in smiles_list[:5]:\n",
    "    print(smiles)\n",
    "\n",
    "# Plot the SMILES grid\n",
    "print(\"\\nPlotting SMILES grid:\")\n",
    "plot_smiles_grid(smiles_list)\n",
    "\n",
    "# Optionally, you can adjust the grid layout or image size like this:\n",
    "# plot_smiles_grid(smiles_list, molsPerRow=4, subImgSize=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0bb97-073f-4442-b7ff-adf30c5f17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['COc1ccccc1CC(C)NCC(O)c1ccc(N)c(NC=O)c1',\n",
    " 'COc1ccccc1CC(CO)NCC(O)C(O)Cc1ccc(O)cc1',\n",
    " 'CCN(CC)c1ccc(CC(C)NCC(O)c2ccc(O)c(NC=O)c2)cc1',\n",
    " 'C=CNc1cc(O)ccc1C(O)CNC(C)Cc1ccccc1OC',\n",
    " 'O=CNc1cccc(C=O)c1C(=O)C(O)CNC(CO)Cc1ccccc1O',\n",
    " 'COc1ccc(CC(C)NCC(O)c2ccc(O)c(NC=O)c2)c(OC)c1',\n",
    " 'COc1ccccc1CC(C=O)NCC(O)C(O)C1CCOc2ccc1cc2NC=O',\n",
    " 'CCOc1ccccc1CC(C)NCC(O)c1ccc(O)c(NC=O)c1',\n",
    " 'COc1ccccc1CC(C)NCC(OC)c1ccc(O)c(NC=O)c1',\n",
    " 'CCOc1cc(C(C)NCC(O)c2ccc(O)c(NC=O)c2)ccc1OC',\n",
    " 'COc1ccccc1CC(C)NCC(O)c1ccc(OC(C)=O)c(O)c1',\n",
    " 'COc1ccccc1CC(C)NCC(O)c1ccc(NC=O)c(O)c1',\n",
    " 'O=CNc1cc(C(O)CNc2cc(C=O)ccc2Cl)ccc1O',\n",
    " 'O=CNc1cc2ccc(O)c(NC=O)c2cc1CCc1ccccc1O',\n",
    " 'COc1ccccc1CC(C)NCC(O)c1cc(O)c(NC=O)cc1C',\n",
    " 'CCN(CC(O)c1ccc(O)c(NC=O)c1)C(C)Cc1ccccc1OC',\n",
    " 'CC(Cc1ccccc1OCC(C)(C)C)NCC(O)c1ccc(O)c(NC=O)c1',\n",
    " 'COc1ccccc1CC(O)C(C)NCC(O)c1ccc(O)c(NC=O)c1',\n",
    " 'COc1cc(C(C)NCC(O)c2ccc(O)c(NC=O)c2)ccc1O',\n",
    " 'COc1ccc(CC(C)NCC(O)c2ccc(NC=O)c(O)c2)cc1F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd68fa8-32fb-4bc9-85f4-11d214a8cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smiles_grid(l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98540bd-c602-40f7-817e-34a7c31d69b4",
   "metadata": {},
   "source": [
    "### Plot Guess Molecule in SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969ded4-e65c-4a62-9784-fb56c5831fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "import os\n",
    "\n",
    "# SMILES string of the molecule\n",
    "smiles = \"OC(CNC(C)Cc1ccc(OC)cc1)c1cc(ccc1O)NC=O\"\n",
    "\n",
    "# Create a RDKit molecule object from the SMILES string\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "# Generate 2D coordinates for the molecule\n",
    "AllChem.Compute2DCoords(mol)\n",
    "\n",
    "# Create a drawer object\n",
    "d = Draw.MolDraw2DSVG(300, 300)\n",
    "\n",
    "# Draw the molecule\n",
    "d.DrawMolecule(mol)\n",
    "\n",
    "# End the drawing\n",
    "d.FinishDrawing()\n",
    "\n",
    "# Get the SVG as a string\n",
    "svg = d.GetDrawingText()\n",
    "\n",
    "# Specify the path where you want to save the SVG file\n",
    "save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/___FIGURES_PAPERS/Figures_Paper_2/guess_molecule.svg\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Save the SVG to a file\n",
    "with open(save_path, 'w') as f:\n",
    "    f.write(svg)\n",
    "\n",
    "print(f\"SVG has been saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d1fdf-d2a5-459d-bd58-720eebca812d",
   "metadata": {},
   "source": [
    "Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537696c6-1f74-4494-b89b-21d4942bd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Define the directory path\n",
    "directory = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Experiment_baseline_PC_ZINC/ZINC_250_350_4000'\n",
    "\n",
    "# Get list of all PKL files in the directory\n",
    "pkl_files = [f for f in os.listdir(directory) if f.endswith('.pkl')]\n",
    "\n",
    "# Sort the files to ensure consistent ordering\n",
    "pkl_files.sort()\n",
    "\n",
    "# Load the first PKL file\n",
    "first_file_path = os.path.join(directory, pkl_files[0])\n",
    "\n",
    "# Load the data from the first PKL file\n",
    "with open(first_file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Print the file name we loaded\n",
    "print(f\"Loaded file: {pkl_files[0]}\")\n",
    "\n",
    "# You can now examine the structure of 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0426c0-eec1-43c7-894e-6ca12600149b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e89d9-f672-4980-ad43-5c8e7e877131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NMR_Structure_Elucidator] *",
   "language": "python",
   "name": "conda-env-NMR_Structure_Elucidator-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
